{
  "metadata": {
    "project_name": "rustex-formats",
    "project_version": "0.1.0",
    "rust_edition": "2021",
    "total_chunks": 44,
    "total_tokens": 7194,
    "chunk_size_stats": {
      "min_tokens": 1,
      "max_tokens": 3871,
      "avg_tokens": 163.5,
      "median_tokens": 16,
      "p95_tokens": 689
    },
    "element_distribution": {
      "Struct": 18,
      "Impl": 2,
      "Enum": 9,
      "Module": 2,
      "Function": 13
    },
    "complexity_distribution": {
      "Very Complex": 18,
      "Simple": 3,
      "Moderate": 6,
      "Complex": 17
    },
    "semantic_categories": [
      "function_definition",
      "data_structure",
      "trait_definition",
      "implementation",
      "module_organization"
    ],
    "generated_at": "2025-07-10T22:17:29.035240+00:00",
    "rustex_version": "0.1.0",
    "chunk_strategy": "semantic_boundaries"
  },
  "chunks": [
    {
      "id": "chunk_1",
      "content": "formatters",
      "content_with_context": "// File: src/lib.rs\n// Module: crate\n\nformatters\n// Complexity: 1",
      "metadata": {
        "file_path": "src/lib.rs",
        "start_line": 1,
        "end_line": 1,
        "element_type": "Module",
        "element_name": "formatters",
        "qualified_name": "crate::formatters",
        "visibility": "Public",
        "token_count": 3,
        "complexity": 1,
        "has_documentation": false,
        "documentation_quality": "Missing",
        "semantic_category": "module_organization",
        "domain_tags": [],
        "intent_tags": [],
        "references": [],
        "referenced_by": [],
        "parent_elements": [
          ""
        ],
        "child_elements": [],
        "embedding_strategy": "CodeOnly",
        "retrieval_keywords": [
          "crate::formatters",
          "formatters"
        ]
      },
      "embedding": null,
      "semantic_hash": "e81a4f3c33972d55"
    },
    {
      "id": "chunk_2",
      "content": "rag",
      "content_with_context": "// File: src/lib.rs\n// Module: crate\n\nrag\n// Complexity: 1",
      "metadata": {
        "file_path": "src/lib.rs",
        "start_line": 1,
        "end_line": 1,
        "element_type": "Module",
        "element_name": "rag",
        "qualified_name": "crate::rag",
        "visibility": "Public",
        "token_count": 1,
        "complexity": 1,
        "has_documentation": false,
        "documentation_quality": "Missing",
        "semantic_category": "module_organization",
        "domain_tags": [],
        "intent_tags": [],
        "references": [],
        "referenced_by": [],
        "parent_elements": [
          ""
        ],
        "child_elements": [],
        "embedding_strategy": "CodeOnly",
        "retrieval_keywords": [
          "crate::rag",
          "rag"
        ]
      },
      "embedding": null,
      "semantic_hash": "d23679a1d85477bc"
    },
    {
      "id": "chunk_3",
      "content": " Format project AST according to the specified output format.\n\n# [doc = \" Format project AST according to the specified output format.\"] pub fn format_project_ast (project_ast : & ProjectAst , format : & OutputFormat , pretty : bool ,) -> Result < String > { match format { OutputFormat :: Json => { if pretty { Ok (serde_json :: to_string_pretty (project_ast) ?) } else { Ok (serde_json :: to_string (project_ast) ?) } } OutputFormat :: MessagePack => { let data = rmp_serde :: to_vec (project_ast) ? ; use base64 :: Engine ; Ok (base64 :: engine :: general_purpose :: STANDARD . encode (data)) } OutputFormat :: Markdown => { format_as_markdown (project_ast) } OutputFormat :: GraphQL => { format_as_graphql_schema (project_ast) } OutputFormat :: Rag => { let formatter = RagFormatter :: default () ; let rag_doc = formatter . format (project_ast) ? ; crate :: rag :: format_as_json (& rag_doc , pretty) } } } . sig",
      "content_with_context": "// File: src/formatters.rs\n// Module: crate::formatters\n\n Format project AST according to the specified output format.\n\n# [doc = \" Format project AST according to the specified output format.\"] pub fn format_project_ast (project_ast : & ProjectAst , format : & OutputFormat , pretty : bool ,) -> Result < String > { match format { OutputFormat :: Json => { if pretty { Ok (serde_json :: to_string_pretty (project_ast) ?) } else { Ok (serde_json :: to_string (project_ast) ?) } } OutputFormat :: MessagePack => { let data = rmp_serde :: to_vec (project_ast) ? ; use base64 :: Engine ; Ok (base64 :: engine :: general_purpose :: STANDARD . encode (data)) } OutputFormat :: Markdown => { format_as_markdown (project_ast) } OutputFormat :: GraphQL => { format_as_graphql_schema (project_ast) } OutputFormat :: Rag => { let formatter = RagFormatter :: default () ; let rag_doc = formatter . format (project_ast) ? ; crate :: rag :: format_as_json (& rag_doc , pretty) } } } . sig\n// Complexity: 50",
      "metadata": {
        "file_path": "src/formatters.rs",
        "start_line": 1,
        "end_line": 1,
        "element_type": "Function",
        "element_name": "format_project_ast",
        "qualified_name": "crate::formatters::format_project_ast",
        "visibility": "Public",
        "token_count": 230,
        "complexity": 50,
        "has_documentation": true,
        "documentation_quality": "Basic",
        "semantic_category": "function_definition",
        "domain_tags": [],
        "intent_tags": [],
        "references": [],
        "referenced_by": [],
        "parent_elements": [
          ""
        ],
        "child_elements": [],
        "embedding_strategy": "Combined",
        "retrieval_keywords": [
          "according",
          "crate::formatters::format_project_ast",
          "format",
          "format_project_ast",
          "output",
          "project",
          "specified"
        ]
      },
      "embedding": null,
      "semantic_hash": "9699e44495bed34"
    },
    {
      "id": "chunk_4",
      "content": " Format project AST as Markdown documentation.\n\n# [doc = \" Format project AST as Markdown documentation.\"] pub fn format_as_markdown (project_ast : & ProjectAst) -> Result < String > { let mut markdown = String :: new () ; markdown . push_str (& format ! (\"# {}\\n\\n\" , project_ast . project . name)) ; markdown . push_str (& format ! (\"**Version:** {}\\n\" , project_ast . project . version)) ; markdown . push_str (& format ! (\"**Rust Edition:** {}\\n\\n\" , project_ast . project . rust_edition)) ; markdown . push_str (\"## Table of Contents\\n\\n\") ; for file in & project_ast . files { markdown . push_str (& format ! (\"- [{}](#{})\\n\" , file . relative_path . display () , file . relative_path . to_string_lossy () . replace ('/' , \"\") . replace ('.' , \"\"))) ; } markdown . push ('\\n') ; markdown . push_str (\"## Project Metrics\\n\\n\") ; markdown . push_str (& format ! (\"- **Total Files:** {}\\n\" , project_ast . metrics . total_files)) ; markdown . push_str (& format ! (\"- **Total Lines:** {}\\n\" , project_ast . metrics . total_lines)) ; markdown . push_str (& format ! (\"- **Total Functions:** {}\\n\" , project_ast . metrics . total_functions)) ; markdown . push_str (& format ! (\"- **Total Structs:** {}\\n\" , project_ast . metrics . total_structs)) ; markdown . push_str (& format ! (\"- **Total Enums:** {}\\n\" , project_ast . metrics . total_enums)) ; markdown . push_str (& format ! (\"- **Total Traits:** {}\\n\" , project_ast . metrics . total_traits)) ; markdown . push_str (& format ! (\"- **Average Complexity:** {:.2}\\n\\n\" , project_ast . metrics . complexity_average)) ; for file in & project_ast . files { markdown . push_str (& format ! (\"## {}\\n\\n\" , file . relative_path . display ())) ; if ! file . elements . is_empty () { for element in & file . elements { markdown . push_str (& format ! (\"### {} `{}`\\n\\n\" , format ! (\"{:?}\" , element . element_type) , element . name)) ; if ! element . doc_comments . is_empty () { for doc in & element . doc_comments { markdown . push_str (& format ! (\"{}\\n\" , doc)) ; } markdown . push ('\\n') ; } if let Some (signature) = & element . signature { markdown . push_str (\"```rust\\n\") ; markdown . push_str (signature) ; markdown . push_str (\"\\n```\\n\\n\") ; } markdown . push_str (\"**Details:**\\n\") ; markdown . push_str (& format ! (\"- **Location:** {}:{}-{}\\n\" , file . relative_path . display () , element . location . line_start , element . location . line_end)) ; markdown . push_str (& format ! (\"- **Visibility:** {:?}\\n\" , element . visibility)) ; if let Some (complexity) = element . complexity { markdown . push_str (& format ! (\"- **Complexity:** {}\\n\" , complexity)) ; } markdown . push ('\\n') ; } } else { markdown . push_str (\"*No documented elements in this file.*\\n\\n\") ; } } Ok (markdown) } . sig",
      "content_with_context": "// File: src/formatters.rs\n// Module: crate::formatters\n\n Format project AST as Markdown documentation.\n\n# [doc = \" Format project AST as Markdown documentation.\"] pub fn format_as_markdown (project_ast : & ProjectAst) -> Result < String > { let mut markdown = String :: new () ; markdown . push_str (& format ! (\"# {}\\n\\n\" , project_ast . project . name)) ; markdown . push_str (& format ! (\"**Version:** {}\\n\" , project_ast . project . version)) ; markdown . push_str (& format ! (\"**Rust Edition:** {}\\n\\n\" , project_ast . project . rust_edition)) ; markdown . push_str (\"## Table of Contents\\n\\n\") ; for file in & project_ast . files { markdown . push_str (& format ! (\"- [{}](#{})\\n\" , file . relative_path . display () , file . relative_path . to_string_lossy () . replace ('/' , \"\") . replace ('.' , \"\"))) ; } markdown . push ('\\n') ; markdown . push_str (\"## Project Metrics\\n\\n\") ; markdown . push_str (& format ! (\"- **Total Files:** {}\\n\" , project_ast . metrics . total_files)) ; markdown . push_str (& format ! (\"- **Total Lines:** {}\\n\" , project_ast . metrics . total_lines)) ; markdown . push_str (& format ! (\"- **Total Functions:** {}\\n\" , project_ast . metrics . total_functions)) ; markdown . push_str (& format ! (\"- **Total Structs:** {}\\n\" , project_ast . metrics . total_structs)) ; markdown . push_str (& format ! (\"- **Total Enums:** {}\\n\" , project_ast . metrics . total_enums)) ; markdown . push_str (& format ! (\"- **Total Traits:** {}\\n\" , project_ast . metrics . total_traits)) ; markdown . push_str (& format ! (\"- **Average Complexity:** {:.2}\\n\\n\" , project_ast . metrics . complexity_average)) ; for file in & project_ast . files { markdown . push_str (& format ! (\"## {}\\n\\n\" , file . relative_path . display ())) ; if ! file . elements . is_empty () { for element in & file . elements { markdown . push_str (& format ! (\"### {} `{}`\\n\\n\" , format ! (\"{:?}\" , element . element_type) , element . name)) ; if ! element . doc_comments . is_empty () { for doc in & element . doc_comments { markdown . push_str (& format ! (\"{}\\n\" , doc)) ; } markdown . push ('\\n') ; } if let Some (signature) = & element . signature { markdown . push_str (\"```rust\\n\") ; markdown . push_str (signature) ; markdown . push_str (\"\\n```\\n\\n\") ; } markdown . push_str (\"**Details:**\\n\") ; markdown . push_str (& format ! (\"- **Location:** {}:{}-{}\\n\" , file . relative_path . display () , element . location . line_start , element . location . line_end)) ; markdown . push_str (& format ! (\"- **Visibility:** {:?}\\n\" , element . visibility)) ; if let Some (complexity) = element . complexity { markdown . push_str (& format ! (\"- **Complexity:** {}\\n\" , complexity)) ; } markdown . push ('\\n') ; } } else { markdown . push_str (\"*No documented elements in this file.*\\n\\n\") ; } } Ok (markdown) } . sig\n// Complexity: 56",
      "metadata": {
        "file_path": "src/formatters.rs",
        "start_line": 1,
        "end_line": 1,
        "element_type": "Function",
        "element_name": "format_as_markdown",
        "qualified_name": "crate::formatters::format_as_markdown",
        "visibility": "Public",
        "token_count": 689,
        "complexity": 56,
        "has_documentation": true,
        "documentation_quality": "Basic",
        "semantic_category": "function_definition",
        "domain_tags": [],
        "intent_tags": [],
        "references": [],
        "referenced_by": [],
        "parent_elements": [
          ""
        ],
        "child_elements": [],
        "embedding_strategy": "Combined",
        "retrieval_keywords": [
          "crate::formatters::format_as_markdown",
          "documentation",
          "format",
          "format_as_markdown",
          "markdown",
          "project"
        ]
      },
      "embedding": null,
      "semantic_hash": "14c39612e707d3a4"
    },
    {
      "id": "chunk_5",
      "content": " Format project AST as GraphQL schema.\n\n# [doc = \" Format project AST as GraphQL schema.\"] pub fn format_as_graphql_schema (project_ast : & ProjectAst) -> Result < String > { let mut schema = String :: new () ; schema . push_str (& format ! (\"# GraphQL Schema for {}\\n\" , project_ast . project . name)) ; schema . push_str (& format ! (\"# Generated from Rust AST\\n\\n\")) ; schema . push_str (\"type Project {\\n\") ; schema . push_str (\"  name: String!\\n\") ; schema . push_str (\"  version: String!\\n\") ; schema . push_str (\"  rustEdition: String!\\n\") ; schema . push_str (\"  files: [File!]!\\n\") ; schema . push_str (\"  metrics: ProjectMetrics!\\n\") ; schema . push_str (\"}\\n\\n\") ; schema . push_str (\"type File {\\n\") ; schema . push_str (\"  path: String!\\n\") ; schema . push_str (\"  elements: [CodeElement!]!\\n\") ; schema . push_str (\"}\\n\\n\") ; schema . push_str (\"type CodeElement {\\n\") ; schema . push_str (\"  id: String!\\n\") ; schema . push_str (\"  elementType: ElementType!\\n\") ; schema . push_str (\"  name: String!\\n\") ; schema . push_str (\"  signature: String\\n\") ; schema . push_str (\"  docComments: [String!]!\\n\") ; schema . push_str (\"  visibility: Visibility!\\n\") ; schema . push_str (\"  complexity: Int\\n\") ; schema . push_str (\"  location: Location!\\n\") ; schema . push_str (\"  hierarchy: ElementHierarchy!\\n\") ; schema . push_str (\"  crossReferences: CrossReferences!\\n\") ; schema . push_str (\"}\\n\\n\") ; schema . push_str (\"enum ElementType {\\n\") ; schema . push_str (\"  FUNCTION\\n\") ; schema . push_str (\"  STRUCT\\n\") ; schema . push_str (\"  ENUM\\n\") ; schema . push_str (\"  TRAIT\\n\") ; schema . push_str (\"  IMPLEMENTATION\\n\") ; schema . push_str (\"  MODULE\\n\") ; schema . push_str (\"}\\n\\n\") ; schema . push_str (\"enum Visibility {\\n\") ; schema . push_str (\"  PUBLIC\\n\") ; schema . push_str (\"  PRIVATE\\n\") ; schema . push_str (\"  CRATE\\n\") ; schema . push_str (\"  SUPER\\n\") ; schema . push_str (\"}\\n\\n\") ; schema . push_str (\"type Location {\\n\") ; schema . push_str (\"  lineStart: Int!\\n\") ; schema . push_str (\"  lineEnd: Int!\\n\") ; schema . push_str (\"  columnStart: Int!\\n\") ; schema . push_str (\"  columnEnd: Int!\\n\") ; schema . push_str (\"}\\n\\n\") ; schema . push_str (\"type ElementHierarchy {\\n\") ; schema . push_str (\"  qualifiedName: String!\\n\") ; schema . push_str (\"  modulePath: String!\\n\") ; schema . push_str (\"  parentId: String\\n\") ; schema . push_str (\"  children: [String!]!\\n\") ; schema . push_str (\"}\\n\\n\") ; schema . push_str (\"type CrossReferences {\\n\") ; schema . push_str (\"  outgoing: [String!]!\\n\") ; schema . push_str (\"  incoming: [String!]!\\n\") ; schema . push_str (\"}\\n\\n\") ; schema . push_str (\"type ProjectMetrics {\\n\") ; schema . push_str (\"  totalFiles: Int!\\n\") ; schema . push_str (\"  totalLines: Int!\\n\") ; schema . push_str (\"  totalFunctions: Int!\\n\") ; schema . push_str (\"  totalStructs: Int!\\n\") ; schema . push_str (\"  totalEnums: Int!\\n\") ; schema . push_str (\"  totalTraits: Int!\\n\") ; schema . push_str (\"  complexityAverage: Float!\\n\") ; schema . push_str (\"}\\n\\n\") ; schema . push_str (\"type Query {\\n\") ; schema . push_str (\"  project: Project!\\n\") ; schema . push_str (\"  file(path: String!): File\\n\") ; schema . push_str (\"  element(id: String!): CodeElement\\n\") ; schema . push_str (\"  elementsByType(elementType: ElementType!): [CodeElement!]!\\n\") ; schema . push_str (\"  elementsByComplexity(minComplexity: Int!): [CodeElement!]!\\n\") ; schema . push_str (\"}\\n\") ; Ok (schema) } . sig",
      "content_with_context": "// File: src/formatters.rs\n// Module: crate::formatters\n\n Format project AST as GraphQL schema.\n\n# [doc = \" Format project AST as GraphQL schema.\"] pub fn format_as_graphql_schema (project_ast : & ProjectAst) -> Result < String > { let mut schema = String :: new () ; schema . push_str (& format ! (\"# GraphQL Schema for {}\\n\" , project_ast . project . name)) ; schema . push_str (& format ! (\"# Generated from Rust AST\\n\\n\")) ; schema . push_str (\"type Project {\\n\") ; schema . push_str (\"  name: String!\\n\") ; schema . push_str (\"  version: String!\\n\") ; schema . push_str (\"  rustEdition: String!\\n\") ; schema . push_str (\"  files: [File!]!\\n\") ; schema . push_str (\"  metrics: ProjectMetrics!\\n\") ; schema . push_str (\"}\\n\\n\") ; schema . push_str (\"type File {\\n\") ; schema . push_str (\"  path: String!\\n\") ; schema . push_str (\"  elements: [CodeElement!]!\\n\") ; schema . push_str (\"}\\n\\n\") ; schema . push_str (\"type CodeElement {\\n\") ; schema . push_str (\"  id: String!\\n\") ; schema . push_str (\"  elementType: ElementType!\\n\") ; schema . push_str (\"  name: String!\\n\") ; schema . push_str (\"  signature: String\\n\") ; schema . push_str (\"  docComments: [String!]!\\n\") ; schema . push_str (\"  visibility: Visibility!\\n\") ; schema . push_str (\"  complexity: Int\\n\") ; schema . push_str (\"  location: Location!\\n\") ; schema . push_str (\"  hierarchy: ElementHierarchy!\\n\") ; schema . push_str (\"  crossReferences: CrossReferences!\\n\") ; schema . push_str (\"}\\n\\n\") ; schema . push_str (\"enum ElementType {\\n\") ; schema . push_str (\"  FUNCTION\\n\") ; schema . push_str (\"  STRUCT\\n\") ; schema . push_str (\"  ENUM\\n\") ; schema . push_str (\"  TRAIT\\n\") ; schema . push_str (\"  IMPLEMENTATION\\n\") ; schema . push_str (\"  MODULE\\n\") ; schema . push_str (\"}\\n\\n\") ; schema . push_str (\"enum Visibility {\\n\") ; schema . push_str (\"  PUBLIC\\n\") ; schema . push_str (\"  PRIVATE\\n\") ; schema . push_str (\"  CRATE\\n\") ; schema . push_str (\"  SUPER\\n\") ; schema . push_str (\"}\\n\\n\") ; schema . push_str (\"type Location {\\n\") ; schema . push_str (\"  lineStart: Int!\\n\") ; schema . push_str (\"  lineEnd: Int!\\n\") ; schema . push_str (\"  columnStart: Int!\\n\") ; schema . push_str (\"  columnEnd: Int!\\n\") ; schema . push_str (\"}\\n\\n\") ; schema . push_str (\"type ElementHierarchy {\\n\") ; schema . push_str (\"  qualifiedName: String!\\n\") ; schema . push_str (\"  modulePath: String!\\n\") ; schema . push_str (\"  parentId: String\\n\") ; schema . push_str (\"  children: [String!]!\\n\") ; schema . push_str (\"}\\n\\n\") ; schema . push_str (\"type CrossReferences {\\n\") ; schema . push_str (\"  outgoing: [String!]!\\n\") ; schema . push_str (\"  incoming: [String!]!\\n\") ; schema . push_str (\"}\\n\\n\") ; schema . push_str (\"type ProjectMetrics {\\n\") ; schema . push_str (\"  totalFiles: Int!\\n\") ; schema . push_str (\"  totalLines: Int!\\n\") ; schema . push_str (\"  totalFunctions: Int!\\n\") ; schema . push_str (\"  totalStructs: Int!\\n\") ; schema . push_str (\"  totalEnums: Int!\\n\") ; schema . push_str (\"  totalTraits: Int!\\n\") ; schema . push_str (\"  complexityAverage: Float!\\n\") ; schema . push_str (\"}\\n\\n\") ; schema . push_str (\"type Query {\\n\") ; schema . push_str (\"  project: Project!\\n\") ; schema . push_str (\"  file(path: String!): File\\n\") ; schema . push_str (\"  element(id: String!): CodeElement\\n\") ; schema . push_str (\"  elementsByType(elementType: ElementType!): [CodeElement!]!\\n\") ; schema . push_str (\"  elementsByComplexity(minComplexity: Int!): [CodeElement!]!\\n\") ; schema . push_str (\"}\\n\") ; Ok (schema) } . sig\n// Complexity: 3",
      "metadata": {
        "file_path": "src/formatters.rs",
        "start_line": 1,
        "end_line": 1,
        "element_type": "Function",
        "element_name": "format_as_graphql_schema",
        "qualified_name": "crate::formatters::format_as_graphql_schema",
        "visibility": "Public",
        "token_count": 862,
        "complexity": 3,
        "has_documentation": true,
        "documentation_quality": "Basic",
        "semantic_category": "function_definition",
        "domain_tags": [],
        "intent_tags": [],
        "references": [],
        "referenced_by": [],
        "parent_elements": [
          ""
        ],
        "child_elements": [],
        "embedding_strategy": "Combined",
        "retrieval_keywords": [
          "crate::formatters::format_as_graphql_schema",
          "format",
          "format_as_graphql_schema",
          "graphql",
          "project",
          "schema"
        ]
      },
      "embedding": null,
      "semantic_hash": "61eed22090eeb10c"
    },
    {
      "id": "chunk_6",
      "content": " Create a RAG formatter with custom configuration.\n\n# [doc = \" Create a RAG formatter with custom configuration.\"] pub fn create_rag_formatter (config : RagConfig) -> RagFormatter { RagFormatter :: new (config) } . sig",
      "content_with_context": "// File: src/formatters.rs\n// Module: crate::formatters\n\n Create a RAG formatter with custom configuration.\n\n# [doc = \" Create a RAG formatter with custom configuration.\"] pub fn create_rag_formatter (config : RagConfig) -> RagFormatter { RagFormatter :: new (config) } . sig\n// Complexity: 3",
      "metadata": {
        "file_path": "src/formatters.rs",
        "start_line": 1,
        "end_line": 1,
        "element_type": "Function",
        "element_name": "create_rag_formatter",
        "qualified_name": "crate::formatters::create_rag_formatter",
        "visibility": "Public",
        "token_count": 55,
        "complexity": 3,
        "has_documentation": true,
        "documentation_quality": "Basic",
        "semantic_category": "function_definition",
        "domain_tags": [],
        "intent_tags": [],
        "references": [],
        "referenced_by": [],
        "parent_elements": [
          ""
        ],
        "child_elements": [],
        "embedding_strategy": "Combined",
        "retrieval_keywords": [
          "configuration",
          "crate::formatters::create_rag_formatter",
          "create",
          "create_rag_formatter",
          "custom",
          "formatter",
          "with"
        ]
      },
      "embedding": null,
      "semantic_hash": "77f96b548d8e6a9a"
    },
    {
      "id": "chunk_7",
      "content": " Format project AST using a custom RAG configuration.\n\n# [doc = \" Format project AST using a custom RAG configuration.\"] pub fn format_as_rag_with_config (project_ast : & ProjectAst , config : RagConfig , pretty : bool ,) -> Result < String > { let formatter = RagFormatter :: new (config) ; let rag_doc = formatter . format (project_ast) ? ; crate :: rag :: format_as_json (& rag_doc , pretty) } . sig",
      "content_with_context": "// File: src/formatters.rs\n// Module: crate::formatters\n\n Format project AST using a custom RAG configuration.\n\n# [doc = \" Format project AST using a custom RAG configuration.\"] pub fn format_as_rag_with_config (project_ast : & ProjectAst , config : RagConfig , pretty : bool ,) -> Result < String > { let formatter = RagFormatter :: new (config) ; let rag_doc = formatter . format (project_ast) ? ; crate :: rag :: format_as_json (& rag_doc , pretty) } . sig\n// Complexity: 7",
      "metadata": {
        "file_path": "src/formatters.rs",
        "start_line": 1,
        "end_line": 1,
        "element_type": "Function",
        "element_name": "format_as_rag_with_config",
        "qualified_name": "crate::formatters::format_as_rag_with_config",
        "visibility": "Public",
        "token_count": 101,
        "complexity": 7,
        "has_documentation": true,
        "documentation_quality": "Basic",
        "semantic_category": "function_definition",
        "domain_tags": [],
        "intent_tags": [],
        "references": [],
        "referenced_by": [],
        "parent_elements": [
          ""
        ],
        "child_elements": [],
        "embedding_strategy": "Combined",
        "retrieval_keywords": [
          "configuration",
          "crate::formatters::format_as_rag_with_config",
          "custom",
          "format",
          "format_as_rag_with_config",
          "project",
          "using"
        ]
      },
      "embedding": null,
      "semantic_hash": "336838aaa28c9873"
    },
    {
      "id": "chunk_8",
      "content": " Format project AST as JSONL for streaming/embedding processing.\n\n# [doc = \" Format project AST as JSONL for streaming/embedding processing.\"] pub fn format_as_rag_jsonl (project_ast : & ProjectAst) -> Result < String > { let formatter = RagFormatter :: default () ; let rag_doc = formatter . format (project_ast) ? ; crate :: rag :: format_as_jsonl (& rag_doc) } . sig",
      "content_with_context": "// File: src/formatters.rs\n// Module: crate::formatters\n\n Format project AST as JSONL for streaming/embedding processing.\n\n# [doc = \" Format project AST as JSONL for streaming/embedding processing.\"] pub fn format_as_rag_jsonl (project_ast : & ProjectAst) -> Result < String > { let formatter = RagFormatter :: default () ; let rag_doc = formatter . format (project_ast) ? ; crate :: rag :: format_as_jsonl (& rag_doc) } . sig\n// Complexity: 7",
      "metadata": {
        "file_path": "src/formatters.rs",
        "start_line": 1,
        "end_line": 1,
        "element_type": "Function",
        "element_name": "format_as_rag_jsonl",
        "qualified_name": "crate::formatters::format_as_rag_jsonl",
        "visibility": "Public",
        "token_count": 93,
        "complexity": 7,
        "has_documentation": true,
        "documentation_quality": "Basic",
        "semantic_category": "function_definition",
        "domain_tags": [],
        "intent_tags": [],
        "references": [],
        "referenced_by": [],
        "parent_elements": [
          ""
        ],
        "child_elements": [],
        "embedding_strategy": "Combined",
        "retrieval_keywords": [
          "crate::formatters::format_as_rag_jsonl",
          "format",
          "format_as_rag_jsonl",
          "jsonl",
          "processing",
          "project",
          "streaming/embedding"
        ]
      },
      "embedding": null,
      "semantic_hash": "150b4e2e2dc05eab"
    },
    {
      "id": "chunk_9",
      "content": " Format project AST for embedding models.\n\n# [doc = \" Format project AST for embedding models.\"] pub fn format_for_embeddings (project_ast : & ProjectAst) -> Result < Vec < crate :: rag :: EmbeddingInput > > { let formatter = RagFormatter :: default () ; let rag_doc = formatter . format (project_ast) ? ; crate :: rag :: format_for_embeddings (& rag_doc) } . sig",
      "content_with_context": "// File: src/formatters.rs\n// Module: crate::formatters\n\n Format project AST for embedding models.\n\n# [doc = \" Format project AST for embedding models.\"] pub fn format_for_embeddings (project_ast : & ProjectAst) -> Result < Vec < crate :: rag :: EmbeddingInput > > { let formatter = RagFormatter :: default () ; let rag_doc = formatter . format (project_ast) ? ; crate :: rag :: format_for_embeddings (& rag_doc) } . sig\n// Complexity: 7",
      "metadata": {
        "file_path": "src/formatters.rs",
        "start_line": 1,
        "end_line": 1,
        "element_type": "Function",
        "element_name": "format_for_embeddings",
        "qualified_name": "crate::formatters::format_for_embeddings",
        "visibility": "Public",
        "token_count": 91,
        "complexity": 7,
        "has_documentation": true,
        "documentation_quality": "Basic",
        "semantic_category": "function_definition",
        "domain_tags": [],
        "intent_tags": [],
        "references": [],
        "referenced_by": [],
        "parent_elements": [
          ""
        ],
        "child_elements": [],
        "embedding_strategy": "Combined",
        "retrieval_keywords": [
          "crate::formatters::format_for_embeddings",
          "embedding",
          "format",
          "format_for_embeddings",
          "models",
          "project"
        ]
      },
      "embedding": null,
      "semantic_hash": "2f2d8fb224606af2"
    },
    {
      "id": "chunk_10",
      "content": " RAG-optimized AST representation designed for embedding and retrieval.\n\nRagDocument",
      "content_with_context": "// File: src/rag.rs\n// Module: crate::rag\n\n RAG-optimized AST representation designed for embedding and retrieval.\n\nRagDocument\n// Complexity: 6",
      "metadata": {
        "file_path": "src/rag.rs",
        "start_line": 1,
        "end_line": 1,
        "element_type": "Struct",
        "element_name": "RagDocument",
        "qualified_name": "crate::rag::RagDocument",
        "visibility": "Public",
        "token_count": 21,
        "complexity": 6,
        "has_documentation": true,
        "documentation_quality": "Basic",
        "semantic_category": "data_structure",
        "domain_tags": [],
        "intent_tags": [
          "data_type"
        ],
        "references": [],
        "referenced_by": [],
        "parent_elements": [
          ""
        ],
        "child_elements": [],
        "embedding_strategy": "DocumentationOnly",
        "retrieval_keywords": [
          "RagDocument",
          "crate::rag::RagDocument",
          "designed",
          "embedding",
          "rag-optimized",
          "representation",
          "retrieval"
        ]
      },
      "embedding": null,
      "semantic_hash": "145f99d28bcb5bb2"
    },
    {
      "id": "chunk_11",
      "content": " Metadata for RAG document indexing and filtering.\n\nRagMetadata",
      "content_with_context": "// File: src/rag.rs\n// Module: crate::rag\n\n Metadata for RAG document indexing and filtering.\n\nRagMetadata\n// Complexity: 16",
      "metadata": {
        "file_path": "src/rag.rs",
        "start_line": 1,
        "end_line": 1,
        "element_type": "Struct",
        "element_name": "RagMetadata",
        "qualified_name": "crate::rag::RagMetadata",
        "visibility": "Public",
        "token_count": 16,
        "complexity": 16,
        "has_documentation": true,
        "documentation_quality": "Basic",
        "semantic_category": "data_structure",
        "domain_tags": [],
        "intent_tags": [
          "data_type"
        ],
        "references": [],
        "referenced_by": [],
        "parent_elements": [
          ""
        ],
        "child_elements": [],
        "embedding_strategy": "DocumentationOnly",
        "retrieval_keywords": [
          "RagMetadata",
          "crate::rag::RagMetadata",
          "document",
          "filtering",
          "indexing",
          "metadata"
        ]
      },
      "embedding": null,
      "semantic_hash": "acf052a748c5524c"
    },
    {
      "id": "chunk_12",
      "content": " Statistics about chunk sizes for embedding optimization.\n\nChunkSizeStats",
      "content_with_context": "// File: src/rag.rs\n// Module: crate::rag\n\n Statistics about chunk sizes for embedding optimization.\n\nChunkSizeStats\n// Complexity: 6",
      "metadata": {
        "file_path": "src/rag.rs",
        "start_line": 1,
        "end_line": 1,
        "element_type": "Struct",
        "element_name": "ChunkSizeStats",
        "qualified_name": "crate::rag::ChunkSizeStats",
        "visibility": "Public",
        "token_count": 19,
        "complexity": 6,
        "has_documentation": true,
        "documentation_quality": "Basic",
        "semantic_category": "data_structure",
        "domain_tags": [],
        "intent_tags": [
          "data_type"
        ],
        "references": [],
        "referenced_by": [],
        "parent_elements": [
          ""
        ],
        "child_elements": [],
        "embedding_strategy": "DocumentationOnly",
        "retrieval_keywords": [
          "ChunkSizeStats",
          "about",
          "chunk",
          "crate::rag::ChunkSizeStats",
          "embedding",
          "optimization",
          "sizes",
          "statistics"
        ]
      },
      "embedding": null,
      "semantic_hash": "62aebf8218f0cf2e"
    },
    {
      "id": "chunk_13",
      "content": " A single text chunk optimized for embedding and retrieval.\n\nRagChunk",
      "content_with_context": "// File: src/rag.rs\n// Module: crate::rag\n\n A single text chunk optimized for embedding and retrieval.\n\nRagChunk\n// Complexity: 9",
      "metadata": {
        "file_path": "src/rag.rs",
        "start_line": 1,
        "end_line": 1,
        "element_type": "Struct",
        "element_name": "RagChunk",
        "qualified_name": "crate::rag::RagChunk",
        "visibility": "Public",
        "token_count": 18,
        "complexity": 9,
        "has_documentation": true,
        "documentation_quality": "Basic",
        "semantic_category": "data_structure",
        "domain_tags": [],
        "intent_tags": [
          "data_type"
        ],
        "references": [],
        "referenced_by": [],
        "parent_elements": [
          ""
        ],
        "child_elements": [],
        "embedding_strategy": "DocumentationOnly",
        "retrieval_keywords": [
          "RagChunk",
          "chunk",
          "crate::rag::RagChunk",
          "embedding",
          "optimized",
          "retrieval",
          "single",
          "text"
        ]
      },
      "embedding": null,
      "semantic_hash": "4f3b710080522eac"
    },
    {
      "id": "chunk_14",
      "content": " Metadata for individual chunks.\n\nChunkMetadata",
      "content_with_context": "// File: src/rag.rs\n// Module: crate::rag\n\n Metadata for individual chunks.\n\nChunkMetadata\n// Complexity: 24",
      "metadata": {
        "file_path": "src/rag.rs",
        "start_line": 1,
        "end_line": 1,
        "element_type": "Struct",
        "element_name": "ChunkMetadata",
        "qualified_name": "crate::rag::ChunkMetadata",
        "visibility": "Public",
        "token_count": 12,
        "complexity": 24,
        "has_documentation": true,
        "documentation_quality": "Basic",
        "semantic_category": "data_structure",
        "domain_tags": [],
        "intent_tags": [
          "data_type"
        ],
        "references": [],
        "referenced_by": [],
        "parent_elements": [
          ""
        ],
        "child_elements": [],
        "embedding_strategy": "DocumentationOnly",
        "retrieval_keywords": [
          "ChunkMetadata",
          "chunks",
          "crate::rag::ChunkMetadata",
          "individual",
          "metadata"
        ]
      },
      "embedding": null,
      "semantic_hash": "8839dda573d6b3b0"
    },
    {
      "id": "chunk_15",
      "content": " Documentation quality assessment for ranking.\n\nDocumentationQuality",
      "content_with_context": "// File: src/rag.rs\n// Module: crate::rag\n\n Documentation quality assessment for ranking.\n\nDocumentationQuality\n// Complexity: 12",
      "metadata": {
        "file_path": "src/rag.rs",
        "start_line": 1,
        "end_line": 1,
        "element_type": "Enum",
        "element_name": "DocumentationQuality",
        "qualified_name": "crate::rag::DocumentationQuality",
        "visibility": "Public",
        "token_count": 17,
        "complexity": 12,
        "has_documentation": true,
        "documentation_quality": "Basic",
        "semantic_category": "data_structure",
        "domain_tags": [],
        "intent_tags": [
          "data_type"
        ],
        "references": [],
        "referenced_by": [],
        "parent_elements": [
          ""
        ],
        "child_elements": [],
        "embedding_strategy": "DocumentationOnly",
        "retrieval_keywords": [
          "DocumentationQuality",
          "assessment",
          "crate::rag::DocumentationQuality",
          "documentation",
          "quality",
          "ranking"
        ]
      },
      "embedding": null,
      "semantic_hash": "b0e0ebd88cc82a7a"
    },
    {
      "id": "chunk_16",
      "content": " Strategy for embedding this chunk.\n\nEmbeddingStrategy",
      "content_with_context": "// File: src/rag.rs\n// Module: crate::rag\n\n Strategy for embedding this chunk.\n\nEmbeddingStrategy\n// Complexity: 13",
      "metadata": {
        "file_path": "src/rag.rs",
        "start_line": 1,
        "end_line": 1,
        "element_type": "Enum",
        "element_name": "EmbeddingStrategy",
        "qualified_name": "crate::rag::EmbeddingStrategy",
        "visibility": "Public",
        "token_count": 14,
        "complexity": 13,
        "has_documentation": true,
        "documentation_quality": "Basic",
        "semantic_category": "data_structure",
        "domain_tags": [],
        "intent_tags": [
          "data_type"
        ],
        "references": [],
        "referenced_by": [],
        "parent_elements": [
          ""
        ],
        "child_elements": [],
        "embedding_strategy": "DocumentationOnly",
        "retrieval_keywords": [
          "EmbeddingStrategy",
          "chunk",
          "crate::rag::EmbeddingStrategy",
          "embedding",
          "strategy",
          "this"
        ]
      },
      "embedding": null,
      "semantic_hash": "7b159afac30ef92e"
    },
    {
      "id": "chunk_17",
      "content": " Semantic information for enhanced retrieval.\n\nRagSemantics",
      "content_with_context": "// File: src/rag.rs\n// Module: crate::rag\n\n Semantic information for enhanced retrieval.\n\nRagSemantics\n// Complexity: 6",
      "metadata": {
        "file_path": "src/rag.rs",
        "start_line": 1,
        "end_line": 1,
        "element_type": "Struct",
        "element_name": "RagSemantics",
        "qualified_name": "crate::rag::RagSemantics",
        "visibility": "Public",
        "token_count": 15,
        "complexity": 6,
        "has_documentation": true,
        "documentation_quality": "Basic",
        "semantic_category": "data_structure",
        "domain_tags": [],
        "intent_tags": [
          "data_type"
        ],
        "references": [],
        "referenced_by": [],
        "parent_elements": [
          ""
        ],
        "child_elements": [],
        "embedding_strategy": "DocumentationOnly",
        "retrieval_keywords": [
          "RagSemantics",
          "crate::rag::RagSemantics",
          "enhanced",
          "information",
          "retrieval",
          "semantic"
        ]
      },
      "embedding": null,
      "semantic_hash": "93c1f78987c98bb0"
    },
    {
      "id": "chunk_18",
      "content": " A concept in the semantic hierarchy.\n\nConceptNode",
      "content_with_context": "// File: src/rag.rs\n// Module: crate::rag\n\n A concept in the semantic hierarchy.\n\nConceptNode\n// Complexity: 10",
      "metadata": {
        "file_path": "src/rag.rs",
        "start_line": 1,
        "end_line": 1,
        "element_type": "Struct",
        "element_name": "ConceptNode",
        "qualified_name": "crate::rag::ConceptNode",
        "visibility": "Public",
        "token_count": 13,
        "complexity": 10,
        "has_documentation": true,
        "documentation_quality": "Basic",
        "semantic_category": "data_structure",
        "domain_tags": [],
        "intent_tags": [
          "data_type"
        ],
        "references": [],
        "referenced_by": [],
        "parent_elements": [
          ""
        ],
        "child_elements": [],
        "embedding_strategy": "DocumentationOnly",
        "retrieval_keywords": [
          "ConceptNode",
          "concept",
          "crate::rag::ConceptNode",
          "hierarchy",
          "semantic"
        ]
      },
      "embedding": null,
      "semantic_hash": "5e09ded7cad2c515"
    },
    {
      "id": "chunk_19",
      "content": " Types of semantic concepts.\n\nConceptType",
      "content_with_context": "// File: src/rag.rs\n// Module: crate::rag\n\n Types of semantic concepts.\n\nConceptType\n// Complexity: 24",
      "metadata": {
        "file_path": "src/rag.rs",
        "start_line": 1,
        "end_line": 1,
        "element_type": "Enum",
        "element_name": "ConceptType",
        "qualified_name": "crate::rag::ConceptType",
        "visibility": "Public",
        "token_count": 11,
        "complexity": 24,
        "has_documentation": true,
        "documentation_quality": "Basic",
        "semantic_category": "data_structure",
        "domain_tags": [],
        "intent_tags": [
          "data_type"
        ],
        "references": [],
        "referenced_by": [],
        "parent_elements": [
          ""
        ],
        "child_elements": [],
        "embedding_strategy": "DocumentationOnly",
        "retrieval_keywords": [
          "ConceptType",
          "concepts",
          "crate::rag::ConceptType",
          "semantic",
          "types"
        ]
      },
      "embedding": null,
      "semantic_hash": "29eedc9debfc4232"
    },
    {
      "id": "chunk_20",
      "content": " Semantic relationship between code elements.\n\nSemanticRelationship",
      "content_with_context": "// File: src/rag.rs\n// Module: crate::rag\n\n Semantic relationship between code elements.\n\nSemanticRelationship\n// Complexity: 6",
      "metadata": {
        "file_path": "src/rag.rs",
        "start_line": 1,
        "end_line": 1,
        "element_type": "Struct",
        "element_name": "SemanticRelationship",
        "qualified_name": "crate::rag::SemanticRelationship",
        "visibility": "Public",
        "token_count": 17,
        "complexity": 6,
        "has_documentation": true,
        "documentation_quality": "Basic",
        "semantic_category": "data_structure",
        "domain_tags": [],
        "intent_tags": [
          "data_type"
        ],
        "references": [],
        "referenced_by": [],
        "parent_elements": [
          ""
        ],
        "child_elements": [],
        "embedding_strategy": "DocumentationOnly",
        "retrieval_keywords": [
          "SemanticRelationship",
          "between",
          "code",
          "crate::rag::SemanticRelationship",
          "elements",
          "relationship",
          "semantic"
        ]
      },
      "embedding": null,
      "semantic_hash": "c289adaf541c0819"
    },
    {
      "id": "chunk_21",
      "content": " Types of semantic relationships.\n\nRelationshipType",
      "content_with_context": "// File: src/rag.rs\n// Module: crate::rag\n\n Types of semantic relationships.\n\nRelationshipType\n// Complexity: 24",
      "metadata": {
        "file_path": "src/rag.rs",
        "start_line": 1,
        "end_line": 1,
        "element_type": "Enum",
        "element_name": "RelationshipType",
        "qualified_name": "crate::rag::RelationshipType",
        "visibility": "Public",
        "token_count": 13,
        "complexity": 24,
        "has_documentation": true,
        "documentation_quality": "Basic",
        "semantic_category": "data_structure",
        "domain_tags": [],
        "intent_tags": [
          "data_type"
        ],
        "references": [],
        "referenced_by": [],
        "parent_elements": [
          ""
        ],
        "child_elements": [],
        "embedding_strategy": "DocumentationOnly",
        "retrieval_keywords": [
          "RelationshipType",
          "crate::rag::RelationshipType",
          "relationships",
          "semantic",
          "types"
        ]
      },
      "embedding": null,
      "semantic_hash": "a5b029d512cfecb1"
    },
    {
      "id": "chunk_22",
      "content": " Entry in the domain vocabulary.\n\nVocabularyEntry",
      "content_with_context": "// File: src/rag.rs\n// Module: crate::rag\n\n Entry in the domain vocabulary.\n\nVocabularyEntry\n// Complexity: 9",
      "metadata": {
        "file_path": "src/rag.rs",
        "start_line": 1,
        "end_line": 1,
        "element_type": "Struct",
        "element_name": "VocabularyEntry",
        "qualified_name": "crate::rag::VocabularyEntry",
        "visibility": "Public",
        "token_count": 13,
        "complexity": 9,
        "has_documentation": true,
        "documentation_quality": "Basic",
        "semantic_category": "data_structure",
        "domain_tags": [],
        "intent_tags": [
          "data_type"
        ],
        "references": [],
        "referenced_by": [],
        "parent_elements": [
          ""
        ],
        "child_elements": [],
        "embedding_strategy": "DocumentationOnly",
        "retrieval_keywords": [
          "VocabularyEntry",
          "crate::rag::VocabularyEntry",
          "domain",
          "entry",
          "vocabulary"
        ]
      },
      "embedding": null,
      "semantic_hash": "45b3bcc11755ddd3"
    },
    {
      "id": "chunk_23",
      "content": " Identified code pattern or idiom.\n\nCodePattern",
      "content_with_context": "// File: src/rag.rs\n// Module: crate::rag\n\n Identified code pattern or idiom.\n\nCodePattern\n// Complexity: 9",
      "metadata": {
        "file_path": "src/rag.rs",
        "start_line": 1,
        "end_line": 1,
        "element_type": "Struct",
        "element_name": "CodePattern",
        "qualified_name": "crate::rag::CodePattern",
        "visibility": "Public",
        "token_count": 12,
        "complexity": 9,
        "has_documentation": true,
        "documentation_quality": "Basic",
        "semantic_category": "data_structure",
        "domain_tags": [],
        "intent_tags": [
          "data_type"
        ],
        "references": [],
        "referenced_by": [],
        "parent_elements": [
          ""
        ],
        "child_elements": [],
        "embedding_strategy": "DocumentationOnly",
        "retrieval_keywords": [
          "CodePattern",
          "code",
          "crate::rag::CodePattern",
          "identified",
          "idiom",
          "pattern"
        ]
      },
      "embedding": null,
      "semantic_hash": "15265019d6c29d85"
    },
    {
      "id": "chunk_24",
      "content": " Types of code patterns.\n\nPatternType",
      "content_with_context": "// File: src/rag.rs\n// Module: crate::rag\n\n Types of code patterns.\n\nPatternType\n// Complexity: 15",
      "metadata": {
        "file_path": "src/rag.rs",
        "start_line": 1,
        "end_line": 1,
        "element_type": "Enum",
        "element_name": "PatternType",
        "qualified_name": "crate::rag::PatternType",
        "visibility": "Public",
        "token_count": 10,
        "complexity": 15,
        "has_documentation": true,
        "documentation_quality": "Basic",
        "semantic_category": "data_structure",
        "domain_tags": [],
        "intent_tags": [
          "data_type"
        ],
        "references": [],
        "referenced_by": [],
        "parent_elements": [
          ""
        ],
        "child_elements": [],
        "embedding_strategy": "DocumentationOnly",
        "retrieval_keywords": [
          "PatternType",
          "code",
          "crate::rag::PatternType",
          "patterns",
          "types"
        ]
      },
      "embedding": null,
      "semantic_hash": "f1eae7550da13d2"
    },
    {
      "id": "chunk_25",
      "content": " Analysis of the public API surface.\n\nApiSurface",
      "content_with_context": "// File: src/rag.rs\n// Module: crate::rag\n\n Analysis of the public API surface.\n\nApiSurface\n// Complexity: 9",
      "metadata": {
        "file_path": "src/rag.rs",
        "start_line": 1,
        "end_line": 1,
        "element_type": "Struct",
        "element_name": "ApiSurface",
        "qualified_name": "crate::rag::ApiSurface",
        "visibility": "Public",
        "token_count": 12,
        "complexity": 9,
        "has_documentation": true,
        "documentation_quality": "Basic",
        "semantic_category": "data_structure",
        "domain_tags": [],
        "intent_tags": [
          "data_type"
        ],
        "references": [],
        "referenced_by": [],
        "parent_elements": [
          ""
        ],
        "child_elements": [],
        "embedding_strategy": "DocumentationOnly",
        "retrieval_keywords": [
          "ApiSurface",
          "analysis",
          "crate::rag::ApiSurface",
          "public",
          "surface"
        ]
      },
      "embedding": null,
      "semantic_hash": "8a4090c42860536b"
    },
    {
      "id": "chunk_26",
      "content": " A public API element.\n\nApiElement",
      "content_with_context": "// File: src/rag.rs\n// Module: crate::rag\n\n A public API element.\n\nApiElement\n// Complexity: 10",
      "metadata": {
        "file_path": "src/rag.rs",
        "start_line": 1,
        "end_line": 1,
        "element_type": "Struct",
        "element_name": "ApiElement",
        "qualified_name": "crate::rag::ApiElement",
        "visibility": "Public",
        "token_count": 9,
        "complexity": 10,
        "has_documentation": true,
        "documentation_quality": "Basic",
        "semantic_category": "data_structure",
        "domain_tags": [],
        "intent_tags": [
          "data_type"
        ],
        "references": [],
        "referenced_by": [],
        "parent_elements": [
          ""
        ],
        "child_elements": [],
        "embedding_strategy": "DocumentationOnly",
        "retrieval_keywords": [
          "ApiElement",
          "crate::rag::ApiElement",
          "element",
          "public"
        ]
      },
      "embedding": null,
      "semantic_hash": "57a035b88a66ab69"
    },
    {
      "id": "chunk_27",
      "content": " API stability assessment.\n\nApiStability",
      "content_with_context": "// File: src/rag.rs\n// Module: crate::rag\n\n API stability assessment.\n\nApiStability\n// Complexity: 12",
      "metadata": {
        "file_path": "src/rag.rs",
        "start_line": 1,
        "end_line": 1,
        "element_type": "Enum",
        "element_name": "ApiStability",
        "qualified_name": "crate::rag::ApiStability",
        "visibility": "Public",
        "token_count": 10,
        "complexity": 12,
        "has_documentation": true,
        "documentation_quality": "Basic",
        "semantic_category": "data_structure",
        "domain_tags": [],
        "intent_tags": [
          "data_type"
        ],
        "references": [],
        "referenced_by": [],
        "parent_elements": [
          ""
        ],
        "child_elements": [],
        "embedding_strategy": "DocumentationOnly",
        "retrieval_keywords": [
          "ApiStability",
          "assessment",
          "crate::rag::ApiStability",
          "stability"
        ]
      },
      "embedding": null,
      "semantic_hash": "77e53d9bc6672843"
    },
    {
      "id": "chunk_28",
      "content": " Metrics about API complexity.\n\nApiComplexityMetrics",
      "content_with_context": "// File: src/rag.rs\n// Module: crate::rag\n\n Metrics about API complexity.\n\nApiComplexityMetrics\n// Complexity: 6",
      "metadata": {
        "file_path": "src/rag.rs",
        "start_line": 1,
        "end_line": 1,
        "element_type": "Struct",
        "element_name": "ApiComplexityMetrics",
        "qualified_name": "crate::rag::ApiComplexityMetrics",
        "visibility": "Public",
        "token_count": 13,
        "complexity": 6,
        "has_documentation": true,
        "documentation_quality": "Basic",
        "semantic_category": "data_structure",
        "domain_tags": [],
        "intent_tags": [
          "data_type"
        ],
        "references": [],
        "referenced_by": [],
        "parent_elements": [
          ""
        ],
        "child_elements": [],
        "embedding_strategy": "DocumentationOnly",
        "retrieval_keywords": [
          "ApiComplexityMetrics",
          "about",
          "complexity",
          "crate::rag::ApiComplexityMetrics",
          "metrics"
        ]
      },
      "embedding": null,
      "semantic_hash": "5c375489690c7eb1"
    },
    {
      "id": "chunk_29",
      "content": " Training example for LLM fine-tuning.\n\nTrainingExample",
      "content_with_context": "// File: src/rag.rs\n// Module: crate::rag\n\n Training example for LLM fine-tuning.\n\nTrainingExample\n// Complexity: 9",
      "metadata": {
        "file_path": "src/rag.rs",
        "start_line": 1,
        "end_line": 1,
        "element_type": "Struct",
        "element_name": "TrainingExample",
        "qualified_name": "crate::rag::TrainingExample",
        "visibility": "Public",
        "token_count": 14,
        "complexity": 9,
        "has_documentation": true,
        "documentation_quality": "Basic",
        "semantic_category": "data_structure",
        "domain_tags": [],
        "intent_tags": [
          "data_type"
        ],
        "references": [],
        "referenced_by": [],
        "parent_elements": [
          ""
        ],
        "child_elements": [],
        "embedding_strategy": "DocumentationOnly",
        "retrieval_keywords": [
          "TrainingExample",
          "crate::rag::TrainingExample",
          "example",
          "fine-tuning",
          "training"
        ]
      },
      "embedding": null,
      "semantic_hash": "cab0b1b369019441"
    },
    {
      "id": "chunk_30",
      "content": " Types of training tasks.\n\nTaskType",
      "content_with_context": "// File: src/rag.rs\n// Module: crate::rag\n\n Types of training tasks.\n\nTaskType\n// Complexity: 24",
      "metadata": {
        "file_path": "src/rag.rs",
        "start_line": 1,
        "end_line": 1,
        "element_type": "Enum",
        "element_name": "TaskType",
        "qualified_name": "crate::rag::TaskType",
        "visibility": "Public",
        "token_count": 9,
        "complexity": 24,
        "has_documentation": true,
        "documentation_quality": "Basic",
        "semantic_category": "data_structure",
        "domain_tags": [],
        "intent_tags": [
          "data_type"
        ],
        "references": [],
        "referenced_by": [],
        "parent_elements": [
          ""
        ],
        "child_elements": [],
        "embedding_strategy": "DocumentationOnly",
        "retrieval_keywords": [
          "TaskType",
          "crate::rag::TaskType",
          "tasks",
          "training",
          "types"
        ]
      },
      "embedding": null,
      "semantic_hash": "49ea03bf2c81f7b5"
    },
    {
      "id": "chunk_31",
      "content": " Difficulty levels for training examples.\n\nDifficultyLevel",
      "content_with_context": "// File: src/rag.rs\n// Module: crate::rag\n\n Difficulty levels for training examples.\n\nDifficultyLevel\n// Complexity: 12",
      "metadata": {
        "file_path": "src/rag.rs",
        "start_line": 1,
        "end_line": 1,
        "element_type": "Enum",
        "element_name": "DifficultyLevel",
        "qualified_name": "crate::rag::DifficultyLevel",
        "visibility": "Public",
        "token_count": 15,
        "complexity": 12,
        "has_documentation": true,
        "documentation_quality": "Basic",
        "semantic_category": "data_structure",
        "domain_tags": [],
        "intent_tags": [
          "data_type"
        ],
        "references": [],
        "referenced_by": [],
        "parent_elements": [
          ""
        ],
        "child_elements": [],
        "embedding_strategy": "DocumentationOnly",
        "retrieval_keywords": [
          "DifficultyLevel",
          "crate::rag::DifficultyLevel",
          "difficulty",
          "examples",
          "levels",
          "training"
        ]
      },
      "embedding": null,
      "semantic_hash": "cfce17c1d252a8f5"
    },
    {
      "id": "chunk_32",
      "content": " Metadata for training examples.\n\nTrainingMetadata",
      "content_with_context": "// File: src/rag.rs\n// Module: crate::rag\n\n Metadata for training examples.\n\nTrainingMetadata\n// Complexity: 6",
      "metadata": {
        "file_path": "src/rag.rs",
        "start_line": 1,
        "end_line": 1,
        "element_type": "Struct",
        "element_name": "TrainingMetadata",
        "qualified_name": "crate::rag::TrainingMetadata",
        "visibility": "Public",
        "token_count": 13,
        "complexity": 6,
        "has_documentation": true,
        "documentation_quality": "Basic",
        "semantic_category": "data_structure",
        "domain_tags": [],
        "intent_tags": [
          "data_type"
        ],
        "references": [],
        "referenced_by": [],
        "parent_elements": [
          ""
        ],
        "child_elements": [],
        "embedding_strategy": "DocumentationOnly",
        "retrieval_keywords": [
          "TrainingMetadata",
          "crate::rag::TrainingMetadata",
          "examples",
          "metadata",
          "training"
        ]
      },
      "embedding": null,
      "semantic_hash": "eb94e05448d74d05"
    },
    {
      "id": "chunk_33",
      "content": " Configuration for RAG document generation.\n\nRagConfig",
      "content_with_context": "// File: src/rag.rs\n// Module: crate::rag\n\n Configuration for RAG document generation.\n\nRagConfig\n// Complexity: 16",
      "metadata": {
        "file_path": "src/rag.rs",
        "start_line": 1,
        "end_line": 1,
        "element_type": "Struct",
        "element_name": "RagConfig",
        "qualified_name": "crate::rag::RagConfig",
        "visibility": "Public",
        "token_count": 14,
        "complexity": 16,
        "has_documentation": true,
        "documentation_quality": "Basic",
        "semantic_category": "data_structure",
        "domain_tags": [],
        "intent_tags": [
          "data_type"
        ],
        "references": [],
        "referenced_by": [],
        "parent_elements": [
          ""
        ],
        "child_elements": [],
        "embedding_strategy": "DocumentationOnly",
        "retrieval_keywords": [
          "RagConfig",
          "configuration",
          "crate::rag::RagConfig",
          "document",
          "generation"
        ]
      },
      "embedding": null,
      "semantic_hash": "45aa2c74cdcb461f"
    },
    {
      "id": "chunk_34",
      "content": " Depth of semantic analysis to perform.\n\nSemanticDepth",
      "content_with_context": "// File: src/rag.rs\n// Module: crate::rag\n\n Depth of semantic analysis to perform.\n\nSemanticDepth\n// Complexity: 9",
      "metadata": {
        "file_path": "src/rag.rs",
        "start_line": 1,
        "end_line": 1,
        "element_type": "Enum",
        "element_name": "SemanticDepth",
        "qualified_name": "crate::rag::SemanticDepth",
        "visibility": "Public",
        "token_count": 14,
        "complexity": 9,
        "has_documentation": true,
        "documentation_quality": "Basic",
        "semantic_category": "data_structure",
        "domain_tags": [],
        "intent_tags": [
          "data_type"
        ],
        "references": [],
        "referenced_by": [],
        "parent_elements": [
          ""
        ],
        "child_elements": [],
        "embedding_strategy": "DocumentationOnly",
        "retrieval_keywords": [
          "SemanticDepth",
          "analysis",
          "crate::rag::SemanticDepth",
          "depth",
          "perform",
          "semantic"
        ]
      },
      "embedding": null,
      "semantic_hash": "923ddb13dee1506f"
    },
    {
      "id": "chunk_35",
      "content": " Main RAG formatter that converts ProjectAst to RAG format.\n\nRagFormatter",
      "content_with_context": "// File: src/rag.rs\n// Module: crate::rag\n\n Main RAG formatter that converts ProjectAst to RAG format.\n\nRagFormatter\n// Complexity: 2",
      "metadata": {
        "file_path": "src/rag.rs",
        "start_line": 1,
        "end_line": 1,
        "element_type": "Struct",
        "element_name": "RagFormatter",
        "qualified_name": "crate::rag::RagFormatter",
        "visibility": "Public",
        "token_count": 19,
        "complexity": 2,
        "has_documentation": true,
        "documentation_quality": "Basic",
        "semantic_category": "data_structure",
        "domain_tags": [],
        "intent_tags": [
          "data_type"
        ],
        "references": [],
        "referenced_by": [],
        "parent_elements": [
          ""
        ],
        "child_elements": [],
        "embedding_strategy": "DocumentationOnly",
        "retrieval_keywords": [
          "RagFormatter",
          "converts",
          "crate::rag::RagFormatter",
          "format",
          "formatter",
          "main",
          "projectast",
          "that"
        ]
      },
      "embedding": null,
      "semantic_hash": "ccbcb5fd86f05f40"
    },
    {
      "id": "chunk_36",
      "content": " Create a new RAG formatter with the given configuration.\n\n# [doc = \" Create a new RAG formatter with the given configuration.\"] pub fn new (config : RagConfig) -> Self { Self { config } } . sig",
      "content_with_context": "// File: src/rag.rs\n// Module: crate::rag\n\n Create a new RAG formatter with the given configuration.\n\n# [doc = \" Create a new RAG formatter with the given configuration.\"] pub fn new (config : RagConfig) -> Self { Self { config } } . sig\n// Complexity: 3",
      "metadata": {
        "file_path": "src/rag.rs",
        "start_line": 1,
        "end_line": 1,
        "element_type": "Function",
        "element_name": "new",
        "qualified_name": "Impl_impl impl RagFormatter { # [doc = \" Create a new RAG formatter with the given configuration.\"] pub fn new (config : RagConfig) -> Self { Self { config } } # [doc = \" Create a new RAG formatter with default configuration.\"] pub fn default () -> Self { Self { config : RagConfig :: default () , } } # [doc = \" Format a ProjectAst into RAG document format.\"] pub fn format (& self , project_ast : & ProjectAst) -> Result < RagDocument > { let metadata = self . build_metadata (project_ast) ? ; let chunks = self . create_chunks (project_ast) ? ; let semantics = self . analyze_semantics (project_ast , & chunks) ? ; let training_examples = if self . config . generate_training_examples { self . generate_training_examples (project_ast , & chunks) ? } else { Vec :: new () } ; Ok (RagDocument { metadata , chunks , semantics , training_examples , }) } # [doc = \" Build metadata for the RAG document.\"] fn build_metadata (& self , project_ast : & ProjectAst) -> Result < RagMetadata > { let mut element_distribution = HashMap :: new () ; let mut complexity_distribution = HashMap :: new () ; let mut total_tokens = 0 ; let mut token_sizes = Vec :: new () ; for file in & project_ast . files { for element in & file . elements { let element_type = format ! (\"{:?}\" , element . element_type) ; * element_distribution . entry (element_type) . or_insert (0) += 1 ; if let Some (complexity) = element . complexity { let complexity_level = match complexity { 0 ..= 2 => \"Simple\" , 3 ..= 5 => \"Moderate\" , 6 ..= 10 => \"Complex\" , _ => \"Very Complex\" , } ; * complexity_distribution . entry (complexity_level . to_string ()) . or_insert (0) += 1 ; } let content = self . build_element_content (element) ; let tokens = self . estimate_token_count (& content) ; total_tokens += tokens ; token_sizes . push (tokens) ; } } token_sizes . sort_unstable () ; let chunk_size_stats = ChunkSizeStats { min_tokens : token_sizes . first () . copied () . unwrap_or (0) , max_tokens : token_sizes . last () . copied () . unwrap_or (0) , avg_tokens : if ! token_sizes . is_empty () { token_sizes . iter () . sum :: < usize > () as f64 / token_sizes . len () as f64 } else { 0.0 } , median_tokens : if ! token_sizes . is_empty () { token_sizes [token_sizes . len () / 2] } else { 0 } , p95_tokens : if ! token_sizes . is_empty () { let p95_index = (token_sizes . len () as f64 * 0.95) as usize ; token_sizes [p95_index . min (token_sizes . len () - 1)] } else { 0 } , } ; Ok (RagMetadata { project_name : project_ast . project . name . clone () , project_version : project_ast . project . version . clone () , rust_edition : project_ast . project . rust_edition . clone () , total_chunks : token_sizes . len () , total_tokens , chunk_size_stats , element_distribution , complexity_distribution , semantic_categories : vec ! [\"function_definition\" . to_string () , \"data_structure\" . to_string () , \"trait_definition\" . to_string () , \"implementation\" . to_string () , \"module_organization\" . to_string () ,] , generated_at : chrono :: Utc :: now () . to_rfc3339 () , rustex_version : env ! (\"CARGO_PKG_VERSION\") . to_string () , chunk_strategy : \"semantic_boundaries\" . to_string () , }) } # [doc = \" Create optimized chunks from the project AST.\"] fn create_chunks (& self , project_ast : & ProjectAst) -> Result < Vec < RagChunk > > { let mut chunks = Vec :: new () ; let mut chunk_id = 0 ; for file in & project_ast . files { for element in & file . elements { if ! self . should_include_element (element) { continue ; } let content = self . build_element_content (element) ; let content_with_context = self . build_element_content_with_context (element , file) ; let metadata = self . build_chunk_metadata (element , file , & content) ? ; let semantic_hash = self . generate_semantic_hash (& content) ; chunk_id += 1 ; chunks . push (RagChunk { id : format ! (\"chunk_{}\" , chunk_id) , content , content_with_context , metadata , embedding : None , semantic_hash , }) ; } } Ok (chunks) } # [doc = \" Analyze semantic relationships and concepts.\"] fn analyze_semantics (& self , project_ast : & ProjectAst , chunks : & [RagChunk]) -> Result < RagSemantics > { let concept_hierarchy = self . extract_concept_hierarchy (project_ast) ? ; let relationships = self . extract_semantic_relationships (project_ast , chunks) ? ; let vocabulary = self . build_vocabulary (project_ast) ? ; let patterns = self . identify_code_patterns (project_ast) ? ; let api_surface = self . analyze_api_surface (project_ast) ? ; Ok (RagSemantics { concept_hierarchy , relationships , vocabulary , patterns , api_surface , }) } # [doc = \" Generate training examples for LLM fine-tuning.\"] fn generate_training_examples (& self , _project_ast : & ProjectAst , chunks : & [RagChunk]) -> Result < Vec < TrainingExample > > { let mut examples = Vec :: new () ; let mut example_id = 0 ; for chunk in chunks { let mut chunk_examples = 0 ; if chunk_examples < self . config . max_training_examples_per_chunk { if let Some (example) = self . create_code_explanation_example (chunk , & mut example_id) ? { examples . push (example) ; chunk_examples += 1 ; } } if chunk_examples < self . config . max_training_examples_per_chunk { if let Some (example) = self . create_code_completion_example (chunk , & mut example_id) ? { examples . push (example) ; chunk_examples += 1 ; } } if chunk_examples < self . config . max_training_examples_per_chunk { if let Some (example) = self . create_api_usage_example (chunk , & mut example_id) ? { examples . push (example) ; let _ = chunk_examples + 1 ; } } } Ok (examples) } # [doc = \" Check if an element should be included based on configuration.\"] fn should_include_element (& self , element : & CodeElement) -> bool { if ! self . config . include_private_items && element . visibility != Visibility :: Public { return false ; } if let Some (min_complexity) = self . config . min_complexity_for_inclusion { if element . complexity . unwrap_or (0) < min_complexity { return false ; } } if ! self . config . include_test_code { if element . name . contains (\"test\") || element . attributes . iter () . any (| attr | attr . contains (\"test\")) { return false ; } } true } # [doc = \" Build content string for an element.\"] fn build_element_content (& self , element : & CodeElement) -> String { let mut content = String :: new () ; if ! element . doc_comments . is_empty () { content . push_str (& element . doc_comments . join (\"\\n\")) ; content . push_str (\"\\n\\n\") ; } if let Some (signature) = & element . signature { content . push_str (signature) ; } else { content . push_str (& element . name) ; } content } # [doc = \" Build content with additional context.\"] fn build_element_content_with_context (& self , element : & CodeElement , file : & FileAst) -> String { let mut content = String :: new () ; content . push_str (& format ! (\"// File: {}\\n\" , file . relative_path . display ())) ; content . push_str (& format ! (\"// Module: {}\\n\\n\" , element . hierarchy . module_path)) ; content . push_str (& self . build_element_content (element)) ; if element . complexity . is_some () { content . push_str (& format ! (\"\\n// Complexity: {}\" , element . complexity . unwrap ())) ; } content } # [doc = \" Build metadata for a chunk.\"] fn build_chunk_metadata (& self , element : & CodeElement , file : & FileAst , content : & str) -> Result < ChunkMetadata > { let documentation_quality = self . assess_documentation_quality (element) ; let semantic_category = self . categorize_element (element) ; let domain_tags = self . extract_domain_tags (element) ; let intent_tags = self . extract_intent_tags (element) ; let embedding_strategy = self . determine_embedding_strategy (element) ; let retrieval_keywords = self . extract_retrieval_keywords (element) ; Ok (ChunkMetadata { file_path : file . relative_path . to_string_lossy () . to_string () , start_line : element . location . line_start as u32 , end_line : element . location . line_end as u32 , element_type : format ! (\"{:?}\" , element . element_type) , element_name : element . name . clone () , qualified_name : element . hierarchy . qualified_name . clone () , visibility : format ! (\"{:?}\" , element . visibility) , token_count : self . estimate_token_count (content) , complexity : element . complexity , has_documentation : ! element . doc_comments . is_empty () , documentation_quality , semantic_category , domain_tags , intent_tags , references : Vec :: new () , referenced_by : Vec :: new () , parent_elements : vec ! [element . hierarchy . parent_id . clone () . unwrap_or_default ()] , child_elements : element . hierarchy . children_ids . clone () , embedding_strategy , retrieval_keywords , }) } # [doc = \" Estimate token count for text (rough approximation).\"] fn estimate_token_count (& self , text : & str) -> usize { (text . len () as f64 / 4.0) . ceil () as usize } # [doc = \" Generate semantic hash for deduplication.\"] fn generate_semantic_hash (& self , content : & str) -> String { use std :: collections :: hash_map :: DefaultHasher ; use std :: hash :: { Hash , Hasher } ; let mut hasher = DefaultHasher :: new () ; content . hash (& mut hasher) ; format ! (\"{:x}\" , hasher . finish ()) } # [doc = \" Assess documentation quality.\"] fn assess_documentation_quality (& self , element : & CodeElement) -> DocumentationQuality { if element . doc_comments . is_empty () { return DocumentationQuality :: Missing ; } let doc_text = element . doc_comments . join (\" \") ; let has_examples = doc_text . contains (\"```\") || doc_text . contains (\"Example\") ; let has_details = doc_text . len () > 100 ; let has_params = doc_text . contains (\"# Arguments\") || doc_text . contains (\"Parameters\") ; match (has_examples , has_details , has_params) { (true , true , true) => DocumentationQuality :: Excellent , (_ , true , true) | (true , true , _) => DocumentationQuality :: Good , (_ , true , _) | (_ , _ , true) => DocumentationQuality :: Basic , _ => DocumentationQuality :: Basic , } } # [doc = \" Categorize element semantically.\"] fn categorize_element (& self , element : & CodeElement) -> String { match element . element_type { ElementType :: Function => \"function_definition\" . to_string () , ElementType :: Struct => \"data_structure\" . to_string () , ElementType :: Enum => \"data_structure\" . to_string () , ElementType :: Trait => \"trait_definition\" . to_string () , ElementType :: Impl => \"implementation\" . to_string () , ElementType :: Module => \"module_organization\" . to_string () , _ => \"other\" . to_string () , } } # [doc = \" Extract domain-specific tags.\"] fn extract_domain_tags (& self , element : & CodeElement) -> Vec < String > { let mut tags = Vec :: new () ; let name_lower = element . name . to_lowercase () ; if name_lower . contains (\"http\") || name_lower . contains (\"web\") { tags . push (\"web\" . to_string ()) ; } if name_lower . contains (\"db\") || name_lower . contains (\"database\") || name_lower . contains (\"sql\") { tags . push (\"database\" . to_string ()) ; } if name_lower . contains (\"async\") || name_lower . contains (\"future\") { tags . push (\"async\" . to_string ()) ; } if name_lower . contains (\"test\") { tags . push (\"testing\" . to_string ()) ; } tags } # [doc = \" Extract intent tags.\"] fn extract_intent_tags (& self , element : & CodeElement) -> Vec < String > { let mut tags = Vec :: new () ; match element . element_type { ElementType :: Function => { if element . name . starts_with (\"new\") { tags . push (\"constructor\" . to_string ()) ; } if element . name . starts_with (\"get\") || element . name . starts_with (\"is\") { tags . push (\"accessor\" . to_string ()) ; } if element . name . starts_with (\"set\") { tags . push (\"mutator\" . to_string ()) ; } } ElementType :: Trait => { tags . push (\"interface\" . to_string ()) ; } ElementType :: Struct | ElementType :: Enum => { tags . push (\"data_type\" . to_string ()) ; } _ => { } } tags } # [doc = \" Determine optimal embedding strategy.\"] fn determine_embedding_strategy (& self , element : & CodeElement) -> EmbeddingStrategy { if element . doc_comments . is_empty () { EmbeddingStrategy :: CodeOnly } else if element . signature . is_none () { EmbeddingStrategy :: DocumentationOnly } else { EmbeddingStrategy :: Combined } } # [doc = \" Extract keywords for retrieval.\"] fn extract_retrieval_keywords (& self , element : & CodeElement) -> Vec < String > { let mut keywords = Vec :: new () ; keywords . push (element . name . clone ()) ; keywords . push (element . hierarchy . qualified_name . clone ()) ; for doc in & element . doc_comments { let words : Vec < String > = doc . split_whitespace () . filter (| w | w . len () > 3 && ! w . starts_with (\"///\")) . map (| w | w . to_lowercase () . trim_matches (| c : char | ! c . is_alphanumeric ()) . to_string ()) . filter (| w | ! w . is_empty ()) . collect () ; keywords . extend (words) ; } keywords . sort () ; keywords . dedup () ; keywords . truncate (20) ; keywords } fn extract_concept_hierarchy (& self , _project_ast : & ProjectAst) -> Result < Vec < ConceptNode > > { Ok (Vec :: new ()) } fn extract_semantic_relationships (& self , _project_ast : & ProjectAst , _chunks : & [RagChunk]) -> Result < Vec < SemanticRelationship > > { Ok (Vec :: new ()) } fn build_vocabulary (& self , _project_ast : & ProjectAst) -> Result < HashMap < String , VocabularyEntry > > { Ok (HashMap :: new ()) } fn identify_code_patterns (& self , _project_ast : & ProjectAst) -> Result < Vec < CodePattern > > { Ok (Vec :: new ()) } fn analyze_api_surface (& self , project_ast : & ProjectAst) -> Result < ApiSurface > { let mut public_functions = Vec :: new () ; let mut public_types = Vec :: new () ; let mut public_traits = Vec :: new () ; let mut modules = Vec :: new () ; for file in & project_ast . files { for element in & file . elements { if element . visibility == Visibility :: Public { let api_element = ApiElement { name : element . name . clone () , qualified_name : element . hierarchy . qualified_name . clone () , element_type : format ! (\"{:?}\" , element . element_type) , signature : element . signature . clone () . unwrap_or_default () , documentation : element . doc_comments . join (\"\\n\") , chunk_id : format ! (\"chunk_{}\" , element . name) , stability : ApiStability :: Stable , usage_examples : Vec :: new () , } ; match element . element_type { ElementType :: Function => public_functions . push (api_element) , ElementType :: Struct | ElementType :: Enum => public_types . push (api_element) , ElementType :: Trait => public_traits . push (api_element) , ElementType :: Module => modules . push (api_element) , ElementType :: Impl => { } , _ => { } , } } } } let complexity_metrics = ApiComplexityMetrics { total_public_items : public_functions . len () + public_types . len () + public_traits . len () , avg_parameter_count : 0.0 , max_parameter_count : 0 , generic_usage_ratio : 0.0 , documentation_coverage : 0.0 , } ; Ok (ApiSurface { public_functions , public_types , public_traits , modules , entry_points : vec ! [\"main\" . to_string ()] , complexity_metrics , }) } fn create_code_explanation_example (& self , _chunk : & RagChunk , example_id : & mut usize) -> Result < Option < TrainingExample > > { * example_id += 1 ; Ok (None) } fn create_code_completion_example (& self , _chunk : & RagChunk , example_id : & mut usize) -> Result < Option < TrainingExample > > { * example_id += 1 ; Ok (None) } fn create_api_usage_example (& self , _chunk : & RagChunk , example_id : & mut usize) -> Result < Option < TrainingExample > > { * example_id += 1 ; Ok (None) } } . self_ty_28::new",
        "visibility": "Public",
        "token_count": 49,
        "complexity": 3,
        "has_documentation": true,
        "documentation_quality": "Basic",
        "semantic_category": "function_definition",
        "domain_tags": [],
        "intent_tags": [
          "constructor"
        ],
        "references": [],
        "referenced_by": [],
        "parent_elements": [
          "Impl_impl impl RagFormatter { # [doc = \" Create a new RAG formatter with the given configuration.\"] pub fn new (config : RagConfig) -> Self { Self { config } } # [doc = \" Create a new RAG formatter with default configuration.\"] pub fn default () -> Self { Self { config : RagConfig :: default () , } } # [doc = \" Format a ProjectAst into RAG document format.\"] pub fn format (& self , project_ast : & ProjectAst) -> Result < RagDocument > { let metadata = self . build_metadata (project_ast) ? ; let chunks = self . create_chunks (project_ast) ? ; let semantics = self . analyze_semantics (project_ast , & chunks) ? ; let training_examples = if self . config . generate_training_examples { self . generate_training_examples (project_ast , & chunks) ? } else { Vec :: new () } ; Ok (RagDocument { metadata , chunks , semantics , training_examples , }) } # [doc = \" Build metadata for the RAG document.\"] fn build_metadata (& self , project_ast : & ProjectAst) -> Result < RagMetadata > { let mut element_distribution = HashMap :: new () ; let mut complexity_distribution = HashMap :: new () ; let mut total_tokens = 0 ; let mut token_sizes = Vec :: new () ; for file in & project_ast . files { for element in & file . elements { let element_type = format ! (\"{:?}\" , element . element_type) ; * element_distribution . entry (element_type) . or_insert (0) += 1 ; if let Some (complexity) = element . complexity { let complexity_level = match complexity { 0 ..= 2 => \"Simple\" , 3 ..= 5 => \"Moderate\" , 6 ..= 10 => \"Complex\" , _ => \"Very Complex\" , } ; * complexity_distribution . entry (complexity_level . to_string ()) . or_insert (0) += 1 ; } let content = self . build_element_content (element) ; let tokens = self . estimate_token_count (& content) ; total_tokens += tokens ; token_sizes . push (tokens) ; } } token_sizes . sort_unstable () ; let chunk_size_stats = ChunkSizeStats { min_tokens : token_sizes . first () . copied () . unwrap_or (0) , max_tokens : token_sizes . last () . copied () . unwrap_or (0) , avg_tokens : if ! token_sizes . is_empty () { token_sizes . iter () . sum :: < usize > () as f64 / token_sizes . len () as f64 } else { 0.0 } , median_tokens : if ! token_sizes . is_empty () { token_sizes [token_sizes . len () / 2] } else { 0 } , p95_tokens : if ! token_sizes . is_empty () { let p95_index = (token_sizes . len () as f64 * 0.95) as usize ; token_sizes [p95_index . min (token_sizes . len () - 1)] } else { 0 } , } ; Ok (RagMetadata { project_name : project_ast . project . name . clone () , project_version : project_ast . project . version . clone () , rust_edition : project_ast . project . rust_edition . clone () , total_chunks : token_sizes . len () , total_tokens , chunk_size_stats , element_distribution , complexity_distribution , semantic_categories : vec ! [\"function_definition\" . to_string () , \"data_structure\" . to_string () , \"trait_definition\" . to_string () , \"implementation\" . to_string () , \"module_organization\" . to_string () ,] , generated_at : chrono :: Utc :: now () . to_rfc3339 () , rustex_version : env ! (\"CARGO_PKG_VERSION\") . to_string () , chunk_strategy : \"semantic_boundaries\" . to_string () , }) } # [doc = \" Create optimized chunks from the project AST.\"] fn create_chunks (& self , project_ast : & ProjectAst) -> Result < Vec < RagChunk > > { let mut chunks = Vec :: new () ; let mut chunk_id = 0 ; for file in & project_ast . files { for element in & file . elements { if ! self . should_include_element (element) { continue ; } let content = self . build_element_content (element) ; let content_with_context = self . build_element_content_with_context (element , file) ; let metadata = self . build_chunk_metadata (element , file , & content) ? ; let semantic_hash = self . generate_semantic_hash (& content) ; chunk_id += 1 ; chunks . push (RagChunk { id : format ! (\"chunk_{}\" , chunk_id) , content , content_with_context , metadata , embedding : None , semantic_hash , }) ; } } Ok (chunks) } # [doc = \" Analyze semantic relationships and concepts.\"] fn analyze_semantics (& self , project_ast : & ProjectAst , chunks : & [RagChunk]) -> Result < RagSemantics > { let concept_hierarchy = self . extract_concept_hierarchy (project_ast) ? ; let relationships = self . extract_semantic_relationships (project_ast , chunks) ? ; let vocabulary = self . build_vocabulary (project_ast) ? ; let patterns = self . identify_code_patterns (project_ast) ? ; let api_surface = self . analyze_api_surface (project_ast) ? ; Ok (RagSemantics { concept_hierarchy , relationships , vocabulary , patterns , api_surface , }) } # [doc = \" Generate training examples for LLM fine-tuning.\"] fn generate_training_examples (& self , _project_ast : & ProjectAst , chunks : & [RagChunk]) -> Result < Vec < TrainingExample > > { let mut examples = Vec :: new () ; let mut example_id = 0 ; for chunk in chunks { let mut chunk_examples = 0 ; if chunk_examples < self . config . max_training_examples_per_chunk { if let Some (example) = self . create_code_explanation_example (chunk , & mut example_id) ? { examples . push (example) ; chunk_examples += 1 ; } } if chunk_examples < self . config . max_training_examples_per_chunk { if let Some (example) = self . create_code_completion_example (chunk , & mut example_id) ? { examples . push (example) ; chunk_examples += 1 ; } } if chunk_examples < self . config . max_training_examples_per_chunk { if let Some (example) = self . create_api_usage_example (chunk , & mut example_id) ? { examples . push (example) ; let _ = chunk_examples + 1 ; } } } Ok (examples) } # [doc = \" Check if an element should be included based on configuration.\"] fn should_include_element (& self , element : & CodeElement) -> bool { if ! self . config . include_private_items && element . visibility != Visibility :: Public { return false ; } if let Some (min_complexity) = self . config . min_complexity_for_inclusion { if element . complexity . unwrap_or (0) < min_complexity { return false ; } } if ! self . config . include_test_code { if element . name . contains (\"test\") || element . attributes . iter () . any (| attr | attr . contains (\"test\")) { return false ; } } true } # [doc = \" Build content string for an element.\"] fn build_element_content (& self , element : & CodeElement) -> String { let mut content = String :: new () ; if ! element . doc_comments . is_empty () { content . push_str (& element . doc_comments . join (\"\\n\")) ; content . push_str (\"\\n\\n\") ; } if let Some (signature) = & element . signature { content . push_str (signature) ; } else { content . push_str (& element . name) ; } content } # [doc = \" Build content with additional context.\"] fn build_element_content_with_context (& self , element : & CodeElement , file : & FileAst) -> String { let mut content = String :: new () ; content . push_str (& format ! (\"// File: {}\\n\" , file . relative_path . display ())) ; content . push_str (& format ! (\"// Module: {}\\n\\n\" , element . hierarchy . module_path)) ; content . push_str (& self . build_element_content (element)) ; if element . complexity . is_some () { content . push_str (& format ! (\"\\n// Complexity: {}\" , element . complexity . unwrap ())) ; } content } # [doc = \" Build metadata for a chunk.\"] fn build_chunk_metadata (& self , element : & CodeElement , file : & FileAst , content : & str) -> Result < ChunkMetadata > { let documentation_quality = self . assess_documentation_quality (element) ; let semantic_category = self . categorize_element (element) ; let domain_tags = self . extract_domain_tags (element) ; let intent_tags = self . extract_intent_tags (element) ; let embedding_strategy = self . determine_embedding_strategy (element) ; let retrieval_keywords = self . extract_retrieval_keywords (element) ; Ok (ChunkMetadata { file_path : file . relative_path . to_string_lossy () . to_string () , start_line : element . location . line_start as u32 , end_line : element . location . line_end as u32 , element_type : format ! (\"{:?}\" , element . element_type) , element_name : element . name . clone () , qualified_name : element . hierarchy . qualified_name . clone () , visibility : format ! (\"{:?}\" , element . visibility) , token_count : self . estimate_token_count (content) , complexity : element . complexity , has_documentation : ! element . doc_comments . is_empty () , documentation_quality , semantic_category , domain_tags , intent_tags , references : Vec :: new () , referenced_by : Vec :: new () , parent_elements : vec ! [element . hierarchy . parent_id . clone () . unwrap_or_default ()] , child_elements : element . hierarchy . children_ids . clone () , embedding_strategy , retrieval_keywords , }) } # [doc = \" Estimate token count for text (rough approximation).\"] fn estimate_token_count (& self , text : & str) -> usize { (text . len () as f64 / 4.0) . ceil () as usize } # [doc = \" Generate semantic hash for deduplication.\"] fn generate_semantic_hash (& self , content : & str) -> String { use std :: collections :: hash_map :: DefaultHasher ; use std :: hash :: { Hash , Hasher } ; let mut hasher = DefaultHasher :: new () ; content . hash (& mut hasher) ; format ! (\"{:x}\" , hasher . finish ()) } # [doc = \" Assess documentation quality.\"] fn assess_documentation_quality (& self , element : & CodeElement) -> DocumentationQuality { if element . doc_comments . is_empty () { return DocumentationQuality :: Missing ; } let doc_text = element . doc_comments . join (\" \") ; let has_examples = doc_text . contains (\"```\") || doc_text . contains (\"Example\") ; let has_details = doc_text . len () > 100 ; let has_params = doc_text . contains (\"# Arguments\") || doc_text . contains (\"Parameters\") ; match (has_examples , has_details , has_params) { (true , true , true) => DocumentationQuality :: Excellent , (_ , true , true) | (true , true , _) => DocumentationQuality :: Good , (_ , true , _) | (_ , _ , true) => DocumentationQuality :: Basic , _ => DocumentationQuality :: Basic , } } # [doc = \" Categorize element semantically.\"] fn categorize_element (& self , element : & CodeElement) -> String { match element . element_type { ElementType :: Function => \"function_definition\" . to_string () , ElementType :: Struct => \"data_structure\" . to_string () , ElementType :: Enum => \"data_structure\" . to_string () , ElementType :: Trait => \"trait_definition\" . to_string () , ElementType :: Impl => \"implementation\" . to_string () , ElementType :: Module => \"module_organization\" . to_string () , _ => \"other\" . to_string () , } } # [doc = \" Extract domain-specific tags.\"] fn extract_domain_tags (& self , element : & CodeElement) -> Vec < String > { let mut tags = Vec :: new () ; let name_lower = element . name . to_lowercase () ; if name_lower . contains (\"http\") || name_lower . contains (\"web\") { tags . push (\"web\" . to_string ()) ; } if name_lower . contains (\"db\") || name_lower . contains (\"database\") || name_lower . contains (\"sql\") { tags . push (\"database\" . to_string ()) ; } if name_lower . contains (\"async\") || name_lower . contains (\"future\") { tags . push (\"async\" . to_string ()) ; } if name_lower . contains (\"test\") { tags . push (\"testing\" . to_string ()) ; } tags } # [doc = \" Extract intent tags.\"] fn extract_intent_tags (& self , element : & CodeElement) -> Vec < String > { let mut tags = Vec :: new () ; match element . element_type { ElementType :: Function => { if element . name . starts_with (\"new\") { tags . push (\"constructor\" . to_string ()) ; } if element . name . starts_with (\"get\") || element . name . starts_with (\"is\") { tags . push (\"accessor\" . to_string ()) ; } if element . name . starts_with (\"set\") { tags . push (\"mutator\" . to_string ()) ; } } ElementType :: Trait => { tags . push (\"interface\" . to_string ()) ; } ElementType :: Struct | ElementType :: Enum => { tags . push (\"data_type\" . to_string ()) ; } _ => { } } tags } # [doc = \" Determine optimal embedding strategy.\"] fn determine_embedding_strategy (& self , element : & CodeElement) -> EmbeddingStrategy { if element . doc_comments . is_empty () { EmbeddingStrategy :: CodeOnly } else if element . signature . is_none () { EmbeddingStrategy :: DocumentationOnly } else { EmbeddingStrategy :: Combined } } # [doc = \" Extract keywords for retrieval.\"] fn extract_retrieval_keywords (& self , element : & CodeElement) -> Vec < String > { let mut keywords = Vec :: new () ; keywords . push (element . name . clone ()) ; keywords . push (element . hierarchy . qualified_name . clone ()) ; for doc in & element . doc_comments { let words : Vec < String > = doc . split_whitespace () . filter (| w | w . len () > 3 && ! w . starts_with (\"///\")) . map (| w | w . to_lowercase () . trim_matches (| c : char | ! c . is_alphanumeric ()) . to_string ()) . filter (| w | ! w . is_empty ()) . collect () ; keywords . extend (words) ; } keywords . sort () ; keywords . dedup () ; keywords . truncate (20) ; keywords } fn extract_concept_hierarchy (& self , _project_ast : & ProjectAst) -> Result < Vec < ConceptNode > > { Ok (Vec :: new ()) } fn extract_semantic_relationships (& self , _project_ast : & ProjectAst , _chunks : & [RagChunk]) -> Result < Vec < SemanticRelationship > > { Ok (Vec :: new ()) } fn build_vocabulary (& self , _project_ast : & ProjectAst) -> Result < HashMap < String , VocabularyEntry > > { Ok (HashMap :: new ()) } fn identify_code_patterns (& self , _project_ast : & ProjectAst) -> Result < Vec < CodePattern > > { Ok (Vec :: new ()) } fn analyze_api_surface (& self , project_ast : & ProjectAst) -> Result < ApiSurface > { let mut public_functions = Vec :: new () ; let mut public_types = Vec :: new () ; let mut public_traits = Vec :: new () ; let mut modules = Vec :: new () ; for file in & project_ast . files { for element in & file . elements { if element . visibility == Visibility :: Public { let api_element = ApiElement { name : element . name . clone () , qualified_name : element . hierarchy . qualified_name . clone () , element_type : format ! (\"{:?}\" , element . element_type) , signature : element . signature . clone () . unwrap_or_default () , documentation : element . doc_comments . join (\"\\n\") , chunk_id : format ! (\"chunk_{}\" , element . name) , stability : ApiStability :: Stable , usage_examples : Vec :: new () , } ; match element . element_type { ElementType :: Function => public_functions . push (api_element) , ElementType :: Struct | ElementType :: Enum => public_types . push (api_element) , ElementType :: Trait => public_traits . push (api_element) , ElementType :: Module => modules . push (api_element) , ElementType :: Impl => { } , _ => { } , } } } } let complexity_metrics = ApiComplexityMetrics { total_public_items : public_functions . len () + public_types . len () + public_traits . len () , avg_parameter_count : 0.0 , max_parameter_count : 0 , generic_usage_ratio : 0.0 , documentation_coverage : 0.0 , } ; Ok (ApiSurface { public_functions , public_types , public_traits , modules , entry_points : vec ! [\"main\" . to_string ()] , complexity_metrics , }) } fn create_code_explanation_example (& self , _chunk : & RagChunk , example_id : & mut usize) -> Result < Option < TrainingExample > > { * example_id += 1 ; Ok (None) } fn create_code_completion_example (& self , _chunk : & RagChunk , example_id : & mut usize) -> Result < Option < TrainingExample > > { * example_id += 1 ; Ok (None) } fn create_api_usage_example (& self , _chunk : & RagChunk , example_id : & mut usize) -> Result < Option < TrainingExample > > { * example_id += 1 ; Ok (None) } } . self_ty_28"
        ],
        "child_elements": [],
        "embedding_strategy": "Combined",
        "retrieval_keywords": [
          "Impl_impl impl RagFormatter { # [doc = \" Create a new RAG formatter with the given configuration.\"] pub fn new (config : RagConfig) -> Self { Self { config } } # [doc = \" Create a new RAG formatter with default configuration.\"] pub fn default () -> Self { Self { config : RagConfig :: default () , } } # [doc = \" Format a ProjectAst into RAG document format.\"] pub fn format (& self , project_ast : & ProjectAst) -> Result < RagDocument > { let metadata = self . build_metadata (project_ast) ? ; let chunks = self . create_chunks (project_ast) ? ; let semantics = self . analyze_semantics (project_ast , & chunks) ? ; let training_examples = if self . config . generate_training_examples { self . generate_training_examples (project_ast , & chunks) ? } else { Vec :: new () } ; Ok (RagDocument { metadata , chunks , semantics , training_examples , }) } # [doc = \" Build metadata for the RAG document.\"] fn build_metadata (& self , project_ast : & ProjectAst) -> Result < RagMetadata > { let mut element_distribution = HashMap :: new () ; let mut complexity_distribution = HashMap :: new () ; let mut total_tokens = 0 ; let mut token_sizes = Vec :: new () ; for file in & project_ast . files { for element in & file . elements { let element_type = format ! (\"{:?}\" , element . element_type) ; * element_distribution . entry (element_type) . or_insert (0) += 1 ; if let Some (complexity) = element . complexity { let complexity_level = match complexity { 0 ..= 2 => \"Simple\" , 3 ..= 5 => \"Moderate\" , 6 ..= 10 => \"Complex\" , _ => \"Very Complex\" , } ; * complexity_distribution . entry (complexity_level . to_string ()) . or_insert (0) += 1 ; } let content = self . build_element_content (element) ; let tokens = self . estimate_token_count (& content) ; total_tokens += tokens ; token_sizes . push (tokens) ; } } token_sizes . sort_unstable () ; let chunk_size_stats = ChunkSizeStats { min_tokens : token_sizes . first () . copied () . unwrap_or (0) , max_tokens : token_sizes . last () . copied () . unwrap_or (0) , avg_tokens : if ! token_sizes . is_empty () { token_sizes . iter () . sum :: < usize > () as f64 / token_sizes . len () as f64 } else { 0.0 } , median_tokens : if ! token_sizes . is_empty () { token_sizes [token_sizes . len () / 2] } else { 0 } , p95_tokens : if ! token_sizes . is_empty () { let p95_index = (token_sizes . len () as f64 * 0.95) as usize ; token_sizes [p95_index . min (token_sizes . len () - 1)] } else { 0 } , } ; Ok (RagMetadata { project_name : project_ast . project . name . clone () , project_version : project_ast . project . version . clone () , rust_edition : project_ast . project . rust_edition . clone () , total_chunks : token_sizes . len () , total_tokens , chunk_size_stats , element_distribution , complexity_distribution , semantic_categories : vec ! [\"function_definition\" . to_string () , \"data_structure\" . to_string () , \"trait_definition\" . to_string () , \"implementation\" . to_string () , \"module_organization\" . to_string () ,] , generated_at : chrono :: Utc :: now () . to_rfc3339 () , rustex_version : env ! (\"CARGO_PKG_VERSION\") . to_string () , chunk_strategy : \"semantic_boundaries\" . to_string () , }) } # [doc = \" Create optimized chunks from the project AST.\"] fn create_chunks (& self , project_ast : & ProjectAst) -> Result < Vec < RagChunk > > { let mut chunks = Vec :: new () ; let mut chunk_id = 0 ; for file in & project_ast . files { for element in & file . elements { if ! self . should_include_element (element) { continue ; } let content = self . build_element_content (element) ; let content_with_context = self . build_element_content_with_context (element , file) ; let metadata = self . build_chunk_metadata (element , file , & content) ? ; let semantic_hash = self . generate_semantic_hash (& content) ; chunk_id += 1 ; chunks . push (RagChunk { id : format ! (\"chunk_{}\" , chunk_id) , content , content_with_context , metadata , embedding : None , semantic_hash , }) ; } } Ok (chunks) } # [doc = \" Analyze semantic relationships and concepts.\"] fn analyze_semantics (& self , project_ast : & ProjectAst , chunks : & [RagChunk]) -> Result < RagSemantics > { let concept_hierarchy = self . extract_concept_hierarchy (project_ast) ? ; let relationships = self . extract_semantic_relationships (project_ast , chunks) ? ; let vocabulary = self . build_vocabulary (project_ast) ? ; let patterns = self . identify_code_patterns (project_ast) ? ; let api_surface = self . analyze_api_surface (project_ast) ? ; Ok (RagSemantics { concept_hierarchy , relationships , vocabulary , patterns , api_surface , }) } # [doc = \" Generate training examples for LLM fine-tuning.\"] fn generate_training_examples (& self , _project_ast : & ProjectAst , chunks : & [RagChunk]) -> Result < Vec < TrainingExample > > { let mut examples = Vec :: new () ; let mut example_id = 0 ; for chunk in chunks { let mut chunk_examples = 0 ; if chunk_examples < self . config . max_training_examples_per_chunk { if let Some (example) = self . create_code_explanation_example (chunk , & mut example_id) ? { examples . push (example) ; chunk_examples += 1 ; } } if chunk_examples < self . config . max_training_examples_per_chunk { if let Some (example) = self . create_code_completion_example (chunk , & mut example_id) ? { examples . push (example) ; chunk_examples += 1 ; } } if chunk_examples < self . config . max_training_examples_per_chunk { if let Some (example) = self . create_api_usage_example (chunk , & mut example_id) ? { examples . push (example) ; let _ = chunk_examples + 1 ; } } } Ok (examples) } # [doc = \" Check if an element should be included based on configuration.\"] fn should_include_element (& self , element : & CodeElement) -> bool { if ! self . config . include_private_items && element . visibility != Visibility :: Public { return false ; } if let Some (min_complexity) = self . config . min_complexity_for_inclusion { if element . complexity . unwrap_or (0) < min_complexity { return false ; } } if ! self . config . include_test_code { if element . name . contains (\"test\") || element . attributes . iter () . any (| attr | attr . contains (\"test\")) { return false ; } } true } # [doc = \" Build content string for an element.\"] fn build_element_content (& self , element : & CodeElement) -> String { let mut content = String :: new () ; if ! element . doc_comments . is_empty () { content . push_str (& element . doc_comments . join (\"\\n\")) ; content . push_str (\"\\n\\n\") ; } if let Some (signature) = & element . signature { content . push_str (signature) ; } else { content . push_str (& element . name) ; } content } # [doc = \" Build content with additional context.\"] fn build_element_content_with_context (& self , element : & CodeElement , file : & FileAst) -> String { let mut content = String :: new () ; content . push_str (& format ! (\"// File: {}\\n\" , file . relative_path . display ())) ; content . push_str (& format ! (\"// Module: {}\\n\\n\" , element . hierarchy . module_path)) ; content . push_str (& self . build_element_content (element)) ; if element . complexity . is_some () { content . push_str (& format ! (\"\\n// Complexity: {}\" , element . complexity . unwrap ())) ; } content } # [doc = \" Build metadata for a chunk.\"] fn build_chunk_metadata (& self , element : & CodeElement , file : & FileAst , content : & str) -> Result < ChunkMetadata > { let documentation_quality = self . assess_documentation_quality (element) ; let semantic_category = self . categorize_element (element) ; let domain_tags = self . extract_domain_tags (element) ; let intent_tags = self . extract_intent_tags (element) ; let embedding_strategy = self . determine_embedding_strategy (element) ; let retrieval_keywords = self . extract_retrieval_keywords (element) ; Ok (ChunkMetadata { file_path : file . relative_path . to_string_lossy () . to_string () , start_line : element . location . line_start as u32 , end_line : element . location . line_end as u32 , element_type : format ! (\"{:?}\" , element . element_type) , element_name : element . name . clone () , qualified_name : element . hierarchy . qualified_name . clone () , visibility : format ! (\"{:?}\" , element . visibility) , token_count : self . estimate_token_count (content) , complexity : element . complexity , has_documentation : ! element . doc_comments . is_empty () , documentation_quality , semantic_category , domain_tags , intent_tags , references : Vec :: new () , referenced_by : Vec :: new () , parent_elements : vec ! [element . hierarchy . parent_id . clone () . unwrap_or_default ()] , child_elements : element . hierarchy . children_ids . clone () , embedding_strategy , retrieval_keywords , }) } # [doc = \" Estimate token count for text (rough approximation).\"] fn estimate_token_count (& self , text : & str) -> usize { (text . len () as f64 / 4.0) . ceil () as usize } # [doc = \" Generate semantic hash for deduplication.\"] fn generate_semantic_hash (& self , content : & str) -> String { use std :: collections :: hash_map :: DefaultHasher ; use std :: hash :: { Hash , Hasher } ; let mut hasher = DefaultHasher :: new () ; content . hash (& mut hasher) ; format ! (\"{:x}\" , hasher . finish ()) } # [doc = \" Assess documentation quality.\"] fn assess_documentation_quality (& self , element : & CodeElement) -> DocumentationQuality { if element . doc_comments . is_empty () { return DocumentationQuality :: Missing ; } let doc_text = element . doc_comments . join (\" \") ; let has_examples = doc_text . contains (\"```\") || doc_text . contains (\"Example\") ; let has_details = doc_text . len () > 100 ; let has_params = doc_text . contains (\"# Arguments\") || doc_text . contains (\"Parameters\") ; match (has_examples , has_details , has_params) { (true , true , true) => DocumentationQuality :: Excellent , (_ , true , true) | (true , true , _) => DocumentationQuality :: Good , (_ , true , _) | (_ , _ , true) => DocumentationQuality :: Basic , _ => DocumentationQuality :: Basic , } } # [doc = \" Categorize element semantically.\"] fn categorize_element (& self , element : & CodeElement) -> String { match element . element_type { ElementType :: Function => \"function_definition\" . to_string () , ElementType :: Struct => \"data_structure\" . to_string () , ElementType :: Enum => \"data_structure\" . to_string () , ElementType :: Trait => \"trait_definition\" . to_string () , ElementType :: Impl => \"implementation\" . to_string () , ElementType :: Module => \"module_organization\" . to_string () , _ => \"other\" . to_string () , } } # [doc = \" Extract domain-specific tags.\"] fn extract_domain_tags (& self , element : & CodeElement) -> Vec < String > { let mut tags = Vec :: new () ; let name_lower = element . name . to_lowercase () ; if name_lower . contains (\"http\") || name_lower . contains (\"web\") { tags . push (\"web\" . to_string ()) ; } if name_lower . contains (\"db\") || name_lower . contains (\"database\") || name_lower . contains (\"sql\") { tags . push (\"database\" . to_string ()) ; } if name_lower . contains (\"async\") || name_lower . contains (\"future\") { tags . push (\"async\" . to_string ()) ; } if name_lower . contains (\"test\") { tags . push (\"testing\" . to_string ()) ; } tags } # [doc = \" Extract intent tags.\"] fn extract_intent_tags (& self , element : & CodeElement) -> Vec < String > { let mut tags = Vec :: new () ; match element . element_type { ElementType :: Function => { if element . name . starts_with (\"new\") { tags . push (\"constructor\" . to_string ()) ; } if element . name . starts_with (\"get\") || element . name . starts_with (\"is\") { tags . push (\"accessor\" . to_string ()) ; } if element . name . starts_with (\"set\") { tags . push (\"mutator\" . to_string ()) ; } } ElementType :: Trait => { tags . push (\"interface\" . to_string ()) ; } ElementType :: Struct | ElementType :: Enum => { tags . push (\"data_type\" . to_string ()) ; } _ => { } } tags } # [doc = \" Determine optimal embedding strategy.\"] fn determine_embedding_strategy (& self , element : & CodeElement) -> EmbeddingStrategy { if element . doc_comments . is_empty () { EmbeddingStrategy :: CodeOnly } else if element . signature . is_none () { EmbeddingStrategy :: DocumentationOnly } else { EmbeddingStrategy :: Combined } } # [doc = \" Extract keywords for retrieval.\"] fn extract_retrieval_keywords (& self , element : & CodeElement) -> Vec < String > { let mut keywords = Vec :: new () ; keywords . push (element . name . clone ()) ; keywords . push (element . hierarchy . qualified_name . clone ()) ; for doc in & element . doc_comments { let words : Vec < String > = doc . split_whitespace () . filter (| w | w . len () > 3 && ! w . starts_with (\"///\")) . map (| w | w . to_lowercase () . trim_matches (| c : char | ! c . is_alphanumeric ()) . to_string ()) . filter (| w | ! w . is_empty ()) . collect () ; keywords . extend (words) ; } keywords . sort () ; keywords . dedup () ; keywords . truncate (20) ; keywords } fn extract_concept_hierarchy (& self , _project_ast : & ProjectAst) -> Result < Vec < ConceptNode > > { Ok (Vec :: new ()) } fn extract_semantic_relationships (& self , _project_ast : & ProjectAst , _chunks : & [RagChunk]) -> Result < Vec < SemanticRelationship > > { Ok (Vec :: new ()) } fn build_vocabulary (& self , _project_ast : & ProjectAst) -> Result < HashMap < String , VocabularyEntry > > { Ok (HashMap :: new ()) } fn identify_code_patterns (& self , _project_ast : & ProjectAst) -> Result < Vec < CodePattern > > { Ok (Vec :: new ()) } fn analyze_api_surface (& self , project_ast : & ProjectAst) -> Result < ApiSurface > { let mut public_functions = Vec :: new () ; let mut public_types = Vec :: new () ; let mut public_traits = Vec :: new () ; let mut modules = Vec :: new () ; for file in & project_ast . files { for element in & file . elements { if element . visibility == Visibility :: Public { let api_element = ApiElement { name : element . name . clone () , qualified_name : element . hierarchy . qualified_name . clone () , element_type : format ! (\"{:?}\" , element . element_type) , signature : element . signature . clone () . unwrap_or_default () , documentation : element . doc_comments . join (\"\\n\") , chunk_id : format ! (\"chunk_{}\" , element . name) , stability : ApiStability :: Stable , usage_examples : Vec :: new () , } ; match element . element_type { ElementType :: Function => public_functions . push (api_element) , ElementType :: Struct | ElementType :: Enum => public_types . push (api_element) , ElementType :: Trait => public_traits . push (api_element) , ElementType :: Module => modules . push (api_element) , ElementType :: Impl => { } , _ => { } , } } } } let complexity_metrics = ApiComplexityMetrics { total_public_items : public_functions . len () + public_types . len () + public_traits . len () , avg_parameter_count : 0.0 , max_parameter_count : 0 , generic_usage_ratio : 0.0 , documentation_coverage : 0.0 , } ; Ok (ApiSurface { public_functions , public_types , public_traits , modules , entry_points : vec ! [\"main\" . to_string ()] , complexity_metrics , }) } fn create_code_explanation_example (& self , _chunk : & RagChunk , example_id : & mut usize) -> Result < Option < TrainingExample > > { * example_id += 1 ; Ok (None) } fn create_code_completion_example (& self , _chunk : & RagChunk , example_id : & mut usize) -> Result < Option < TrainingExample > > { * example_id += 1 ; Ok (None) } fn create_api_usage_example (& self , _chunk : & RagChunk , example_id : & mut usize) -> Result < Option < TrainingExample > > { * example_id += 1 ; Ok (None) } } . self_ty_28::new",
          "configuration",
          "create",
          "formatter",
          "given",
          "new",
          "with"
        ]
      },
      "embedding": null,
      "semantic_hash": "52146369cd2136d4"
    },
    {
      "id": "chunk_37",
      "content": " Create a new RAG formatter with default configuration.\n\n# [doc = \" Create a new RAG formatter with default configuration.\"] pub fn default () -> Self { Self { config : RagConfig :: default () , } } . sig",
      "content_with_context": "// File: src/rag.rs\n// Module: crate::rag\n\n Create a new RAG formatter with default configuration.\n\n# [doc = \" Create a new RAG formatter with default configuration.\"] pub fn default () -> Self { Self { config : RagConfig :: default () , } } . sig\n// Complexity: 3",
      "metadata": {
        "file_path": "src/rag.rs",
        "start_line": 1,
        "end_line": 1,
        "element_type": "Function",
        "element_name": "default",
        "qualified_name": "Impl_impl impl RagFormatter { # [doc = \" Create a new RAG formatter with the given configuration.\"] pub fn new (config : RagConfig) -> Self { Self { config } } # [doc = \" Create a new RAG formatter with default configuration.\"] pub fn default () -> Self { Self { config : RagConfig :: default () , } } # [doc = \" Format a ProjectAst into RAG document format.\"] pub fn format (& self , project_ast : & ProjectAst) -> Result < RagDocument > { let metadata = self . build_metadata (project_ast) ? ; let chunks = self . create_chunks (project_ast) ? ; let semantics = self . analyze_semantics (project_ast , & chunks) ? ; let training_examples = if self . config . generate_training_examples { self . generate_training_examples (project_ast , & chunks) ? } else { Vec :: new () } ; Ok (RagDocument { metadata , chunks , semantics , training_examples , }) } # [doc = \" Build metadata for the RAG document.\"] fn build_metadata (& self , project_ast : & ProjectAst) -> Result < RagMetadata > { let mut element_distribution = HashMap :: new () ; let mut complexity_distribution = HashMap :: new () ; let mut total_tokens = 0 ; let mut token_sizes = Vec :: new () ; for file in & project_ast . files { for element in & file . elements { let element_type = format ! (\"{:?}\" , element . element_type) ; * element_distribution . entry (element_type) . or_insert (0) += 1 ; if let Some (complexity) = element . complexity { let complexity_level = match complexity { 0 ..= 2 => \"Simple\" , 3 ..= 5 => \"Moderate\" , 6 ..= 10 => \"Complex\" , _ => \"Very Complex\" , } ; * complexity_distribution . entry (complexity_level . to_string ()) . or_insert (0) += 1 ; } let content = self . build_element_content (element) ; let tokens = self . estimate_token_count (& content) ; total_tokens += tokens ; token_sizes . push (tokens) ; } } token_sizes . sort_unstable () ; let chunk_size_stats = ChunkSizeStats { min_tokens : token_sizes . first () . copied () . unwrap_or (0) , max_tokens : token_sizes . last () . copied () . unwrap_or (0) , avg_tokens : if ! token_sizes . is_empty () { token_sizes . iter () . sum :: < usize > () as f64 / token_sizes . len () as f64 } else { 0.0 } , median_tokens : if ! token_sizes . is_empty () { token_sizes [token_sizes . len () / 2] } else { 0 } , p95_tokens : if ! token_sizes . is_empty () { let p95_index = (token_sizes . len () as f64 * 0.95) as usize ; token_sizes [p95_index . min (token_sizes . len () - 1)] } else { 0 } , } ; Ok (RagMetadata { project_name : project_ast . project . name . clone () , project_version : project_ast . project . version . clone () , rust_edition : project_ast . project . rust_edition . clone () , total_chunks : token_sizes . len () , total_tokens , chunk_size_stats , element_distribution , complexity_distribution , semantic_categories : vec ! [\"function_definition\" . to_string () , \"data_structure\" . to_string () , \"trait_definition\" . to_string () , \"implementation\" . to_string () , \"module_organization\" . to_string () ,] , generated_at : chrono :: Utc :: now () . to_rfc3339 () , rustex_version : env ! (\"CARGO_PKG_VERSION\") . to_string () , chunk_strategy : \"semantic_boundaries\" . to_string () , }) } # [doc = \" Create optimized chunks from the project AST.\"] fn create_chunks (& self , project_ast : & ProjectAst) -> Result < Vec < RagChunk > > { let mut chunks = Vec :: new () ; let mut chunk_id = 0 ; for file in & project_ast . files { for element in & file . elements { if ! self . should_include_element (element) { continue ; } let content = self . build_element_content (element) ; let content_with_context = self . build_element_content_with_context (element , file) ; let metadata = self . build_chunk_metadata (element , file , & content) ? ; let semantic_hash = self . generate_semantic_hash (& content) ; chunk_id += 1 ; chunks . push (RagChunk { id : format ! (\"chunk_{}\" , chunk_id) , content , content_with_context , metadata , embedding : None , semantic_hash , }) ; } } Ok (chunks) } # [doc = \" Analyze semantic relationships and concepts.\"] fn analyze_semantics (& self , project_ast : & ProjectAst , chunks : & [RagChunk]) -> Result < RagSemantics > { let concept_hierarchy = self . extract_concept_hierarchy (project_ast) ? ; let relationships = self . extract_semantic_relationships (project_ast , chunks) ? ; let vocabulary = self . build_vocabulary (project_ast) ? ; let patterns = self . identify_code_patterns (project_ast) ? ; let api_surface = self . analyze_api_surface (project_ast) ? ; Ok (RagSemantics { concept_hierarchy , relationships , vocabulary , patterns , api_surface , }) } # [doc = \" Generate training examples for LLM fine-tuning.\"] fn generate_training_examples (& self , _project_ast : & ProjectAst , chunks : & [RagChunk]) -> Result < Vec < TrainingExample > > { let mut examples = Vec :: new () ; let mut example_id = 0 ; for chunk in chunks { let mut chunk_examples = 0 ; if chunk_examples < self . config . max_training_examples_per_chunk { if let Some (example) = self . create_code_explanation_example (chunk , & mut example_id) ? { examples . push (example) ; chunk_examples += 1 ; } } if chunk_examples < self . config . max_training_examples_per_chunk { if let Some (example) = self . create_code_completion_example (chunk , & mut example_id) ? { examples . push (example) ; chunk_examples += 1 ; } } if chunk_examples < self . config . max_training_examples_per_chunk { if let Some (example) = self . create_api_usage_example (chunk , & mut example_id) ? { examples . push (example) ; let _ = chunk_examples + 1 ; } } } Ok (examples) } # [doc = \" Check if an element should be included based on configuration.\"] fn should_include_element (& self , element : & CodeElement) -> bool { if ! self . config . include_private_items && element . visibility != Visibility :: Public { return false ; } if let Some (min_complexity) = self . config . min_complexity_for_inclusion { if element . complexity . unwrap_or (0) < min_complexity { return false ; } } if ! self . config . include_test_code { if element . name . contains (\"test\") || element . attributes . iter () . any (| attr | attr . contains (\"test\")) { return false ; } } true } # [doc = \" Build content string for an element.\"] fn build_element_content (& self , element : & CodeElement) -> String { let mut content = String :: new () ; if ! element . doc_comments . is_empty () { content . push_str (& element . doc_comments . join (\"\\n\")) ; content . push_str (\"\\n\\n\") ; } if let Some (signature) = & element . signature { content . push_str (signature) ; } else { content . push_str (& element . name) ; } content } # [doc = \" Build content with additional context.\"] fn build_element_content_with_context (& self , element : & CodeElement , file : & FileAst) -> String { let mut content = String :: new () ; content . push_str (& format ! (\"// File: {}\\n\" , file . relative_path . display ())) ; content . push_str (& format ! (\"// Module: {}\\n\\n\" , element . hierarchy . module_path)) ; content . push_str (& self . build_element_content (element)) ; if element . complexity . is_some () { content . push_str (& format ! (\"\\n// Complexity: {}\" , element . complexity . unwrap ())) ; } content } # [doc = \" Build metadata for a chunk.\"] fn build_chunk_metadata (& self , element : & CodeElement , file : & FileAst , content : & str) -> Result < ChunkMetadata > { let documentation_quality = self . assess_documentation_quality (element) ; let semantic_category = self . categorize_element (element) ; let domain_tags = self . extract_domain_tags (element) ; let intent_tags = self . extract_intent_tags (element) ; let embedding_strategy = self . determine_embedding_strategy (element) ; let retrieval_keywords = self . extract_retrieval_keywords (element) ; Ok (ChunkMetadata { file_path : file . relative_path . to_string_lossy () . to_string () , start_line : element . location . line_start as u32 , end_line : element . location . line_end as u32 , element_type : format ! (\"{:?}\" , element . element_type) , element_name : element . name . clone () , qualified_name : element . hierarchy . qualified_name . clone () , visibility : format ! (\"{:?}\" , element . visibility) , token_count : self . estimate_token_count (content) , complexity : element . complexity , has_documentation : ! element . doc_comments . is_empty () , documentation_quality , semantic_category , domain_tags , intent_tags , references : Vec :: new () , referenced_by : Vec :: new () , parent_elements : vec ! [element . hierarchy . parent_id . clone () . unwrap_or_default ()] , child_elements : element . hierarchy . children_ids . clone () , embedding_strategy , retrieval_keywords , }) } # [doc = \" Estimate token count for text (rough approximation).\"] fn estimate_token_count (& self , text : & str) -> usize { (text . len () as f64 / 4.0) . ceil () as usize } # [doc = \" Generate semantic hash for deduplication.\"] fn generate_semantic_hash (& self , content : & str) -> String { use std :: collections :: hash_map :: DefaultHasher ; use std :: hash :: { Hash , Hasher } ; let mut hasher = DefaultHasher :: new () ; content . hash (& mut hasher) ; format ! (\"{:x}\" , hasher . finish ()) } # [doc = \" Assess documentation quality.\"] fn assess_documentation_quality (& self , element : & CodeElement) -> DocumentationQuality { if element . doc_comments . is_empty () { return DocumentationQuality :: Missing ; } let doc_text = element . doc_comments . join (\" \") ; let has_examples = doc_text . contains (\"```\") || doc_text . contains (\"Example\") ; let has_details = doc_text . len () > 100 ; let has_params = doc_text . contains (\"# Arguments\") || doc_text . contains (\"Parameters\") ; match (has_examples , has_details , has_params) { (true , true , true) => DocumentationQuality :: Excellent , (_ , true , true) | (true , true , _) => DocumentationQuality :: Good , (_ , true , _) | (_ , _ , true) => DocumentationQuality :: Basic , _ => DocumentationQuality :: Basic , } } # [doc = \" Categorize element semantically.\"] fn categorize_element (& self , element : & CodeElement) -> String { match element . element_type { ElementType :: Function => \"function_definition\" . to_string () , ElementType :: Struct => \"data_structure\" . to_string () , ElementType :: Enum => \"data_structure\" . to_string () , ElementType :: Trait => \"trait_definition\" . to_string () , ElementType :: Impl => \"implementation\" . to_string () , ElementType :: Module => \"module_organization\" . to_string () , _ => \"other\" . to_string () , } } # [doc = \" Extract domain-specific tags.\"] fn extract_domain_tags (& self , element : & CodeElement) -> Vec < String > { let mut tags = Vec :: new () ; let name_lower = element . name . to_lowercase () ; if name_lower . contains (\"http\") || name_lower . contains (\"web\") { tags . push (\"web\" . to_string ()) ; } if name_lower . contains (\"db\") || name_lower . contains (\"database\") || name_lower . contains (\"sql\") { tags . push (\"database\" . to_string ()) ; } if name_lower . contains (\"async\") || name_lower . contains (\"future\") { tags . push (\"async\" . to_string ()) ; } if name_lower . contains (\"test\") { tags . push (\"testing\" . to_string ()) ; } tags } # [doc = \" Extract intent tags.\"] fn extract_intent_tags (& self , element : & CodeElement) -> Vec < String > { let mut tags = Vec :: new () ; match element . element_type { ElementType :: Function => { if element . name . starts_with (\"new\") { tags . push (\"constructor\" . to_string ()) ; } if element . name . starts_with (\"get\") || element . name . starts_with (\"is\") { tags . push (\"accessor\" . to_string ()) ; } if element . name . starts_with (\"set\") { tags . push (\"mutator\" . to_string ()) ; } } ElementType :: Trait => { tags . push (\"interface\" . to_string ()) ; } ElementType :: Struct | ElementType :: Enum => { tags . push (\"data_type\" . to_string ()) ; } _ => { } } tags } # [doc = \" Determine optimal embedding strategy.\"] fn determine_embedding_strategy (& self , element : & CodeElement) -> EmbeddingStrategy { if element . doc_comments . is_empty () { EmbeddingStrategy :: CodeOnly } else if element . signature . is_none () { EmbeddingStrategy :: DocumentationOnly } else { EmbeddingStrategy :: Combined } } # [doc = \" Extract keywords for retrieval.\"] fn extract_retrieval_keywords (& self , element : & CodeElement) -> Vec < String > { let mut keywords = Vec :: new () ; keywords . push (element . name . clone ()) ; keywords . push (element . hierarchy . qualified_name . clone ()) ; for doc in & element . doc_comments { let words : Vec < String > = doc . split_whitespace () . filter (| w | w . len () > 3 && ! w . starts_with (\"///\")) . map (| w | w . to_lowercase () . trim_matches (| c : char | ! c . is_alphanumeric ()) . to_string ()) . filter (| w | ! w . is_empty ()) . collect () ; keywords . extend (words) ; } keywords . sort () ; keywords . dedup () ; keywords . truncate (20) ; keywords } fn extract_concept_hierarchy (& self , _project_ast : & ProjectAst) -> Result < Vec < ConceptNode > > { Ok (Vec :: new ()) } fn extract_semantic_relationships (& self , _project_ast : & ProjectAst , _chunks : & [RagChunk]) -> Result < Vec < SemanticRelationship > > { Ok (Vec :: new ()) } fn build_vocabulary (& self , _project_ast : & ProjectAst) -> Result < HashMap < String , VocabularyEntry > > { Ok (HashMap :: new ()) } fn identify_code_patterns (& self , _project_ast : & ProjectAst) -> Result < Vec < CodePattern > > { Ok (Vec :: new ()) } fn analyze_api_surface (& self , project_ast : & ProjectAst) -> Result < ApiSurface > { let mut public_functions = Vec :: new () ; let mut public_types = Vec :: new () ; let mut public_traits = Vec :: new () ; let mut modules = Vec :: new () ; for file in & project_ast . files { for element in & file . elements { if element . visibility == Visibility :: Public { let api_element = ApiElement { name : element . name . clone () , qualified_name : element . hierarchy . qualified_name . clone () , element_type : format ! (\"{:?}\" , element . element_type) , signature : element . signature . clone () . unwrap_or_default () , documentation : element . doc_comments . join (\"\\n\") , chunk_id : format ! (\"chunk_{}\" , element . name) , stability : ApiStability :: Stable , usage_examples : Vec :: new () , } ; match element . element_type { ElementType :: Function => public_functions . push (api_element) , ElementType :: Struct | ElementType :: Enum => public_types . push (api_element) , ElementType :: Trait => public_traits . push (api_element) , ElementType :: Module => modules . push (api_element) , ElementType :: Impl => { } , _ => { } , } } } } let complexity_metrics = ApiComplexityMetrics { total_public_items : public_functions . len () + public_types . len () + public_traits . len () , avg_parameter_count : 0.0 , max_parameter_count : 0 , generic_usage_ratio : 0.0 , documentation_coverage : 0.0 , } ; Ok (ApiSurface { public_functions , public_types , public_traits , modules , entry_points : vec ! [\"main\" . to_string ()] , complexity_metrics , }) } fn create_code_explanation_example (& self , _chunk : & RagChunk , example_id : & mut usize) -> Result < Option < TrainingExample > > { * example_id += 1 ; Ok (None) } fn create_code_completion_example (& self , _chunk : & RagChunk , example_id : & mut usize) -> Result < Option < TrainingExample > > { * example_id += 1 ; Ok (None) } fn create_api_usage_example (& self , _chunk : & RagChunk , example_id : & mut usize) -> Result < Option < TrainingExample > > { * example_id += 1 ; Ok (None) } } . self_ty_28::default",
        "visibility": "Public",
        "token_count": 51,
        "complexity": 3,
        "has_documentation": true,
        "documentation_quality": "Basic",
        "semantic_category": "function_definition",
        "domain_tags": [],
        "intent_tags": [],
        "references": [],
        "referenced_by": [],
        "parent_elements": [
          "Impl_impl impl RagFormatter { # [doc = \" Create a new RAG formatter with the given configuration.\"] pub fn new (config : RagConfig) -> Self { Self { config } } # [doc = \" Create a new RAG formatter with default configuration.\"] pub fn default () -> Self { Self { config : RagConfig :: default () , } } # [doc = \" Format a ProjectAst into RAG document format.\"] pub fn format (& self , project_ast : & ProjectAst) -> Result < RagDocument > { let metadata = self . build_metadata (project_ast) ? ; let chunks = self . create_chunks (project_ast) ? ; let semantics = self . analyze_semantics (project_ast , & chunks) ? ; let training_examples = if self . config . generate_training_examples { self . generate_training_examples (project_ast , & chunks) ? } else { Vec :: new () } ; Ok (RagDocument { metadata , chunks , semantics , training_examples , }) } # [doc = \" Build metadata for the RAG document.\"] fn build_metadata (& self , project_ast : & ProjectAst) -> Result < RagMetadata > { let mut element_distribution = HashMap :: new () ; let mut complexity_distribution = HashMap :: new () ; let mut total_tokens = 0 ; let mut token_sizes = Vec :: new () ; for file in & project_ast . files { for element in & file . elements { let element_type = format ! (\"{:?}\" , element . element_type) ; * element_distribution . entry (element_type) . or_insert (0) += 1 ; if let Some (complexity) = element . complexity { let complexity_level = match complexity { 0 ..= 2 => \"Simple\" , 3 ..= 5 => \"Moderate\" , 6 ..= 10 => \"Complex\" , _ => \"Very Complex\" , } ; * complexity_distribution . entry (complexity_level . to_string ()) . or_insert (0) += 1 ; } let content = self . build_element_content (element) ; let tokens = self . estimate_token_count (& content) ; total_tokens += tokens ; token_sizes . push (tokens) ; } } token_sizes . sort_unstable () ; let chunk_size_stats = ChunkSizeStats { min_tokens : token_sizes . first () . copied () . unwrap_or (0) , max_tokens : token_sizes . last () . copied () . unwrap_or (0) , avg_tokens : if ! token_sizes . is_empty () { token_sizes . iter () . sum :: < usize > () as f64 / token_sizes . len () as f64 } else { 0.0 } , median_tokens : if ! token_sizes . is_empty () { token_sizes [token_sizes . len () / 2] } else { 0 } , p95_tokens : if ! token_sizes . is_empty () { let p95_index = (token_sizes . len () as f64 * 0.95) as usize ; token_sizes [p95_index . min (token_sizes . len () - 1)] } else { 0 } , } ; Ok (RagMetadata { project_name : project_ast . project . name . clone () , project_version : project_ast . project . version . clone () , rust_edition : project_ast . project . rust_edition . clone () , total_chunks : token_sizes . len () , total_tokens , chunk_size_stats , element_distribution , complexity_distribution , semantic_categories : vec ! [\"function_definition\" . to_string () , \"data_structure\" . to_string () , \"trait_definition\" . to_string () , \"implementation\" . to_string () , \"module_organization\" . to_string () ,] , generated_at : chrono :: Utc :: now () . to_rfc3339 () , rustex_version : env ! (\"CARGO_PKG_VERSION\") . to_string () , chunk_strategy : \"semantic_boundaries\" . to_string () , }) } # [doc = \" Create optimized chunks from the project AST.\"] fn create_chunks (& self , project_ast : & ProjectAst) -> Result < Vec < RagChunk > > { let mut chunks = Vec :: new () ; let mut chunk_id = 0 ; for file in & project_ast . files { for element in & file . elements { if ! self . should_include_element (element) { continue ; } let content = self . build_element_content (element) ; let content_with_context = self . build_element_content_with_context (element , file) ; let metadata = self . build_chunk_metadata (element , file , & content) ? ; let semantic_hash = self . generate_semantic_hash (& content) ; chunk_id += 1 ; chunks . push (RagChunk { id : format ! (\"chunk_{}\" , chunk_id) , content , content_with_context , metadata , embedding : None , semantic_hash , }) ; } } Ok (chunks) } # [doc = \" Analyze semantic relationships and concepts.\"] fn analyze_semantics (& self , project_ast : & ProjectAst , chunks : & [RagChunk]) -> Result < RagSemantics > { let concept_hierarchy = self . extract_concept_hierarchy (project_ast) ? ; let relationships = self . extract_semantic_relationships (project_ast , chunks) ? ; let vocabulary = self . build_vocabulary (project_ast) ? ; let patterns = self . identify_code_patterns (project_ast) ? ; let api_surface = self . analyze_api_surface (project_ast) ? ; Ok (RagSemantics { concept_hierarchy , relationships , vocabulary , patterns , api_surface , }) } # [doc = \" Generate training examples for LLM fine-tuning.\"] fn generate_training_examples (& self , _project_ast : & ProjectAst , chunks : & [RagChunk]) -> Result < Vec < TrainingExample > > { let mut examples = Vec :: new () ; let mut example_id = 0 ; for chunk in chunks { let mut chunk_examples = 0 ; if chunk_examples < self . config . max_training_examples_per_chunk { if let Some (example) = self . create_code_explanation_example (chunk , & mut example_id) ? { examples . push (example) ; chunk_examples += 1 ; } } if chunk_examples < self . config . max_training_examples_per_chunk { if let Some (example) = self . create_code_completion_example (chunk , & mut example_id) ? { examples . push (example) ; chunk_examples += 1 ; } } if chunk_examples < self . config . max_training_examples_per_chunk { if let Some (example) = self . create_api_usage_example (chunk , & mut example_id) ? { examples . push (example) ; let _ = chunk_examples + 1 ; } } } Ok (examples) } # [doc = \" Check if an element should be included based on configuration.\"] fn should_include_element (& self , element : & CodeElement) -> bool { if ! self . config . include_private_items && element . visibility != Visibility :: Public { return false ; } if let Some (min_complexity) = self . config . min_complexity_for_inclusion { if element . complexity . unwrap_or (0) < min_complexity { return false ; } } if ! self . config . include_test_code { if element . name . contains (\"test\") || element . attributes . iter () . any (| attr | attr . contains (\"test\")) { return false ; } } true } # [doc = \" Build content string for an element.\"] fn build_element_content (& self , element : & CodeElement) -> String { let mut content = String :: new () ; if ! element . doc_comments . is_empty () { content . push_str (& element . doc_comments . join (\"\\n\")) ; content . push_str (\"\\n\\n\") ; } if let Some (signature) = & element . signature { content . push_str (signature) ; } else { content . push_str (& element . name) ; } content } # [doc = \" Build content with additional context.\"] fn build_element_content_with_context (& self , element : & CodeElement , file : & FileAst) -> String { let mut content = String :: new () ; content . push_str (& format ! (\"// File: {}\\n\" , file . relative_path . display ())) ; content . push_str (& format ! (\"// Module: {}\\n\\n\" , element . hierarchy . module_path)) ; content . push_str (& self . build_element_content (element)) ; if element . complexity . is_some () { content . push_str (& format ! (\"\\n// Complexity: {}\" , element . complexity . unwrap ())) ; } content } # [doc = \" Build metadata for a chunk.\"] fn build_chunk_metadata (& self , element : & CodeElement , file : & FileAst , content : & str) -> Result < ChunkMetadata > { let documentation_quality = self . assess_documentation_quality (element) ; let semantic_category = self . categorize_element (element) ; let domain_tags = self . extract_domain_tags (element) ; let intent_tags = self . extract_intent_tags (element) ; let embedding_strategy = self . determine_embedding_strategy (element) ; let retrieval_keywords = self . extract_retrieval_keywords (element) ; Ok (ChunkMetadata { file_path : file . relative_path . to_string_lossy () . to_string () , start_line : element . location . line_start as u32 , end_line : element . location . line_end as u32 , element_type : format ! (\"{:?}\" , element . element_type) , element_name : element . name . clone () , qualified_name : element . hierarchy . qualified_name . clone () , visibility : format ! (\"{:?}\" , element . visibility) , token_count : self . estimate_token_count (content) , complexity : element . complexity , has_documentation : ! element . doc_comments . is_empty () , documentation_quality , semantic_category , domain_tags , intent_tags , references : Vec :: new () , referenced_by : Vec :: new () , parent_elements : vec ! [element . hierarchy . parent_id . clone () . unwrap_or_default ()] , child_elements : element . hierarchy . children_ids . clone () , embedding_strategy , retrieval_keywords , }) } # [doc = \" Estimate token count for text (rough approximation).\"] fn estimate_token_count (& self , text : & str) -> usize { (text . len () as f64 / 4.0) . ceil () as usize } # [doc = \" Generate semantic hash for deduplication.\"] fn generate_semantic_hash (& self , content : & str) -> String { use std :: collections :: hash_map :: DefaultHasher ; use std :: hash :: { Hash , Hasher } ; let mut hasher = DefaultHasher :: new () ; content . hash (& mut hasher) ; format ! (\"{:x}\" , hasher . finish ()) } # [doc = \" Assess documentation quality.\"] fn assess_documentation_quality (& self , element : & CodeElement) -> DocumentationQuality { if element . doc_comments . is_empty () { return DocumentationQuality :: Missing ; } let doc_text = element . doc_comments . join (\" \") ; let has_examples = doc_text . contains (\"```\") || doc_text . contains (\"Example\") ; let has_details = doc_text . len () > 100 ; let has_params = doc_text . contains (\"# Arguments\") || doc_text . contains (\"Parameters\") ; match (has_examples , has_details , has_params) { (true , true , true) => DocumentationQuality :: Excellent , (_ , true , true) | (true , true , _) => DocumentationQuality :: Good , (_ , true , _) | (_ , _ , true) => DocumentationQuality :: Basic , _ => DocumentationQuality :: Basic , } } # [doc = \" Categorize element semantically.\"] fn categorize_element (& self , element : & CodeElement) -> String { match element . element_type { ElementType :: Function => \"function_definition\" . to_string () , ElementType :: Struct => \"data_structure\" . to_string () , ElementType :: Enum => \"data_structure\" . to_string () , ElementType :: Trait => \"trait_definition\" . to_string () , ElementType :: Impl => \"implementation\" . to_string () , ElementType :: Module => \"module_organization\" . to_string () , _ => \"other\" . to_string () , } } # [doc = \" Extract domain-specific tags.\"] fn extract_domain_tags (& self , element : & CodeElement) -> Vec < String > { let mut tags = Vec :: new () ; let name_lower = element . name . to_lowercase () ; if name_lower . contains (\"http\") || name_lower . contains (\"web\") { tags . push (\"web\" . to_string ()) ; } if name_lower . contains (\"db\") || name_lower . contains (\"database\") || name_lower . contains (\"sql\") { tags . push (\"database\" . to_string ()) ; } if name_lower . contains (\"async\") || name_lower . contains (\"future\") { tags . push (\"async\" . to_string ()) ; } if name_lower . contains (\"test\") { tags . push (\"testing\" . to_string ()) ; } tags } # [doc = \" Extract intent tags.\"] fn extract_intent_tags (& self , element : & CodeElement) -> Vec < String > { let mut tags = Vec :: new () ; match element . element_type { ElementType :: Function => { if element . name . starts_with (\"new\") { tags . push (\"constructor\" . to_string ()) ; } if element . name . starts_with (\"get\") || element . name . starts_with (\"is\") { tags . push (\"accessor\" . to_string ()) ; } if element . name . starts_with (\"set\") { tags . push (\"mutator\" . to_string ()) ; } } ElementType :: Trait => { tags . push (\"interface\" . to_string ()) ; } ElementType :: Struct | ElementType :: Enum => { tags . push (\"data_type\" . to_string ()) ; } _ => { } } tags } # [doc = \" Determine optimal embedding strategy.\"] fn determine_embedding_strategy (& self , element : & CodeElement) -> EmbeddingStrategy { if element . doc_comments . is_empty () { EmbeddingStrategy :: CodeOnly } else if element . signature . is_none () { EmbeddingStrategy :: DocumentationOnly } else { EmbeddingStrategy :: Combined } } # [doc = \" Extract keywords for retrieval.\"] fn extract_retrieval_keywords (& self , element : & CodeElement) -> Vec < String > { let mut keywords = Vec :: new () ; keywords . push (element . name . clone ()) ; keywords . push (element . hierarchy . qualified_name . clone ()) ; for doc in & element . doc_comments { let words : Vec < String > = doc . split_whitespace () . filter (| w | w . len () > 3 && ! w . starts_with (\"///\")) . map (| w | w . to_lowercase () . trim_matches (| c : char | ! c . is_alphanumeric ()) . to_string ()) . filter (| w | ! w . is_empty ()) . collect () ; keywords . extend (words) ; } keywords . sort () ; keywords . dedup () ; keywords . truncate (20) ; keywords } fn extract_concept_hierarchy (& self , _project_ast : & ProjectAst) -> Result < Vec < ConceptNode > > { Ok (Vec :: new ()) } fn extract_semantic_relationships (& self , _project_ast : & ProjectAst , _chunks : & [RagChunk]) -> Result < Vec < SemanticRelationship > > { Ok (Vec :: new ()) } fn build_vocabulary (& self , _project_ast : & ProjectAst) -> Result < HashMap < String , VocabularyEntry > > { Ok (HashMap :: new ()) } fn identify_code_patterns (& self , _project_ast : & ProjectAst) -> Result < Vec < CodePattern > > { Ok (Vec :: new ()) } fn analyze_api_surface (& self , project_ast : & ProjectAst) -> Result < ApiSurface > { let mut public_functions = Vec :: new () ; let mut public_types = Vec :: new () ; let mut public_traits = Vec :: new () ; let mut modules = Vec :: new () ; for file in & project_ast . files { for element in & file . elements { if element . visibility == Visibility :: Public { let api_element = ApiElement { name : element . name . clone () , qualified_name : element . hierarchy . qualified_name . clone () , element_type : format ! (\"{:?}\" , element . element_type) , signature : element . signature . clone () . unwrap_or_default () , documentation : element . doc_comments . join (\"\\n\") , chunk_id : format ! (\"chunk_{}\" , element . name) , stability : ApiStability :: Stable , usage_examples : Vec :: new () , } ; match element . element_type { ElementType :: Function => public_functions . push (api_element) , ElementType :: Struct | ElementType :: Enum => public_types . push (api_element) , ElementType :: Trait => public_traits . push (api_element) , ElementType :: Module => modules . push (api_element) , ElementType :: Impl => { } , _ => { } , } } } } let complexity_metrics = ApiComplexityMetrics { total_public_items : public_functions . len () + public_types . len () + public_traits . len () , avg_parameter_count : 0.0 , max_parameter_count : 0 , generic_usage_ratio : 0.0 , documentation_coverage : 0.0 , } ; Ok (ApiSurface { public_functions , public_types , public_traits , modules , entry_points : vec ! [\"main\" . to_string ()] , complexity_metrics , }) } fn create_code_explanation_example (& self , _chunk : & RagChunk , example_id : & mut usize) -> Result < Option < TrainingExample > > { * example_id += 1 ; Ok (None) } fn create_code_completion_example (& self , _chunk : & RagChunk , example_id : & mut usize) -> Result < Option < TrainingExample > > { * example_id += 1 ; Ok (None) } fn create_api_usage_example (& self , _chunk : & RagChunk , example_id : & mut usize) -> Result < Option < TrainingExample > > { * example_id += 1 ; Ok (None) } } . self_ty_28"
        ],
        "child_elements": [],
        "embedding_strategy": "Combined",
        "retrieval_keywords": [
          "Impl_impl impl RagFormatter { # [doc = \" Create a new RAG formatter with the given configuration.\"] pub fn new (config : RagConfig) -> Self { Self { config } } # [doc = \" Create a new RAG formatter with default configuration.\"] pub fn default () -> Self { Self { config : RagConfig :: default () , } } # [doc = \" Format a ProjectAst into RAG document format.\"] pub fn format (& self , project_ast : & ProjectAst) -> Result < RagDocument > { let metadata = self . build_metadata (project_ast) ? ; let chunks = self . create_chunks (project_ast) ? ; let semantics = self . analyze_semantics (project_ast , & chunks) ? ; let training_examples = if self . config . generate_training_examples { self . generate_training_examples (project_ast , & chunks) ? } else { Vec :: new () } ; Ok (RagDocument { metadata , chunks , semantics , training_examples , }) } # [doc = \" Build metadata for the RAG document.\"] fn build_metadata (& self , project_ast : & ProjectAst) -> Result < RagMetadata > { let mut element_distribution = HashMap :: new () ; let mut complexity_distribution = HashMap :: new () ; let mut total_tokens = 0 ; let mut token_sizes = Vec :: new () ; for file in & project_ast . files { for element in & file . elements { let element_type = format ! (\"{:?}\" , element . element_type) ; * element_distribution . entry (element_type) . or_insert (0) += 1 ; if let Some (complexity) = element . complexity { let complexity_level = match complexity { 0 ..= 2 => \"Simple\" , 3 ..= 5 => \"Moderate\" , 6 ..= 10 => \"Complex\" , _ => \"Very Complex\" , } ; * complexity_distribution . entry (complexity_level . to_string ()) . or_insert (0) += 1 ; } let content = self . build_element_content (element) ; let tokens = self . estimate_token_count (& content) ; total_tokens += tokens ; token_sizes . push (tokens) ; } } token_sizes . sort_unstable () ; let chunk_size_stats = ChunkSizeStats { min_tokens : token_sizes . first () . copied () . unwrap_or (0) , max_tokens : token_sizes . last () . copied () . unwrap_or (0) , avg_tokens : if ! token_sizes . is_empty () { token_sizes . iter () . sum :: < usize > () as f64 / token_sizes . len () as f64 } else { 0.0 } , median_tokens : if ! token_sizes . is_empty () { token_sizes [token_sizes . len () / 2] } else { 0 } , p95_tokens : if ! token_sizes . is_empty () { let p95_index = (token_sizes . len () as f64 * 0.95) as usize ; token_sizes [p95_index . min (token_sizes . len () - 1)] } else { 0 } , } ; Ok (RagMetadata { project_name : project_ast . project . name . clone () , project_version : project_ast . project . version . clone () , rust_edition : project_ast . project . rust_edition . clone () , total_chunks : token_sizes . len () , total_tokens , chunk_size_stats , element_distribution , complexity_distribution , semantic_categories : vec ! [\"function_definition\" . to_string () , \"data_structure\" . to_string () , \"trait_definition\" . to_string () , \"implementation\" . to_string () , \"module_organization\" . to_string () ,] , generated_at : chrono :: Utc :: now () . to_rfc3339 () , rustex_version : env ! (\"CARGO_PKG_VERSION\") . to_string () , chunk_strategy : \"semantic_boundaries\" . to_string () , }) } # [doc = \" Create optimized chunks from the project AST.\"] fn create_chunks (& self , project_ast : & ProjectAst) -> Result < Vec < RagChunk > > { let mut chunks = Vec :: new () ; let mut chunk_id = 0 ; for file in & project_ast . files { for element in & file . elements { if ! self . should_include_element (element) { continue ; } let content = self . build_element_content (element) ; let content_with_context = self . build_element_content_with_context (element , file) ; let metadata = self . build_chunk_metadata (element , file , & content) ? ; let semantic_hash = self . generate_semantic_hash (& content) ; chunk_id += 1 ; chunks . push (RagChunk { id : format ! (\"chunk_{}\" , chunk_id) , content , content_with_context , metadata , embedding : None , semantic_hash , }) ; } } Ok (chunks) } # [doc = \" Analyze semantic relationships and concepts.\"] fn analyze_semantics (& self , project_ast : & ProjectAst , chunks : & [RagChunk]) -> Result < RagSemantics > { let concept_hierarchy = self . extract_concept_hierarchy (project_ast) ? ; let relationships = self . extract_semantic_relationships (project_ast , chunks) ? ; let vocabulary = self . build_vocabulary (project_ast) ? ; let patterns = self . identify_code_patterns (project_ast) ? ; let api_surface = self . analyze_api_surface (project_ast) ? ; Ok (RagSemantics { concept_hierarchy , relationships , vocabulary , patterns , api_surface , }) } # [doc = \" Generate training examples for LLM fine-tuning.\"] fn generate_training_examples (& self , _project_ast : & ProjectAst , chunks : & [RagChunk]) -> Result < Vec < TrainingExample > > { let mut examples = Vec :: new () ; let mut example_id = 0 ; for chunk in chunks { let mut chunk_examples = 0 ; if chunk_examples < self . config . max_training_examples_per_chunk { if let Some (example) = self . create_code_explanation_example (chunk , & mut example_id) ? { examples . push (example) ; chunk_examples += 1 ; } } if chunk_examples < self . config . max_training_examples_per_chunk { if let Some (example) = self . create_code_completion_example (chunk , & mut example_id) ? { examples . push (example) ; chunk_examples += 1 ; } } if chunk_examples < self . config . max_training_examples_per_chunk { if let Some (example) = self . create_api_usage_example (chunk , & mut example_id) ? { examples . push (example) ; let _ = chunk_examples + 1 ; } } } Ok (examples) } # [doc = \" Check if an element should be included based on configuration.\"] fn should_include_element (& self , element : & CodeElement) -> bool { if ! self . config . include_private_items && element . visibility != Visibility :: Public { return false ; } if let Some (min_complexity) = self . config . min_complexity_for_inclusion { if element . complexity . unwrap_or (0) < min_complexity { return false ; } } if ! self . config . include_test_code { if element . name . contains (\"test\") || element . attributes . iter () . any (| attr | attr . contains (\"test\")) { return false ; } } true } # [doc = \" Build content string for an element.\"] fn build_element_content (& self , element : & CodeElement) -> String { let mut content = String :: new () ; if ! element . doc_comments . is_empty () { content . push_str (& element . doc_comments . join (\"\\n\")) ; content . push_str (\"\\n\\n\") ; } if let Some (signature) = & element . signature { content . push_str (signature) ; } else { content . push_str (& element . name) ; } content } # [doc = \" Build content with additional context.\"] fn build_element_content_with_context (& self , element : & CodeElement , file : & FileAst) -> String { let mut content = String :: new () ; content . push_str (& format ! (\"// File: {}\\n\" , file . relative_path . display ())) ; content . push_str (& format ! (\"// Module: {}\\n\\n\" , element . hierarchy . module_path)) ; content . push_str (& self . build_element_content (element)) ; if element . complexity . is_some () { content . push_str (& format ! (\"\\n// Complexity: {}\" , element . complexity . unwrap ())) ; } content } # [doc = \" Build metadata for a chunk.\"] fn build_chunk_metadata (& self , element : & CodeElement , file : & FileAst , content : & str) -> Result < ChunkMetadata > { let documentation_quality = self . assess_documentation_quality (element) ; let semantic_category = self . categorize_element (element) ; let domain_tags = self . extract_domain_tags (element) ; let intent_tags = self . extract_intent_tags (element) ; let embedding_strategy = self . determine_embedding_strategy (element) ; let retrieval_keywords = self . extract_retrieval_keywords (element) ; Ok (ChunkMetadata { file_path : file . relative_path . to_string_lossy () . to_string () , start_line : element . location . line_start as u32 , end_line : element . location . line_end as u32 , element_type : format ! (\"{:?}\" , element . element_type) , element_name : element . name . clone () , qualified_name : element . hierarchy . qualified_name . clone () , visibility : format ! (\"{:?}\" , element . visibility) , token_count : self . estimate_token_count (content) , complexity : element . complexity , has_documentation : ! element . doc_comments . is_empty () , documentation_quality , semantic_category , domain_tags , intent_tags , references : Vec :: new () , referenced_by : Vec :: new () , parent_elements : vec ! [element . hierarchy . parent_id . clone () . unwrap_or_default ()] , child_elements : element . hierarchy . children_ids . clone () , embedding_strategy , retrieval_keywords , }) } # [doc = \" Estimate token count for text (rough approximation).\"] fn estimate_token_count (& self , text : & str) -> usize { (text . len () as f64 / 4.0) . ceil () as usize } # [doc = \" Generate semantic hash for deduplication.\"] fn generate_semantic_hash (& self , content : & str) -> String { use std :: collections :: hash_map :: DefaultHasher ; use std :: hash :: { Hash , Hasher } ; let mut hasher = DefaultHasher :: new () ; content . hash (& mut hasher) ; format ! (\"{:x}\" , hasher . finish ()) } # [doc = \" Assess documentation quality.\"] fn assess_documentation_quality (& self , element : & CodeElement) -> DocumentationQuality { if element . doc_comments . is_empty () { return DocumentationQuality :: Missing ; } let doc_text = element . doc_comments . join (\" \") ; let has_examples = doc_text . contains (\"```\") || doc_text . contains (\"Example\") ; let has_details = doc_text . len () > 100 ; let has_params = doc_text . contains (\"# Arguments\") || doc_text . contains (\"Parameters\") ; match (has_examples , has_details , has_params) { (true , true , true) => DocumentationQuality :: Excellent , (_ , true , true) | (true , true , _) => DocumentationQuality :: Good , (_ , true , _) | (_ , _ , true) => DocumentationQuality :: Basic , _ => DocumentationQuality :: Basic , } } # [doc = \" Categorize element semantically.\"] fn categorize_element (& self , element : & CodeElement) -> String { match element . element_type { ElementType :: Function => \"function_definition\" . to_string () , ElementType :: Struct => \"data_structure\" . to_string () , ElementType :: Enum => \"data_structure\" . to_string () , ElementType :: Trait => \"trait_definition\" . to_string () , ElementType :: Impl => \"implementation\" . to_string () , ElementType :: Module => \"module_organization\" . to_string () , _ => \"other\" . to_string () , } } # [doc = \" Extract domain-specific tags.\"] fn extract_domain_tags (& self , element : & CodeElement) -> Vec < String > { let mut tags = Vec :: new () ; let name_lower = element . name . to_lowercase () ; if name_lower . contains (\"http\") || name_lower . contains (\"web\") { tags . push (\"web\" . to_string ()) ; } if name_lower . contains (\"db\") || name_lower . contains (\"database\") || name_lower . contains (\"sql\") { tags . push (\"database\" . to_string ()) ; } if name_lower . contains (\"async\") || name_lower . contains (\"future\") { tags . push (\"async\" . to_string ()) ; } if name_lower . contains (\"test\") { tags . push (\"testing\" . to_string ()) ; } tags } # [doc = \" Extract intent tags.\"] fn extract_intent_tags (& self , element : & CodeElement) -> Vec < String > { let mut tags = Vec :: new () ; match element . element_type { ElementType :: Function => { if element . name . starts_with (\"new\") { tags . push (\"constructor\" . to_string ()) ; } if element . name . starts_with (\"get\") || element . name . starts_with (\"is\") { tags . push (\"accessor\" . to_string ()) ; } if element . name . starts_with (\"set\") { tags . push (\"mutator\" . to_string ()) ; } } ElementType :: Trait => { tags . push (\"interface\" . to_string ()) ; } ElementType :: Struct | ElementType :: Enum => { tags . push (\"data_type\" . to_string ()) ; } _ => { } } tags } # [doc = \" Determine optimal embedding strategy.\"] fn determine_embedding_strategy (& self , element : & CodeElement) -> EmbeddingStrategy { if element . doc_comments . is_empty () { EmbeddingStrategy :: CodeOnly } else if element . signature . is_none () { EmbeddingStrategy :: DocumentationOnly } else { EmbeddingStrategy :: Combined } } # [doc = \" Extract keywords for retrieval.\"] fn extract_retrieval_keywords (& self , element : & CodeElement) -> Vec < String > { let mut keywords = Vec :: new () ; keywords . push (element . name . clone ()) ; keywords . push (element . hierarchy . qualified_name . clone ()) ; for doc in & element . doc_comments { let words : Vec < String > = doc . split_whitespace () . filter (| w | w . len () > 3 && ! w . starts_with (\"///\")) . map (| w | w . to_lowercase () . trim_matches (| c : char | ! c . is_alphanumeric ()) . to_string ()) . filter (| w | ! w . is_empty ()) . collect () ; keywords . extend (words) ; } keywords . sort () ; keywords . dedup () ; keywords . truncate (20) ; keywords } fn extract_concept_hierarchy (& self , _project_ast : & ProjectAst) -> Result < Vec < ConceptNode > > { Ok (Vec :: new ()) } fn extract_semantic_relationships (& self , _project_ast : & ProjectAst , _chunks : & [RagChunk]) -> Result < Vec < SemanticRelationship > > { Ok (Vec :: new ()) } fn build_vocabulary (& self , _project_ast : & ProjectAst) -> Result < HashMap < String , VocabularyEntry > > { Ok (HashMap :: new ()) } fn identify_code_patterns (& self , _project_ast : & ProjectAst) -> Result < Vec < CodePattern > > { Ok (Vec :: new ()) } fn analyze_api_surface (& self , project_ast : & ProjectAst) -> Result < ApiSurface > { let mut public_functions = Vec :: new () ; let mut public_types = Vec :: new () ; let mut public_traits = Vec :: new () ; let mut modules = Vec :: new () ; for file in & project_ast . files { for element in & file . elements { if element . visibility == Visibility :: Public { let api_element = ApiElement { name : element . name . clone () , qualified_name : element . hierarchy . qualified_name . clone () , element_type : format ! (\"{:?}\" , element . element_type) , signature : element . signature . clone () . unwrap_or_default () , documentation : element . doc_comments . join (\"\\n\") , chunk_id : format ! (\"chunk_{}\" , element . name) , stability : ApiStability :: Stable , usage_examples : Vec :: new () , } ; match element . element_type { ElementType :: Function => public_functions . push (api_element) , ElementType :: Struct | ElementType :: Enum => public_types . push (api_element) , ElementType :: Trait => public_traits . push (api_element) , ElementType :: Module => modules . push (api_element) , ElementType :: Impl => { } , _ => { } , } } } } let complexity_metrics = ApiComplexityMetrics { total_public_items : public_functions . len () + public_types . len () + public_traits . len () , avg_parameter_count : 0.0 , max_parameter_count : 0 , generic_usage_ratio : 0.0 , documentation_coverage : 0.0 , } ; Ok (ApiSurface { public_functions , public_types , public_traits , modules , entry_points : vec ! [\"main\" . to_string ()] , complexity_metrics , }) } fn create_code_explanation_example (& self , _chunk : & RagChunk , example_id : & mut usize) -> Result < Option < TrainingExample > > { * example_id += 1 ; Ok (None) } fn create_code_completion_example (& self , _chunk : & RagChunk , example_id : & mut usize) -> Result < Option < TrainingExample > > { * example_id += 1 ; Ok (None) } fn create_api_usage_example (& self , _chunk : & RagChunk , example_id : & mut usize) -> Result < Option < TrainingExample > > { * example_id += 1 ; Ok (None) } } . self_ty_28::default",
          "configuration",
          "create",
          "default",
          "formatter",
          "with"
        ]
      },
      "embedding": null,
      "semantic_hash": "2929eb41b1b151c0"
    },
    {
      "id": "chunk_38",
      "content": " Format a ProjectAst into RAG document format.\n\n# [doc = \" Format a ProjectAst into RAG document format.\"] pub fn format (& self , project_ast : & ProjectAst) -> Result < RagDocument > { let metadata = self . build_metadata (project_ast) ? ; let chunks = self . create_chunks (project_ast) ? ; let semantics = self . analyze_semantics (project_ast , & chunks) ? ; let training_examples = if self . config . generate_training_examples { self . generate_training_examples (project_ast , & chunks) ? } else { Vec :: new () } ; Ok (RagDocument { metadata , chunks , semantics , training_examples , }) } . sig",
      "content_with_context": "// File: src/rag.rs\n// Module: crate::rag\n\n Format a ProjectAst into RAG document format.\n\n# [doc = \" Format a ProjectAst into RAG document format.\"] pub fn format (& self , project_ast : & ProjectAst) -> Result < RagDocument > { let metadata = self . build_metadata (project_ast) ? ; let chunks = self . create_chunks (project_ast) ? ; let semantics = self . analyze_semantics (project_ast , & chunks) ? ; let training_examples = if self . config . generate_training_examples { self . generate_training_examples (project_ast , & chunks) ? } else { Vec :: new () } ; Ok (RagDocument { metadata , chunks , semantics , training_examples , }) } . sig\n// Complexity: 25",
      "metadata": {
        "file_path": "src/rag.rs",
        "start_line": 1,
        "end_line": 1,
        "element_type": "Function",
        "element_name": "format",
        "qualified_name": "Impl_impl impl RagFormatter { # [doc = \" Create a new RAG formatter with the given configuration.\"] pub fn new (config : RagConfig) -> Self { Self { config } } # [doc = \" Create a new RAG formatter with default configuration.\"] pub fn default () -> Self { Self { config : RagConfig :: default () , } } # [doc = \" Format a ProjectAst into RAG document format.\"] pub fn format (& self , project_ast : & ProjectAst) -> Result < RagDocument > { let metadata = self . build_metadata (project_ast) ? ; let chunks = self . create_chunks (project_ast) ? ; let semantics = self . analyze_semantics (project_ast , & chunks) ? ; let training_examples = if self . config . generate_training_examples { self . generate_training_examples (project_ast , & chunks) ? } else { Vec :: new () } ; Ok (RagDocument { metadata , chunks , semantics , training_examples , }) } # [doc = \" Build metadata for the RAG document.\"] fn build_metadata (& self , project_ast : & ProjectAst) -> Result < RagMetadata > { let mut element_distribution = HashMap :: new () ; let mut complexity_distribution = HashMap :: new () ; let mut total_tokens = 0 ; let mut token_sizes = Vec :: new () ; for file in & project_ast . files { for element in & file . elements { let element_type = format ! (\"{:?}\" , element . element_type) ; * element_distribution . entry (element_type) . or_insert (0) += 1 ; if let Some (complexity) = element . complexity { let complexity_level = match complexity { 0 ..= 2 => \"Simple\" , 3 ..= 5 => \"Moderate\" , 6 ..= 10 => \"Complex\" , _ => \"Very Complex\" , } ; * complexity_distribution . entry (complexity_level . to_string ()) . or_insert (0) += 1 ; } let content = self . build_element_content (element) ; let tokens = self . estimate_token_count (& content) ; total_tokens += tokens ; token_sizes . push (tokens) ; } } token_sizes . sort_unstable () ; let chunk_size_stats = ChunkSizeStats { min_tokens : token_sizes . first () . copied () . unwrap_or (0) , max_tokens : token_sizes . last () . copied () . unwrap_or (0) , avg_tokens : if ! token_sizes . is_empty () { token_sizes . iter () . sum :: < usize > () as f64 / token_sizes . len () as f64 } else { 0.0 } , median_tokens : if ! token_sizes . is_empty () { token_sizes [token_sizes . len () / 2] } else { 0 } , p95_tokens : if ! token_sizes . is_empty () { let p95_index = (token_sizes . len () as f64 * 0.95) as usize ; token_sizes [p95_index . min (token_sizes . len () - 1)] } else { 0 } , } ; Ok (RagMetadata { project_name : project_ast . project . name . clone () , project_version : project_ast . project . version . clone () , rust_edition : project_ast . project . rust_edition . clone () , total_chunks : token_sizes . len () , total_tokens , chunk_size_stats , element_distribution , complexity_distribution , semantic_categories : vec ! [\"function_definition\" . to_string () , \"data_structure\" . to_string () , \"trait_definition\" . to_string () , \"implementation\" . to_string () , \"module_organization\" . to_string () ,] , generated_at : chrono :: Utc :: now () . to_rfc3339 () , rustex_version : env ! (\"CARGO_PKG_VERSION\") . to_string () , chunk_strategy : \"semantic_boundaries\" . to_string () , }) } # [doc = \" Create optimized chunks from the project AST.\"] fn create_chunks (& self , project_ast : & ProjectAst) -> Result < Vec < RagChunk > > { let mut chunks = Vec :: new () ; let mut chunk_id = 0 ; for file in & project_ast . files { for element in & file . elements { if ! self . should_include_element (element) { continue ; } let content = self . build_element_content (element) ; let content_with_context = self . build_element_content_with_context (element , file) ; let metadata = self . build_chunk_metadata (element , file , & content) ? ; let semantic_hash = self . generate_semantic_hash (& content) ; chunk_id += 1 ; chunks . push (RagChunk { id : format ! (\"chunk_{}\" , chunk_id) , content , content_with_context , metadata , embedding : None , semantic_hash , }) ; } } Ok (chunks) } # [doc = \" Analyze semantic relationships and concepts.\"] fn analyze_semantics (& self , project_ast : & ProjectAst , chunks : & [RagChunk]) -> Result < RagSemantics > { let concept_hierarchy = self . extract_concept_hierarchy (project_ast) ? ; let relationships = self . extract_semantic_relationships (project_ast , chunks) ? ; let vocabulary = self . build_vocabulary (project_ast) ? ; let patterns = self . identify_code_patterns (project_ast) ? ; let api_surface = self . analyze_api_surface (project_ast) ? ; Ok (RagSemantics { concept_hierarchy , relationships , vocabulary , patterns , api_surface , }) } # [doc = \" Generate training examples for LLM fine-tuning.\"] fn generate_training_examples (& self , _project_ast : & ProjectAst , chunks : & [RagChunk]) -> Result < Vec < TrainingExample > > { let mut examples = Vec :: new () ; let mut example_id = 0 ; for chunk in chunks { let mut chunk_examples = 0 ; if chunk_examples < self . config . max_training_examples_per_chunk { if let Some (example) = self . create_code_explanation_example (chunk , & mut example_id) ? { examples . push (example) ; chunk_examples += 1 ; } } if chunk_examples < self . config . max_training_examples_per_chunk { if let Some (example) = self . create_code_completion_example (chunk , & mut example_id) ? { examples . push (example) ; chunk_examples += 1 ; } } if chunk_examples < self . config . max_training_examples_per_chunk { if let Some (example) = self . create_api_usage_example (chunk , & mut example_id) ? { examples . push (example) ; let _ = chunk_examples + 1 ; } } } Ok (examples) } # [doc = \" Check if an element should be included based on configuration.\"] fn should_include_element (& self , element : & CodeElement) -> bool { if ! self . config . include_private_items && element . visibility != Visibility :: Public { return false ; } if let Some (min_complexity) = self . config . min_complexity_for_inclusion { if element . complexity . unwrap_or (0) < min_complexity { return false ; } } if ! self . config . include_test_code { if element . name . contains (\"test\") || element . attributes . iter () . any (| attr | attr . contains (\"test\")) { return false ; } } true } # [doc = \" Build content string for an element.\"] fn build_element_content (& self , element : & CodeElement) -> String { let mut content = String :: new () ; if ! element . doc_comments . is_empty () { content . push_str (& element . doc_comments . join (\"\\n\")) ; content . push_str (\"\\n\\n\") ; } if let Some (signature) = & element . signature { content . push_str (signature) ; } else { content . push_str (& element . name) ; } content } # [doc = \" Build content with additional context.\"] fn build_element_content_with_context (& self , element : & CodeElement , file : & FileAst) -> String { let mut content = String :: new () ; content . push_str (& format ! (\"// File: {}\\n\" , file . relative_path . display ())) ; content . push_str (& format ! (\"// Module: {}\\n\\n\" , element . hierarchy . module_path)) ; content . push_str (& self . build_element_content (element)) ; if element . complexity . is_some () { content . push_str (& format ! (\"\\n// Complexity: {}\" , element . complexity . unwrap ())) ; } content } # [doc = \" Build metadata for a chunk.\"] fn build_chunk_metadata (& self , element : & CodeElement , file : & FileAst , content : & str) -> Result < ChunkMetadata > { let documentation_quality = self . assess_documentation_quality (element) ; let semantic_category = self . categorize_element (element) ; let domain_tags = self . extract_domain_tags (element) ; let intent_tags = self . extract_intent_tags (element) ; let embedding_strategy = self . determine_embedding_strategy (element) ; let retrieval_keywords = self . extract_retrieval_keywords (element) ; Ok (ChunkMetadata { file_path : file . relative_path . to_string_lossy () . to_string () , start_line : element . location . line_start as u32 , end_line : element . location . line_end as u32 , element_type : format ! (\"{:?}\" , element . element_type) , element_name : element . name . clone () , qualified_name : element . hierarchy . qualified_name . clone () , visibility : format ! (\"{:?}\" , element . visibility) , token_count : self . estimate_token_count (content) , complexity : element . complexity , has_documentation : ! element . doc_comments . is_empty () , documentation_quality , semantic_category , domain_tags , intent_tags , references : Vec :: new () , referenced_by : Vec :: new () , parent_elements : vec ! [element . hierarchy . parent_id . clone () . unwrap_or_default ()] , child_elements : element . hierarchy . children_ids . clone () , embedding_strategy , retrieval_keywords , }) } # [doc = \" Estimate token count for text (rough approximation).\"] fn estimate_token_count (& self , text : & str) -> usize { (text . len () as f64 / 4.0) . ceil () as usize } # [doc = \" Generate semantic hash for deduplication.\"] fn generate_semantic_hash (& self , content : & str) -> String { use std :: collections :: hash_map :: DefaultHasher ; use std :: hash :: { Hash , Hasher } ; let mut hasher = DefaultHasher :: new () ; content . hash (& mut hasher) ; format ! (\"{:x}\" , hasher . finish ()) } # [doc = \" Assess documentation quality.\"] fn assess_documentation_quality (& self , element : & CodeElement) -> DocumentationQuality { if element . doc_comments . is_empty () { return DocumentationQuality :: Missing ; } let doc_text = element . doc_comments . join (\" \") ; let has_examples = doc_text . contains (\"```\") || doc_text . contains (\"Example\") ; let has_details = doc_text . len () > 100 ; let has_params = doc_text . contains (\"# Arguments\") || doc_text . contains (\"Parameters\") ; match (has_examples , has_details , has_params) { (true , true , true) => DocumentationQuality :: Excellent , (_ , true , true) | (true , true , _) => DocumentationQuality :: Good , (_ , true , _) | (_ , _ , true) => DocumentationQuality :: Basic , _ => DocumentationQuality :: Basic , } } # [doc = \" Categorize element semantically.\"] fn categorize_element (& self , element : & CodeElement) -> String { match element . element_type { ElementType :: Function => \"function_definition\" . to_string () , ElementType :: Struct => \"data_structure\" . to_string () , ElementType :: Enum => \"data_structure\" . to_string () , ElementType :: Trait => \"trait_definition\" . to_string () , ElementType :: Impl => \"implementation\" . to_string () , ElementType :: Module => \"module_organization\" . to_string () , _ => \"other\" . to_string () , } } # [doc = \" Extract domain-specific tags.\"] fn extract_domain_tags (& self , element : & CodeElement) -> Vec < String > { let mut tags = Vec :: new () ; let name_lower = element . name . to_lowercase () ; if name_lower . contains (\"http\") || name_lower . contains (\"web\") { tags . push (\"web\" . to_string ()) ; } if name_lower . contains (\"db\") || name_lower . contains (\"database\") || name_lower . contains (\"sql\") { tags . push (\"database\" . to_string ()) ; } if name_lower . contains (\"async\") || name_lower . contains (\"future\") { tags . push (\"async\" . to_string ()) ; } if name_lower . contains (\"test\") { tags . push (\"testing\" . to_string ()) ; } tags } # [doc = \" Extract intent tags.\"] fn extract_intent_tags (& self , element : & CodeElement) -> Vec < String > { let mut tags = Vec :: new () ; match element . element_type { ElementType :: Function => { if element . name . starts_with (\"new\") { tags . push (\"constructor\" . to_string ()) ; } if element . name . starts_with (\"get\") || element . name . starts_with (\"is\") { tags . push (\"accessor\" . to_string ()) ; } if element . name . starts_with (\"set\") { tags . push (\"mutator\" . to_string ()) ; } } ElementType :: Trait => { tags . push (\"interface\" . to_string ()) ; } ElementType :: Struct | ElementType :: Enum => { tags . push (\"data_type\" . to_string ()) ; } _ => { } } tags } # [doc = \" Determine optimal embedding strategy.\"] fn determine_embedding_strategy (& self , element : & CodeElement) -> EmbeddingStrategy { if element . doc_comments . is_empty () { EmbeddingStrategy :: CodeOnly } else if element . signature . is_none () { EmbeddingStrategy :: DocumentationOnly } else { EmbeddingStrategy :: Combined } } # [doc = \" Extract keywords for retrieval.\"] fn extract_retrieval_keywords (& self , element : & CodeElement) -> Vec < String > { let mut keywords = Vec :: new () ; keywords . push (element . name . clone ()) ; keywords . push (element . hierarchy . qualified_name . clone ()) ; for doc in & element . doc_comments { let words : Vec < String > = doc . split_whitespace () . filter (| w | w . len () > 3 && ! w . starts_with (\"///\")) . map (| w | w . to_lowercase () . trim_matches (| c : char | ! c . is_alphanumeric ()) . to_string ()) . filter (| w | ! w . is_empty ()) . collect () ; keywords . extend (words) ; } keywords . sort () ; keywords . dedup () ; keywords . truncate (20) ; keywords } fn extract_concept_hierarchy (& self , _project_ast : & ProjectAst) -> Result < Vec < ConceptNode > > { Ok (Vec :: new ()) } fn extract_semantic_relationships (& self , _project_ast : & ProjectAst , _chunks : & [RagChunk]) -> Result < Vec < SemanticRelationship > > { Ok (Vec :: new ()) } fn build_vocabulary (& self , _project_ast : & ProjectAst) -> Result < HashMap < String , VocabularyEntry > > { Ok (HashMap :: new ()) } fn identify_code_patterns (& self , _project_ast : & ProjectAst) -> Result < Vec < CodePattern > > { Ok (Vec :: new ()) } fn analyze_api_surface (& self , project_ast : & ProjectAst) -> Result < ApiSurface > { let mut public_functions = Vec :: new () ; let mut public_types = Vec :: new () ; let mut public_traits = Vec :: new () ; let mut modules = Vec :: new () ; for file in & project_ast . files { for element in & file . elements { if element . visibility == Visibility :: Public { let api_element = ApiElement { name : element . name . clone () , qualified_name : element . hierarchy . qualified_name . clone () , element_type : format ! (\"{:?}\" , element . element_type) , signature : element . signature . clone () . unwrap_or_default () , documentation : element . doc_comments . join (\"\\n\") , chunk_id : format ! (\"chunk_{}\" , element . name) , stability : ApiStability :: Stable , usage_examples : Vec :: new () , } ; match element . element_type { ElementType :: Function => public_functions . push (api_element) , ElementType :: Struct | ElementType :: Enum => public_types . push (api_element) , ElementType :: Trait => public_traits . push (api_element) , ElementType :: Module => modules . push (api_element) , ElementType :: Impl => { } , _ => { } , } } } } let complexity_metrics = ApiComplexityMetrics { total_public_items : public_functions . len () + public_types . len () + public_traits . len () , avg_parameter_count : 0.0 , max_parameter_count : 0 , generic_usage_ratio : 0.0 , documentation_coverage : 0.0 , } ; Ok (ApiSurface { public_functions , public_types , public_traits , modules , entry_points : vec ! [\"main\" . to_string ()] , complexity_metrics , }) } fn create_code_explanation_example (& self , _chunk : & RagChunk , example_id : & mut usize) -> Result < Option < TrainingExample > > { * example_id += 1 ; Ok (None) } fn create_code_completion_example (& self , _chunk : & RagChunk , example_id : & mut usize) -> Result < Option < TrainingExample > > { * example_id += 1 ; Ok (None) } fn create_api_usage_example (& self , _chunk : & RagChunk , example_id : & mut usize) -> Result < Option < TrainingExample > > { * example_id += 1 ; Ok (None) } } . self_ty_28::format",
        "visibility": "Public",
        "token_count": 151,
        "complexity": 25,
        "has_documentation": true,
        "documentation_quality": "Basic",
        "semantic_category": "function_definition",
        "domain_tags": [],
        "intent_tags": [],
        "references": [],
        "referenced_by": [],
        "parent_elements": [
          "Impl_impl impl RagFormatter { # [doc = \" Create a new RAG formatter with the given configuration.\"] pub fn new (config : RagConfig) -> Self { Self { config } } # [doc = \" Create a new RAG formatter with default configuration.\"] pub fn default () -> Self { Self { config : RagConfig :: default () , } } # [doc = \" Format a ProjectAst into RAG document format.\"] pub fn format (& self , project_ast : & ProjectAst) -> Result < RagDocument > { let metadata = self . build_metadata (project_ast) ? ; let chunks = self . create_chunks (project_ast) ? ; let semantics = self . analyze_semantics (project_ast , & chunks) ? ; let training_examples = if self . config . generate_training_examples { self . generate_training_examples (project_ast , & chunks) ? } else { Vec :: new () } ; Ok (RagDocument { metadata , chunks , semantics , training_examples , }) } # [doc = \" Build metadata for the RAG document.\"] fn build_metadata (& self , project_ast : & ProjectAst) -> Result < RagMetadata > { let mut element_distribution = HashMap :: new () ; let mut complexity_distribution = HashMap :: new () ; let mut total_tokens = 0 ; let mut token_sizes = Vec :: new () ; for file in & project_ast . files { for element in & file . elements { let element_type = format ! (\"{:?}\" , element . element_type) ; * element_distribution . entry (element_type) . or_insert (0) += 1 ; if let Some (complexity) = element . complexity { let complexity_level = match complexity { 0 ..= 2 => \"Simple\" , 3 ..= 5 => \"Moderate\" , 6 ..= 10 => \"Complex\" , _ => \"Very Complex\" , } ; * complexity_distribution . entry (complexity_level . to_string ()) . or_insert (0) += 1 ; } let content = self . build_element_content (element) ; let tokens = self . estimate_token_count (& content) ; total_tokens += tokens ; token_sizes . push (tokens) ; } } token_sizes . sort_unstable () ; let chunk_size_stats = ChunkSizeStats { min_tokens : token_sizes . first () . copied () . unwrap_or (0) , max_tokens : token_sizes . last () . copied () . unwrap_or (0) , avg_tokens : if ! token_sizes . is_empty () { token_sizes . iter () . sum :: < usize > () as f64 / token_sizes . len () as f64 } else { 0.0 } , median_tokens : if ! token_sizes . is_empty () { token_sizes [token_sizes . len () / 2] } else { 0 } , p95_tokens : if ! token_sizes . is_empty () { let p95_index = (token_sizes . len () as f64 * 0.95) as usize ; token_sizes [p95_index . min (token_sizes . len () - 1)] } else { 0 } , } ; Ok (RagMetadata { project_name : project_ast . project . name . clone () , project_version : project_ast . project . version . clone () , rust_edition : project_ast . project . rust_edition . clone () , total_chunks : token_sizes . len () , total_tokens , chunk_size_stats , element_distribution , complexity_distribution , semantic_categories : vec ! [\"function_definition\" . to_string () , \"data_structure\" . to_string () , \"trait_definition\" . to_string () , \"implementation\" . to_string () , \"module_organization\" . to_string () ,] , generated_at : chrono :: Utc :: now () . to_rfc3339 () , rustex_version : env ! (\"CARGO_PKG_VERSION\") . to_string () , chunk_strategy : \"semantic_boundaries\" . to_string () , }) } # [doc = \" Create optimized chunks from the project AST.\"] fn create_chunks (& self , project_ast : & ProjectAst) -> Result < Vec < RagChunk > > { let mut chunks = Vec :: new () ; let mut chunk_id = 0 ; for file in & project_ast . files { for element in & file . elements { if ! self . should_include_element (element) { continue ; } let content = self . build_element_content (element) ; let content_with_context = self . build_element_content_with_context (element , file) ; let metadata = self . build_chunk_metadata (element , file , & content) ? ; let semantic_hash = self . generate_semantic_hash (& content) ; chunk_id += 1 ; chunks . push (RagChunk { id : format ! (\"chunk_{}\" , chunk_id) , content , content_with_context , metadata , embedding : None , semantic_hash , }) ; } } Ok (chunks) } # [doc = \" Analyze semantic relationships and concepts.\"] fn analyze_semantics (& self , project_ast : & ProjectAst , chunks : & [RagChunk]) -> Result < RagSemantics > { let concept_hierarchy = self . extract_concept_hierarchy (project_ast) ? ; let relationships = self . extract_semantic_relationships (project_ast , chunks) ? ; let vocabulary = self . build_vocabulary (project_ast) ? ; let patterns = self . identify_code_patterns (project_ast) ? ; let api_surface = self . analyze_api_surface (project_ast) ? ; Ok (RagSemantics { concept_hierarchy , relationships , vocabulary , patterns , api_surface , }) } # [doc = \" Generate training examples for LLM fine-tuning.\"] fn generate_training_examples (& self , _project_ast : & ProjectAst , chunks : & [RagChunk]) -> Result < Vec < TrainingExample > > { let mut examples = Vec :: new () ; let mut example_id = 0 ; for chunk in chunks { let mut chunk_examples = 0 ; if chunk_examples < self . config . max_training_examples_per_chunk { if let Some (example) = self . create_code_explanation_example (chunk , & mut example_id) ? { examples . push (example) ; chunk_examples += 1 ; } } if chunk_examples < self . config . max_training_examples_per_chunk { if let Some (example) = self . create_code_completion_example (chunk , & mut example_id) ? { examples . push (example) ; chunk_examples += 1 ; } } if chunk_examples < self . config . max_training_examples_per_chunk { if let Some (example) = self . create_api_usage_example (chunk , & mut example_id) ? { examples . push (example) ; let _ = chunk_examples + 1 ; } } } Ok (examples) } # [doc = \" Check if an element should be included based on configuration.\"] fn should_include_element (& self , element : & CodeElement) -> bool { if ! self . config . include_private_items && element . visibility != Visibility :: Public { return false ; } if let Some (min_complexity) = self . config . min_complexity_for_inclusion { if element . complexity . unwrap_or (0) < min_complexity { return false ; } } if ! self . config . include_test_code { if element . name . contains (\"test\") || element . attributes . iter () . any (| attr | attr . contains (\"test\")) { return false ; } } true } # [doc = \" Build content string for an element.\"] fn build_element_content (& self , element : & CodeElement) -> String { let mut content = String :: new () ; if ! element . doc_comments . is_empty () { content . push_str (& element . doc_comments . join (\"\\n\")) ; content . push_str (\"\\n\\n\") ; } if let Some (signature) = & element . signature { content . push_str (signature) ; } else { content . push_str (& element . name) ; } content } # [doc = \" Build content with additional context.\"] fn build_element_content_with_context (& self , element : & CodeElement , file : & FileAst) -> String { let mut content = String :: new () ; content . push_str (& format ! (\"// File: {}\\n\" , file . relative_path . display ())) ; content . push_str (& format ! (\"// Module: {}\\n\\n\" , element . hierarchy . module_path)) ; content . push_str (& self . build_element_content (element)) ; if element . complexity . is_some () { content . push_str (& format ! (\"\\n// Complexity: {}\" , element . complexity . unwrap ())) ; } content } # [doc = \" Build metadata for a chunk.\"] fn build_chunk_metadata (& self , element : & CodeElement , file : & FileAst , content : & str) -> Result < ChunkMetadata > { let documentation_quality = self . assess_documentation_quality (element) ; let semantic_category = self . categorize_element (element) ; let domain_tags = self . extract_domain_tags (element) ; let intent_tags = self . extract_intent_tags (element) ; let embedding_strategy = self . determine_embedding_strategy (element) ; let retrieval_keywords = self . extract_retrieval_keywords (element) ; Ok (ChunkMetadata { file_path : file . relative_path . to_string_lossy () . to_string () , start_line : element . location . line_start as u32 , end_line : element . location . line_end as u32 , element_type : format ! (\"{:?}\" , element . element_type) , element_name : element . name . clone () , qualified_name : element . hierarchy . qualified_name . clone () , visibility : format ! (\"{:?}\" , element . visibility) , token_count : self . estimate_token_count (content) , complexity : element . complexity , has_documentation : ! element . doc_comments . is_empty () , documentation_quality , semantic_category , domain_tags , intent_tags , references : Vec :: new () , referenced_by : Vec :: new () , parent_elements : vec ! [element . hierarchy . parent_id . clone () . unwrap_or_default ()] , child_elements : element . hierarchy . children_ids . clone () , embedding_strategy , retrieval_keywords , }) } # [doc = \" Estimate token count for text (rough approximation).\"] fn estimate_token_count (& self , text : & str) -> usize { (text . len () as f64 / 4.0) . ceil () as usize } # [doc = \" Generate semantic hash for deduplication.\"] fn generate_semantic_hash (& self , content : & str) -> String { use std :: collections :: hash_map :: DefaultHasher ; use std :: hash :: { Hash , Hasher } ; let mut hasher = DefaultHasher :: new () ; content . hash (& mut hasher) ; format ! (\"{:x}\" , hasher . finish ()) } # [doc = \" Assess documentation quality.\"] fn assess_documentation_quality (& self , element : & CodeElement) -> DocumentationQuality { if element . doc_comments . is_empty () { return DocumentationQuality :: Missing ; } let doc_text = element . doc_comments . join (\" \") ; let has_examples = doc_text . contains (\"```\") || doc_text . contains (\"Example\") ; let has_details = doc_text . len () > 100 ; let has_params = doc_text . contains (\"# Arguments\") || doc_text . contains (\"Parameters\") ; match (has_examples , has_details , has_params) { (true , true , true) => DocumentationQuality :: Excellent , (_ , true , true) | (true , true , _) => DocumentationQuality :: Good , (_ , true , _) | (_ , _ , true) => DocumentationQuality :: Basic , _ => DocumentationQuality :: Basic , } } # [doc = \" Categorize element semantically.\"] fn categorize_element (& self , element : & CodeElement) -> String { match element . element_type { ElementType :: Function => \"function_definition\" . to_string () , ElementType :: Struct => \"data_structure\" . to_string () , ElementType :: Enum => \"data_structure\" . to_string () , ElementType :: Trait => \"trait_definition\" . to_string () , ElementType :: Impl => \"implementation\" . to_string () , ElementType :: Module => \"module_organization\" . to_string () , _ => \"other\" . to_string () , } } # [doc = \" Extract domain-specific tags.\"] fn extract_domain_tags (& self , element : & CodeElement) -> Vec < String > { let mut tags = Vec :: new () ; let name_lower = element . name . to_lowercase () ; if name_lower . contains (\"http\") || name_lower . contains (\"web\") { tags . push (\"web\" . to_string ()) ; } if name_lower . contains (\"db\") || name_lower . contains (\"database\") || name_lower . contains (\"sql\") { tags . push (\"database\" . to_string ()) ; } if name_lower . contains (\"async\") || name_lower . contains (\"future\") { tags . push (\"async\" . to_string ()) ; } if name_lower . contains (\"test\") { tags . push (\"testing\" . to_string ()) ; } tags } # [doc = \" Extract intent tags.\"] fn extract_intent_tags (& self , element : & CodeElement) -> Vec < String > { let mut tags = Vec :: new () ; match element . element_type { ElementType :: Function => { if element . name . starts_with (\"new\") { tags . push (\"constructor\" . to_string ()) ; } if element . name . starts_with (\"get\") || element . name . starts_with (\"is\") { tags . push (\"accessor\" . to_string ()) ; } if element . name . starts_with (\"set\") { tags . push (\"mutator\" . to_string ()) ; } } ElementType :: Trait => { tags . push (\"interface\" . to_string ()) ; } ElementType :: Struct | ElementType :: Enum => { tags . push (\"data_type\" . to_string ()) ; } _ => { } } tags } # [doc = \" Determine optimal embedding strategy.\"] fn determine_embedding_strategy (& self , element : & CodeElement) -> EmbeddingStrategy { if element . doc_comments . is_empty () { EmbeddingStrategy :: CodeOnly } else if element . signature . is_none () { EmbeddingStrategy :: DocumentationOnly } else { EmbeddingStrategy :: Combined } } # [doc = \" Extract keywords for retrieval.\"] fn extract_retrieval_keywords (& self , element : & CodeElement) -> Vec < String > { let mut keywords = Vec :: new () ; keywords . push (element . name . clone ()) ; keywords . push (element . hierarchy . qualified_name . clone ()) ; for doc in & element . doc_comments { let words : Vec < String > = doc . split_whitespace () . filter (| w | w . len () > 3 && ! w . starts_with (\"///\")) . map (| w | w . to_lowercase () . trim_matches (| c : char | ! c . is_alphanumeric ()) . to_string ()) . filter (| w | ! w . is_empty ()) . collect () ; keywords . extend (words) ; } keywords . sort () ; keywords . dedup () ; keywords . truncate (20) ; keywords } fn extract_concept_hierarchy (& self , _project_ast : & ProjectAst) -> Result < Vec < ConceptNode > > { Ok (Vec :: new ()) } fn extract_semantic_relationships (& self , _project_ast : & ProjectAst , _chunks : & [RagChunk]) -> Result < Vec < SemanticRelationship > > { Ok (Vec :: new ()) } fn build_vocabulary (& self , _project_ast : & ProjectAst) -> Result < HashMap < String , VocabularyEntry > > { Ok (HashMap :: new ()) } fn identify_code_patterns (& self , _project_ast : & ProjectAst) -> Result < Vec < CodePattern > > { Ok (Vec :: new ()) } fn analyze_api_surface (& self , project_ast : & ProjectAst) -> Result < ApiSurface > { let mut public_functions = Vec :: new () ; let mut public_types = Vec :: new () ; let mut public_traits = Vec :: new () ; let mut modules = Vec :: new () ; for file in & project_ast . files { for element in & file . elements { if element . visibility == Visibility :: Public { let api_element = ApiElement { name : element . name . clone () , qualified_name : element . hierarchy . qualified_name . clone () , element_type : format ! (\"{:?}\" , element . element_type) , signature : element . signature . clone () . unwrap_or_default () , documentation : element . doc_comments . join (\"\\n\") , chunk_id : format ! (\"chunk_{}\" , element . name) , stability : ApiStability :: Stable , usage_examples : Vec :: new () , } ; match element . element_type { ElementType :: Function => public_functions . push (api_element) , ElementType :: Struct | ElementType :: Enum => public_types . push (api_element) , ElementType :: Trait => public_traits . push (api_element) , ElementType :: Module => modules . push (api_element) , ElementType :: Impl => { } , _ => { } , } } } } let complexity_metrics = ApiComplexityMetrics { total_public_items : public_functions . len () + public_types . len () + public_traits . len () , avg_parameter_count : 0.0 , max_parameter_count : 0 , generic_usage_ratio : 0.0 , documentation_coverage : 0.0 , } ; Ok (ApiSurface { public_functions , public_types , public_traits , modules , entry_points : vec ! [\"main\" . to_string ()] , complexity_metrics , }) } fn create_code_explanation_example (& self , _chunk : & RagChunk , example_id : & mut usize) -> Result < Option < TrainingExample > > { * example_id += 1 ; Ok (None) } fn create_code_completion_example (& self , _chunk : & RagChunk , example_id : & mut usize) -> Result < Option < TrainingExample > > { * example_id += 1 ; Ok (None) } fn create_api_usage_example (& self , _chunk : & RagChunk , example_id : & mut usize) -> Result < Option < TrainingExample > > { * example_id += 1 ; Ok (None) } } . self_ty_28"
        ],
        "child_elements": [],
        "embedding_strategy": "Combined",
        "retrieval_keywords": [
          "Impl_impl impl RagFormatter { # [doc = \" Create a new RAG formatter with the given configuration.\"] pub fn new (config : RagConfig) -> Self { Self { config } } # [doc = \" Create a new RAG formatter with default configuration.\"] pub fn default () -> Self { Self { config : RagConfig :: default () , } } # [doc = \" Format a ProjectAst into RAG document format.\"] pub fn format (& self , project_ast : & ProjectAst) -> Result < RagDocument > { let metadata = self . build_metadata (project_ast) ? ; let chunks = self . create_chunks (project_ast) ? ; let semantics = self . analyze_semantics (project_ast , & chunks) ? ; let training_examples = if self . config . generate_training_examples { self . generate_training_examples (project_ast , & chunks) ? } else { Vec :: new () } ; Ok (RagDocument { metadata , chunks , semantics , training_examples , }) } # [doc = \" Build metadata for the RAG document.\"] fn build_metadata (& self , project_ast : & ProjectAst) -> Result < RagMetadata > { let mut element_distribution = HashMap :: new () ; let mut complexity_distribution = HashMap :: new () ; let mut total_tokens = 0 ; let mut token_sizes = Vec :: new () ; for file in & project_ast . files { for element in & file . elements { let element_type = format ! (\"{:?}\" , element . element_type) ; * element_distribution . entry (element_type) . or_insert (0) += 1 ; if let Some (complexity) = element . complexity { let complexity_level = match complexity { 0 ..= 2 => \"Simple\" , 3 ..= 5 => \"Moderate\" , 6 ..= 10 => \"Complex\" , _ => \"Very Complex\" , } ; * complexity_distribution . entry (complexity_level . to_string ()) . or_insert (0) += 1 ; } let content = self . build_element_content (element) ; let tokens = self . estimate_token_count (& content) ; total_tokens += tokens ; token_sizes . push (tokens) ; } } token_sizes . sort_unstable () ; let chunk_size_stats = ChunkSizeStats { min_tokens : token_sizes . first () . copied () . unwrap_or (0) , max_tokens : token_sizes . last () . copied () . unwrap_or (0) , avg_tokens : if ! token_sizes . is_empty () { token_sizes . iter () . sum :: < usize > () as f64 / token_sizes . len () as f64 } else { 0.0 } , median_tokens : if ! token_sizes . is_empty () { token_sizes [token_sizes . len () / 2] } else { 0 } , p95_tokens : if ! token_sizes . is_empty () { let p95_index = (token_sizes . len () as f64 * 0.95) as usize ; token_sizes [p95_index . min (token_sizes . len () - 1)] } else { 0 } , } ; Ok (RagMetadata { project_name : project_ast . project . name . clone () , project_version : project_ast . project . version . clone () , rust_edition : project_ast . project . rust_edition . clone () , total_chunks : token_sizes . len () , total_tokens , chunk_size_stats , element_distribution , complexity_distribution , semantic_categories : vec ! [\"function_definition\" . to_string () , \"data_structure\" . to_string () , \"trait_definition\" . to_string () , \"implementation\" . to_string () , \"module_organization\" . to_string () ,] , generated_at : chrono :: Utc :: now () . to_rfc3339 () , rustex_version : env ! (\"CARGO_PKG_VERSION\") . to_string () , chunk_strategy : \"semantic_boundaries\" . to_string () , }) } # [doc = \" Create optimized chunks from the project AST.\"] fn create_chunks (& self , project_ast : & ProjectAst) -> Result < Vec < RagChunk > > { let mut chunks = Vec :: new () ; let mut chunk_id = 0 ; for file in & project_ast . files { for element in & file . elements { if ! self . should_include_element (element) { continue ; } let content = self . build_element_content (element) ; let content_with_context = self . build_element_content_with_context (element , file) ; let metadata = self . build_chunk_metadata (element , file , & content) ? ; let semantic_hash = self . generate_semantic_hash (& content) ; chunk_id += 1 ; chunks . push (RagChunk { id : format ! (\"chunk_{}\" , chunk_id) , content , content_with_context , metadata , embedding : None , semantic_hash , }) ; } } Ok (chunks) } # [doc = \" Analyze semantic relationships and concepts.\"] fn analyze_semantics (& self , project_ast : & ProjectAst , chunks : & [RagChunk]) -> Result < RagSemantics > { let concept_hierarchy = self . extract_concept_hierarchy (project_ast) ? ; let relationships = self . extract_semantic_relationships (project_ast , chunks) ? ; let vocabulary = self . build_vocabulary (project_ast) ? ; let patterns = self . identify_code_patterns (project_ast) ? ; let api_surface = self . analyze_api_surface (project_ast) ? ; Ok (RagSemantics { concept_hierarchy , relationships , vocabulary , patterns , api_surface , }) } # [doc = \" Generate training examples for LLM fine-tuning.\"] fn generate_training_examples (& self , _project_ast : & ProjectAst , chunks : & [RagChunk]) -> Result < Vec < TrainingExample > > { let mut examples = Vec :: new () ; let mut example_id = 0 ; for chunk in chunks { let mut chunk_examples = 0 ; if chunk_examples < self . config . max_training_examples_per_chunk { if let Some (example) = self . create_code_explanation_example (chunk , & mut example_id) ? { examples . push (example) ; chunk_examples += 1 ; } } if chunk_examples < self . config . max_training_examples_per_chunk { if let Some (example) = self . create_code_completion_example (chunk , & mut example_id) ? { examples . push (example) ; chunk_examples += 1 ; } } if chunk_examples < self . config . max_training_examples_per_chunk { if let Some (example) = self . create_api_usage_example (chunk , & mut example_id) ? { examples . push (example) ; let _ = chunk_examples + 1 ; } } } Ok (examples) } # [doc = \" Check if an element should be included based on configuration.\"] fn should_include_element (& self , element : & CodeElement) -> bool { if ! self . config . include_private_items && element . visibility != Visibility :: Public { return false ; } if let Some (min_complexity) = self . config . min_complexity_for_inclusion { if element . complexity . unwrap_or (0) < min_complexity { return false ; } } if ! self . config . include_test_code { if element . name . contains (\"test\") || element . attributes . iter () . any (| attr | attr . contains (\"test\")) { return false ; } } true } # [doc = \" Build content string for an element.\"] fn build_element_content (& self , element : & CodeElement) -> String { let mut content = String :: new () ; if ! element . doc_comments . is_empty () { content . push_str (& element . doc_comments . join (\"\\n\")) ; content . push_str (\"\\n\\n\") ; } if let Some (signature) = & element . signature { content . push_str (signature) ; } else { content . push_str (& element . name) ; } content } # [doc = \" Build content with additional context.\"] fn build_element_content_with_context (& self , element : & CodeElement , file : & FileAst) -> String { let mut content = String :: new () ; content . push_str (& format ! (\"// File: {}\\n\" , file . relative_path . display ())) ; content . push_str (& format ! (\"// Module: {}\\n\\n\" , element . hierarchy . module_path)) ; content . push_str (& self . build_element_content (element)) ; if element . complexity . is_some () { content . push_str (& format ! (\"\\n// Complexity: {}\" , element . complexity . unwrap ())) ; } content } # [doc = \" Build metadata for a chunk.\"] fn build_chunk_metadata (& self , element : & CodeElement , file : & FileAst , content : & str) -> Result < ChunkMetadata > { let documentation_quality = self . assess_documentation_quality (element) ; let semantic_category = self . categorize_element (element) ; let domain_tags = self . extract_domain_tags (element) ; let intent_tags = self . extract_intent_tags (element) ; let embedding_strategy = self . determine_embedding_strategy (element) ; let retrieval_keywords = self . extract_retrieval_keywords (element) ; Ok (ChunkMetadata { file_path : file . relative_path . to_string_lossy () . to_string () , start_line : element . location . line_start as u32 , end_line : element . location . line_end as u32 , element_type : format ! (\"{:?}\" , element . element_type) , element_name : element . name . clone () , qualified_name : element . hierarchy . qualified_name . clone () , visibility : format ! (\"{:?}\" , element . visibility) , token_count : self . estimate_token_count (content) , complexity : element . complexity , has_documentation : ! element . doc_comments . is_empty () , documentation_quality , semantic_category , domain_tags , intent_tags , references : Vec :: new () , referenced_by : Vec :: new () , parent_elements : vec ! [element . hierarchy . parent_id . clone () . unwrap_or_default ()] , child_elements : element . hierarchy . children_ids . clone () , embedding_strategy , retrieval_keywords , }) } # [doc = \" Estimate token count for text (rough approximation).\"] fn estimate_token_count (& self , text : & str) -> usize { (text . len () as f64 / 4.0) . ceil () as usize } # [doc = \" Generate semantic hash for deduplication.\"] fn generate_semantic_hash (& self , content : & str) -> String { use std :: collections :: hash_map :: DefaultHasher ; use std :: hash :: { Hash , Hasher } ; let mut hasher = DefaultHasher :: new () ; content . hash (& mut hasher) ; format ! (\"{:x}\" , hasher . finish ()) } # [doc = \" Assess documentation quality.\"] fn assess_documentation_quality (& self , element : & CodeElement) -> DocumentationQuality { if element . doc_comments . is_empty () { return DocumentationQuality :: Missing ; } let doc_text = element . doc_comments . join (\" \") ; let has_examples = doc_text . contains (\"```\") || doc_text . contains (\"Example\") ; let has_details = doc_text . len () > 100 ; let has_params = doc_text . contains (\"# Arguments\") || doc_text . contains (\"Parameters\") ; match (has_examples , has_details , has_params) { (true , true , true) => DocumentationQuality :: Excellent , (_ , true , true) | (true , true , _) => DocumentationQuality :: Good , (_ , true , _) | (_ , _ , true) => DocumentationQuality :: Basic , _ => DocumentationQuality :: Basic , } } # [doc = \" Categorize element semantically.\"] fn categorize_element (& self , element : & CodeElement) -> String { match element . element_type { ElementType :: Function => \"function_definition\" . to_string () , ElementType :: Struct => \"data_structure\" . to_string () , ElementType :: Enum => \"data_structure\" . to_string () , ElementType :: Trait => \"trait_definition\" . to_string () , ElementType :: Impl => \"implementation\" . to_string () , ElementType :: Module => \"module_organization\" . to_string () , _ => \"other\" . to_string () , } } # [doc = \" Extract domain-specific tags.\"] fn extract_domain_tags (& self , element : & CodeElement) -> Vec < String > { let mut tags = Vec :: new () ; let name_lower = element . name . to_lowercase () ; if name_lower . contains (\"http\") || name_lower . contains (\"web\") { tags . push (\"web\" . to_string ()) ; } if name_lower . contains (\"db\") || name_lower . contains (\"database\") || name_lower . contains (\"sql\") { tags . push (\"database\" . to_string ()) ; } if name_lower . contains (\"async\") || name_lower . contains (\"future\") { tags . push (\"async\" . to_string ()) ; } if name_lower . contains (\"test\") { tags . push (\"testing\" . to_string ()) ; } tags } # [doc = \" Extract intent tags.\"] fn extract_intent_tags (& self , element : & CodeElement) -> Vec < String > { let mut tags = Vec :: new () ; match element . element_type { ElementType :: Function => { if element . name . starts_with (\"new\") { tags . push (\"constructor\" . to_string ()) ; } if element . name . starts_with (\"get\") || element . name . starts_with (\"is\") { tags . push (\"accessor\" . to_string ()) ; } if element . name . starts_with (\"set\") { tags . push (\"mutator\" . to_string ()) ; } } ElementType :: Trait => { tags . push (\"interface\" . to_string ()) ; } ElementType :: Struct | ElementType :: Enum => { tags . push (\"data_type\" . to_string ()) ; } _ => { } } tags } # [doc = \" Determine optimal embedding strategy.\"] fn determine_embedding_strategy (& self , element : & CodeElement) -> EmbeddingStrategy { if element . doc_comments . is_empty () { EmbeddingStrategy :: CodeOnly } else if element . signature . is_none () { EmbeddingStrategy :: DocumentationOnly } else { EmbeddingStrategy :: Combined } } # [doc = \" Extract keywords for retrieval.\"] fn extract_retrieval_keywords (& self , element : & CodeElement) -> Vec < String > { let mut keywords = Vec :: new () ; keywords . push (element . name . clone ()) ; keywords . push (element . hierarchy . qualified_name . clone ()) ; for doc in & element . doc_comments { let words : Vec < String > = doc . split_whitespace () . filter (| w | w . len () > 3 && ! w . starts_with (\"///\")) . map (| w | w . to_lowercase () . trim_matches (| c : char | ! c . is_alphanumeric ()) . to_string ()) . filter (| w | ! w . is_empty ()) . collect () ; keywords . extend (words) ; } keywords . sort () ; keywords . dedup () ; keywords . truncate (20) ; keywords } fn extract_concept_hierarchy (& self , _project_ast : & ProjectAst) -> Result < Vec < ConceptNode > > { Ok (Vec :: new ()) } fn extract_semantic_relationships (& self , _project_ast : & ProjectAst , _chunks : & [RagChunk]) -> Result < Vec < SemanticRelationship > > { Ok (Vec :: new ()) } fn build_vocabulary (& self , _project_ast : & ProjectAst) -> Result < HashMap < String , VocabularyEntry > > { Ok (HashMap :: new ()) } fn identify_code_patterns (& self , _project_ast : & ProjectAst) -> Result < Vec < CodePattern > > { Ok (Vec :: new ()) } fn analyze_api_surface (& self , project_ast : & ProjectAst) -> Result < ApiSurface > { let mut public_functions = Vec :: new () ; let mut public_types = Vec :: new () ; let mut public_traits = Vec :: new () ; let mut modules = Vec :: new () ; for file in & project_ast . files { for element in & file . elements { if element . visibility == Visibility :: Public { let api_element = ApiElement { name : element . name . clone () , qualified_name : element . hierarchy . qualified_name . clone () , element_type : format ! (\"{:?}\" , element . element_type) , signature : element . signature . clone () . unwrap_or_default () , documentation : element . doc_comments . join (\"\\n\") , chunk_id : format ! (\"chunk_{}\" , element . name) , stability : ApiStability :: Stable , usage_examples : Vec :: new () , } ; match element . element_type { ElementType :: Function => public_functions . push (api_element) , ElementType :: Struct | ElementType :: Enum => public_types . push (api_element) , ElementType :: Trait => public_traits . push (api_element) , ElementType :: Module => modules . push (api_element) , ElementType :: Impl => { } , _ => { } , } } } } let complexity_metrics = ApiComplexityMetrics { total_public_items : public_functions . len () + public_types . len () + public_traits . len () , avg_parameter_count : 0.0 , max_parameter_count : 0 , generic_usage_ratio : 0.0 , documentation_coverage : 0.0 , } ; Ok (ApiSurface { public_functions , public_types , public_traits , modules , entry_points : vec ! [\"main\" . to_string ()] , complexity_metrics , }) } fn create_code_explanation_example (& self , _chunk : & RagChunk , example_id : & mut usize) -> Result < Option < TrainingExample > > { * example_id += 1 ; Ok (None) } fn create_code_completion_example (& self , _chunk : & RagChunk , example_id : & mut usize) -> Result < Option < TrainingExample > > { * example_id += 1 ; Ok (None) } fn create_api_usage_example (& self , _chunk : & RagChunk , example_id : & mut usize) -> Result < Option < TrainingExample > > { * example_id += 1 ; Ok (None) } } . self_ty_28::format",
          "document",
          "format",
          "into",
          "projectast"
        ]
      },
      "embedding": null,
      "semantic_hash": "4c2585d4e868e7dd"
    },
    {
      "id": "chunk_39",
      "content": " Convert RAG document to JSON format.\n\n# [doc = \" Convert RAG document to JSON format.\"] pub fn format_as_json (document : & RagDocument , pretty : bool) -> Result < String > { if pretty { Ok (serde_json :: to_string_pretty (document) ?) } else { Ok (serde_json :: to_string (document) ?) } } . sig",
      "content_with_context": "// File: src/rag.rs\n// Module: crate::rag\n\n Convert RAG document to JSON format.\n\n# [doc = \" Convert RAG document to JSON format.\"] pub fn format_as_json (document : & RagDocument , pretty : bool) -> Result < String > { if pretty { Ok (serde_json :: to_string_pretty (document) ?) } else { Ok (serde_json :: to_string (document) ?) } } . sig\n// Complexity: 18",
      "metadata": {
        "file_path": "src/rag.rs",
        "start_line": 1,
        "end_line": 1,
        "element_type": "Function",
        "element_name": "format_as_json",
        "qualified_name": "crate::rag::format_as_json",
        "visibility": "Public",
        "token_count": 75,
        "complexity": 18,
        "has_documentation": true,
        "documentation_quality": "Basic",
        "semantic_category": "function_definition",
        "domain_tags": [],
        "intent_tags": [],
        "references": [],
        "referenced_by": [],
        "parent_elements": [
          ""
        ],
        "child_elements": [],
        "embedding_strategy": "Combined",
        "retrieval_keywords": [
          "convert",
          "crate::rag::format_as_json",
          "document",
          "format",
          "format_as_json",
          "json"
        ]
      },
      "embedding": null,
      "semantic_hash": "5063fb3c9e674dd"
    },
    {
      "id": "chunk_40",
      "content": " Convert RAG document to JSONL format (one chunk per line).\n\n# [doc = \" Convert RAG document to JSONL format (one chunk per line).\"] pub fn format_as_jsonl (document : & RagDocument) -> Result < String > { let mut output = String :: new () ; output . push_str (& serde_json :: to_string (& document . metadata) ?) ; output . push ('\\n') ; for chunk in & document . chunks { output . push_str (& serde_json :: to_string (chunk) ?) ; output . push ('\\n') ; } Ok (output) } . sig",
      "content_with_context": "// File: src/rag.rs\n// Module: crate::rag\n\n Convert RAG document to JSONL format (one chunk per line).\n\n# [doc = \" Convert RAG document to JSONL format (one chunk per line).\"] pub fn format_as_jsonl (document : & RagDocument) -> Result < String > { let mut output = String :: new () ; output . push_str (& serde_json :: to_string (& document . metadata) ?) ; output . push ('\\n') ; for chunk in & document . chunks { output . push_str (& serde_json :: to_string (chunk) ?) ; output . push ('\\n') ; } Ok (output) } . sig\n// Complexity: 17",
      "metadata": {
        "file_path": "src/rag.rs",
        "start_line": 1,
        "end_line": 1,
        "element_type": "Function",
        "element_name": "format_as_jsonl",
        "qualified_name": "crate::rag::format_as_jsonl",
        "visibility": "Public",
        "token_count": 119,
        "complexity": 17,
        "has_documentation": true,
        "documentation_quality": "Basic",
        "semantic_category": "function_definition",
        "domain_tags": [],
        "intent_tags": [],
        "references": [],
        "referenced_by": [],
        "parent_elements": [
          ""
        ],
        "child_elements": [],
        "embedding_strategy": "Combined",
        "retrieval_keywords": [
          "chunk",
          "convert",
          "crate::rag::format_as_jsonl",
          "document",
          "format",
          "format_as_jsonl",
          "jsonl",
          "line",
          "one"
        ]
      },
      "embedding": null,
      "semantic_hash": "e30b45c3db4250c8"
    },
    {
      "id": "chunk_41",
      "content": " Convert RAG document to embedding-optimized format.\n\n# [doc = \" Convert RAG document to embedding-optimized format.\"] pub fn format_for_embeddings (document : & RagDocument) -> Result < Vec < EmbeddingInput > > { let mut inputs = Vec :: new () ; for chunk in & document . chunks { let text = match chunk . metadata . embedding_strategy { EmbeddingStrategy :: Combined => chunk . content_with_context . clone () , EmbeddingStrategy :: CodeOnly => { chunk . content . clone () } EmbeddingStrategy :: DocumentationOnly => { chunk . content . lines () . filter (| line | line . starts_with (\"///\") || line . starts_with (\"//!\")) . map (| line | line . trim_start_matches (\"///\") . trim_start_matches (\"//!\") . trim ()) . collect :: < Vec < _ > > () . join (\" \") } EmbeddingStrategy :: Specialized (_) => chunk . content_with_context . clone () , } ; inputs . push (EmbeddingInput { id : chunk . id . clone () , text , metadata : chunk . metadata . clone () , }) ; } Ok (inputs) } . sig",
      "content_with_context": "// File: src/rag.rs\n// Module: crate::rag\n\n Convert RAG document to embedding-optimized format.\n\n# [doc = \" Convert RAG document to embedding-optimized format.\"] pub fn format_for_embeddings (document : & RagDocument) -> Result < Vec < EmbeddingInput > > { let mut inputs = Vec :: new () ; for chunk in & document . chunks { let text = match chunk . metadata . embedding_strategy { EmbeddingStrategy :: Combined => chunk . content_with_context . clone () , EmbeddingStrategy :: CodeOnly => { chunk . content . clone () } EmbeddingStrategy :: DocumentationOnly => { chunk . content . lines () . filter (| line | line . starts_with (\"///\") || line . starts_with (\"//!\")) . map (| line | line . trim_start_matches (\"///\") . trim_start_matches (\"//!\") . trim ()) . collect :: < Vec < _ > > () . join (\" \") } EmbeddingStrategy :: Specialized (_) => chunk . content_with_context . clone () , } ; inputs . push (EmbeddingInput { id : chunk . id . clone () , text , metadata : chunk . metadata . clone () , }) ; } Ok (inputs) } . sig\n// Complexity: 23",
      "metadata": {
        "file_path": "src/rag.rs",
        "start_line": 1,
        "end_line": 1,
        "element_type": "Function",
        "element_name": "format_for_embeddings",
        "qualified_name": "crate::rag::format_for_embeddings",
        "visibility": "Public",
        "token_count": 246,
        "complexity": 23,
        "has_documentation": true,
        "documentation_quality": "Basic",
        "semantic_category": "function_definition",
        "domain_tags": [],
        "intent_tags": [],
        "references": [],
        "referenced_by": [],
        "parent_elements": [
          ""
        ],
        "child_elements": [],
        "embedding_strategy": "Combined",
        "retrieval_keywords": [
          "convert",
          "crate::rag::format_for_embeddings",
          "document",
          "embedding-optimized",
          "format",
          "format_for_embeddings"
        ]
      },
      "embedding": null,
      "semantic_hash": "5abb88f97b739bdb"
    },
    {
      "id": "chunk_42",
      "content": " Input format for embedding models.\n\nEmbeddingInput",
      "content_with_context": "// File: src/rag.rs\n// Module: crate::rag\n\n Input format for embedding models.\n\nEmbeddingInput\n// Complexity: 5",
      "metadata": {
        "file_path": "src/rag.rs",
        "start_line": 1,
        "end_line": 1,
        "element_type": "Struct",
        "element_name": "EmbeddingInput",
        "qualified_name": "crate::rag::EmbeddingInput",
        "visibility": "Public",
        "token_count": 13,
        "complexity": 5,
        "has_documentation": true,
        "documentation_quality": "Basic",
        "semantic_category": "data_structure",
        "domain_tags": [],
        "intent_tags": [
          "data_type"
        ],
        "references": [],
        "referenced_by": [],
        "parent_elements": [
          ""
        ],
        "child_elements": [],
        "embedding_strategy": "DocumentationOnly",
        "retrieval_keywords": [
          "EmbeddingInput",
          "crate::rag::EmbeddingInput",
          "embedding",
          "format",
          "input",
          "models"
        ]
      },
      "embedding": null,
      "semantic_hash": "eb92763d9f9a3167"
    }
  ],
  "semantics": {
    "concept_hierarchy": [],
    "relationships": [],
    "vocabulary": {},
    "patterns": [],
    "api_surface": {
      "public_functions": [
        {
          "name": "format_project_ast",
          "qualified_name": "crate::formatters::format_project_ast",
          "element_type": "Function",
          "signature": "# [doc = \" Format project AST according to the specified output format.\"] pub fn format_project_ast (project_ast : & ProjectAst , format : & OutputFormat , pretty : bool ,) -> Result < String > { match format { OutputFormat :: Json => { if pretty { Ok (serde_json :: to_string_pretty (project_ast) ?) } else { Ok (serde_json :: to_string (project_ast) ?) } } OutputFormat :: MessagePack => { let data = rmp_serde :: to_vec (project_ast) ? ; use base64 :: Engine ; Ok (base64 :: engine :: general_purpose :: STANDARD . encode (data)) } OutputFormat :: Markdown => { format_as_markdown (project_ast) } OutputFormat :: GraphQL => { format_as_graphql_schema (project_ast) } OutputFormat :: Rag => { let formatter = RagFormatter :: default () ; let rag_doc = formatter . format (project_ast) ? ; crate :: rag :: format_as_json (& rag_doc , pretty) } } } . sig",
          "documentation": " Format project AST according to the specified output format.",
          "chunk_id": "chunk_format_project_ast",
          "stability": "Stable",
          "usage_examples": []
        },
        {
          "name": "format_as_markdown",
          "qualified_name": "crate::formatters::format_as_markdown",
          "element_type": "Function",
          "signature": "# [doc = \" Format project AST as Markdown documentation.\"] pub fn format_as_markdown (project_ast : & ProjectAst) -> Result < String > { let mut markdown = String :: new () ; markdown . push_str (& format ! (\"# {}\\n\\n\" , project_ast . project . name)) ; markdown . push_str (& format ! (\"**Version:** {}\\n\" , project_ast . project . version)) ; markdown . push_str (& format ! (\"**Rust Edition:** {}\\n\\n\" , project_ast . project . rust_edition)) ; markdown . push_str (\"## Table of Contents\\n\\n\") ; for file in & project_ast . files { markdown . push_str (& format ! (\"- [{}](#{})\\n\" , file . relative_path . display () , file . relative_path . to_string_lossy () . replace ('/' , \"\") . replace ('.' , \"\"))) ; } markdown . push ('\\n') ; markdown . push_str (\"## Project Metrics\\n\\n\") ; markdown . push_str (& format ! (\"- **Total Files:** {}\\n\" , project_ast . metrics . total_files)) ; markdown . push_str (& format ! (\"- **Total Lines:** {}\\n\" , project_ast . metrics . total_lines)) ; markdown . push_str (& format ! (\"- **Total Functions:** {}\\n\" , project_ast . metrics . total_functions)) ; markdown . push_str (& format ! (\"- **Total Structs:** {}\\n\" , project_ast . metrics . total_structs)) ; markdown . push_str (& format ! (\"- **Total Enums:** {}\\n\" , project_ast . metrics . total_enums)) ; markdown . push_str (& format ! (\"- **Total Traits:** {}\\n\" , project_ast . metrics . total_traits)) ; markdown . push_str (& format ! (\"- **Average Complexity:** {:.2}\\n\\n\" , project_ast . metrics . complexity_average)) ; for file in & project_ast . files { markdown . push_str (& format ! (\"## {}\\n\\n\" , file . relative_path . display ())) ; if ! file . elements . is_empty () { for element in & file . elements { markdown . push_str (& format ! (\"### {} `{}`\\n\\n\" , format ! (\"{:?}\" , element . element_type) , element . name)) ; if ! element . doc_comments . is_empty () { for doc in & element . doc_comments { markdown . push_str (& format ! (\"{}\\n\" , doc)) ; } markdown . push ('\\n') ; } if let Some (signature) = & element . signature { markdown . push_str (\"```rust\\n\") ; markdown . push_str (signature) ; markdown . push_str (\"\\n```\\n\\n\") ; } markdown . push_str (\"**Details:**\\n\") ; markdown . push_str (& format ! (\"- **Location:** {}:{}-{}\\n\" , file . relative_path . display () , element . location . line_start , element . location . line_end)) ; markdown . push_str (& format ! (\"- **Visibility:** {:?}\\n\" , element . visibility)) ; if let Some (complexity) = element . complexity { markdown . push_str (& format ! (\"- **Complexity:** {}\\n\" , complexity)) ; } markdown . push ('\\n') ; } } else { markdown . push_str (\"*No documented elements in this file.*\\n\\n\") ; } } Ok (markdown) } . sig",
          "documentation": " Format project AST as Markdown documentation.",
          "chunk_id": "chunk_format_as_markdown",
          "stability": "Stable",
          "usage_examples": []
        },
        {
          "name": "format_as_graphql_schema",
          "qualified_name": "crate::formatters::format_as_graphql_schema",
          "element_type": "Function",
          "signature": "# [doc = \" Format project AST as GraphQL schema.\"] pub fn format_as_graphql_schema (project_ast : & ProjectAst) -> Result < String > { let mut schema = String :: new () ; schema . push_str (& format ! (\"# GraphQL Schema for {}\\n\" , project_ast . project . name)) ; schema . push_str (& format ! (\"# Generated from Rust AST\\n\\n\")) ; schema . push_str (\"type Project {\\n\") ; schema . push_str (\"  name: String!\\n\") ; schema . push_str (\"  version: String!\\n\") ; schema . push_str (\"  rustEdition: String!\\n\") ; schema . push_str (\"  files: [File!]!\\n\") ; schema . push_str (\"  metrics: ProjectMetrics!\\n\") ; schema . push_str (\"}\\n\\n\") ; schema . push_str (\"type File {\\n\") ; schema . push_str (\"  path: String!\\n\") ; schema . push_str (\"  elements: [CodeElement!]!\\n\") ; schema . push_str (\"}\\n\\n\") ; schema . push_str (\"type CodeElement {\\n\") ; schema . push_str (\"  id: String!\\n\") ; schema . push_str (\"  elementType: ElementType!\\n\") ; schema . push_str (\"  name: String!\\n\") ; schema . push_str (\"  signature: String\\n\") ; schema . push_str (\"  docComments: [String!]!\\n\") ; schema . push_str (\"  visibility: Visibility!\\n\") ; schema . push_str (\"  complexity: Int\\n\") ; schema . push_str (\"  location: Location!\\n\") ; schema . push_str (\"  hierarchy: ElementHierarchy!\\n\") ; schema . push_str (\"  crossReferences: CrossReferences!\\n\") ; schema . push_str (\"}\\n\\n\") ; schema . push_str (\"enum ElementType {\\n\") ; schema . push_str (\"  FUNCTION\\n\") ; schema . push_str (\"  STRUCT\\n\") ; schema . push_str (\"  ENUM\\n\") ; schema . push_str (\"  TRAIT\\n\") ; schema . push_str (\"  IMPLEMENTATION\\n\") ; schema . push_str (\"  MODULE\\n\") ; schema . push_str (\"}\\n\\n\") ; schema . push_str (\"enum Visibility {\\n\") ; schema . push_str (\"  PUBLIC\\n\") ; schema . push_str (\"  PRIVATE\\n\") ; schema . push_str (\"  CRATE\\n\") ; schema . push_str (\"  SUPER\\n\") ; schema . push_str (\"}\\n\\n\") ; schema . push_str (\"type Location {\\n\") ; schema . push_str (\"  lineStart: Int!\\n\") ; schema . push_str (\"  lineEnd: Int!\\n\") ; schema . push_str (\"  columnStart: Int!\\n\") ; schema . push_str (\"  columnEnd: Int!\\n\") ; schema . push_str (\"}\\n\\n\") ; schema . push_str (\"type ElementHierarchy {\\n\") ; schema . push_str (\"  qualifiedName: String!\\n\") ; schema . push_str (\"  modulePath: String!\\n\") ; schema . push_str (\"  parentId: String\\n\") ; schema . push_str (\"  children: [String!]!\\n\") ; schema . push_str (\"}\\n\\n\") ; schema . push_str (\"type CrossReferences {\\n\") ; schema . push_str (\"  outgoing: [String!]!\\n\") ; schema . push_str (\"  incoming: [String!]!\\n\") ; schema . push_str (\"}\\n\\n\") ; schema . push_str (\"type ProjectMetrics {\\n\") ; schema . push_str (\"  totalFiles: Int!\\n\") ; schema . push_str (\"  totalLines: Int!\\n\") ; schema . push_str (\"  totalFunctions: Int!\\n\") ; schema . push_str (\"  totalStructs: Int!\\n\") ; schema . push_str (\"  totalEnums: Int!\\n\") ; schema . push_str (\"  totalTraits: Int!\\n\") ; schema . push_str (\"  complexityAverage: Float!\\n\") ; schema . push_str (\"}\\n\\n\") ; schema . push_str (\"type Query {\\n\") ; schema . push_str (\"  project: Project!\\n\") ; schema . push_str (\"  file(path: String!): File\\n\") ; schema . push_str (\"  element(id: String!): CodeElement\\n\") ; schema . push_str (\"  elementsByType(elementType: ElementType!): [CodeElement!]!\\n\") ; schema . push_str (\"  elementsByComplexity(minComplexity: Int!): [CodeElement!]!\\n\") ; schema . push_str (\"}\\n\") ; Ok (schema) } . sig",
          "documentation": " Format project AST as GraphQL schema.",
          "chunk_id": "chunk_format_as_graphql_schema",
          "stability": "Stable",
          "usage_examples": []
        },
        {
          "name": "create_rag_formatter",
          "qualified_name": "crate::formatters::create_rag_formatter",
          "element_type": "Function",
          "signature": "# [doc = \" Create a RAG formatter with custom configuration.\"] pub fn create_rag_formatter (config : RagConfig) -> RagFormatter { RagFormatter :: new (config) } . sig",
          "documentation": " Create a RAG formatter with custom configuration.",
          "chunk_id": "chunk_create_rag_formatter",
          "stability": "Stable",
          "usage_examples": []
        },
        {
          "name": "format_as_rag_with_config",
          "qualified_name": "crate::formatters::format_as_rag_with_config",
          "element_type": "Function",
          "signature": "# [doc = \" Format project AST using a custom RAG configuration.\"] pub fn format_as_rag_with_config (project_ast : & ProjectAst , config : RagConfig , pretty : bool ,) -> Result < String > { let formatter = RagFormatter :: new (config) ; let rag_doc = formatter . format (project_ast) ? ; crate :: rag :: format_as_json (& rag_doc , pretty) } . sig",
          "documentation": " Format project AST using a custom RAG configuration.",
          "chunk_id": "chunk_format_as_rag_with_config",
          "stability": "Stable",
          "usage_examples": []
        },
        {
          "name": "format_as_rag_jsonl",
          "qualified_name": "crate::formatters::format_as_rag_jsonl",
          "element_type": "Function",
          "signature": "# [doc = \" Format project AST as JSONL for streaming/embedding processing.\"] pub fn format_as_rag_jsonl (project_ast : & ProjectAst) -> Result < String > { let formatter = RagFormatter :: default () ; let rag_doc = formatter . format (project_ast) ? ; crate :: rag :: format_as_jsonl (& rag_doc) } . sig",
          "documentation": " Format project AST as JSONL for streaming/embedding processing.",
          "chunk_id": "chunk_format_as_rag_jsonl",
          "stability": "Stable",
          "usage_examples": []
        },
        {
          "name": "format_for_embeddings",
          "qualified_name": "crate::formatters::format_for_embeddings",
          "element_type": "Function",
          "signature": "# [doc = \" Format project AST for embedding models.\"] pub fn format_for_embeddings (project_ast : & ProjectAst) -> Result < Vec < crate :: rag :: EmbeddingInput > > { let formatter = RagFormatter :: default () ; let rag_doc = formatter . format (project_ast) ? ; crate :: rag :: format_for_embeddings (& rag_doc) } . sig",
          "documentation": " Format project AST for embedding models.",
          "chunk_id": "chunk_format_for_embeddings",
          "stability": "Stable",
          "usage_examples": []
        },
        {
          "name": "new",
          "qualified_name": "Impl_impl impl RagFormatter { # [doc = \" Create a new RAG formatter with the given configuration.\"] pub fn new (config : RagConfig) -> Self { Self { config } } # [doc = \" Create a new RAG formatter with default configuration.\"] pub fn default () -> Self { Self { config : RagConfig :: default () , } } # [doc = \" Format a ProjectAst into RAG document format.\"] pub fn format (& self , project_ast : & ProjectAst) -> Result < RagDocument > { let metadata = self . build_metadata (project_ast) ? ; let chunks = self . create_chunks (project_ast) ? ; let semantics = self . analyze_semantics (project_ast , & chunks) ? ; let training_examples = if self . config . generate_training_examples { self . generate_training_examples (project_ast , & chunks) ? } else { Vec :: new () } ; Ok (RagDocument { metadata , chunks , semantics , training_examples , }) } # [doc = \" Build metadata for the RAG document.\"] fn build_metadata (& self , project_ast : & ProjectAst) -> Result < RagMetadata > { let mut element_distribution = HashMap :: new () ; let mut complexity_distribution = HashMap :: new () ; let mut total_tokens = 0 ; let mut token_sizes = Vec :: new () ; for file in & project_ast . files { for element in & file . elements { let element_type = format ! (\"{:?}\" , element . element_type) ; * element_distribution . entry (element_type) . or_insert (0) += 1 ; if let Some (complexity) = element . complexity { let complexity_level = match complexity { 0 ..= 2 => \"Simple\" , 3 ..= 5 => \"Moderate\" , 6 ..= 10 => \"Complex\" , _ => \"Very Complex\" , } ; * complexity_distribution . entry (complexity_level . to_string ()) . or_insert (0) += 1 ; } let content = self . build_element_content (element) ; let tokens = self . estimate_token_count (& content) ; total_tokens += tokens ; token_sizes . push (tokens) ; } } token_sizes . sort_unstable () ; let chunk_size_stats = ChunkSizeStats { min_tokens : token_sizes . first () . copied () . unwrap_or (0) , max_tokens : token_sizes . last () . copied () . unwrap_or (0) , avg_tokens : if ! token_sizes . is_empty () { token_sizes . iter () . sum :: < usize > () as f64 / token_sizes . len () as f64 } else { 0.0 } , median_tokens : if ! token_sizes . is_empty () { token_sizes [token_sizes . len () / 2] } else { 0 } , p95_tokens : if ! token_sizes . is_empty () { let p95_index = (token_sizes . len () as f64 * 0.95) as usize ; token_sizes [p95_index . min (token_sizes . len () - 1)] } else { 0 } , } ; Ok (RagMetadata { project_name : project_ast . project . name . clone () , project_version : project_ast . project . version . clone () , rust_edition : project_ast . project . rust_edition . clone () , total_chunks : token_sizes . len () , total_tokens , chunk_size_stats , element_distribution , complexity_distribution , semantic_categories : vec ! [\"function_definition\" . to_string () , \"data_structure\" . to_string () , \"trait_definition\" . to_string () , \"implementation\" . to_string () , \"module_organization\" . to_string () ,] , generated_at : chrono :: Utc :: now () . to_rfc3339 () , rustex_version : env ! (\"CARGO_PKG_VERSION\") . to_string () , chunk_strategy : \"semantic_boundaries\" . to_string () , }) } # [doc = \" Create optimized chunks from the project AST.\"] fn create_chunks (& self , project_ast : & ProjectAst) -> Result < Vec < RagChunk > > { let mut chunks = Vec :: new () ; let mut chunk_id = 0 ; for file in & project_ast . files { for element in & file . elements { if ! self . should_include_element (element) { continue ; } let content = self . build_element_content (element) ; let content_with_context = self . build_element_content_with_context (element , file) ; let metadata = self . build_chunk_metadata (element , file , & content) ? ; let semantic_hash = self . generate_semantic_hash (& content) ; chunk_id += 1 ; chunks . push (RagChunk { id : format ! (\"chunk_{}\" , chunk_id) , content , content_with_context , metadata , embedding : None , semantic_hash , }) ; } } Ok (chunks) } # [doc = \" Analyze semantic relationships and concepts.\"] fn analyze_semantics (& self , project_ast : & ProjectAst , chunks : & [RagChunk]) -> Result < RagSemantics > { let concept_hierarchy = self . extract_concept_hierarchy (project_ast) ? ; let relationships = self . extract_semantic_relationships (project_ast , chunks) ? ; let vocabulary = self . build_vocabulary (project_ast) ? ; let patterns = self . identify_code_patterns (project_ast) ? ; let api_surface = self . analyze_api_surface (project_ast) ? ; Ok (RagSemantics { concept_hierarchy , relationships , vocabulary , patterns , api_surface , }) } # [doc = \" Generate training examples for LLM fine-tuning.\"] fn generate_training_examples (& self , _project_ast : & ProjectAst , chunks : & [RagChunk]) -> Result < Vec < TrainingExample > > { let mut examples = Vec :: new () ; let mut example_id = 0 ; for chunk in chunks { let mut chunk_examples = 0 ; if chunk_examples < self . config . max_training_examples_per_chunk { if let Some (example) = self . create_code_explanation_example (chunk , & mut example_id) ? { examples . push (example) ; chunk_examples += 1 ; } } if chunk_examples < self . config . max_training_examples_per_chunk { if let Some (example) = self . create_code_completion_example (chunk , & mut example_id) ? { examples . push (example) ; chunk_examples += 1 ; } } if chunk_examples < self . config . max_training_examples_per_chunk { if let Some (example) = self . create_api_usage_example (chunk , & mut example_id) ? { examples . push (example) ; let _ = chunk_examples + 1 ; } } } Ok (examples) } # [doc = \" Check if an element should be included based on configuration.\"] fn should_include_element (& self , element : & CodeElement) -> bool { if ! self . config . include_private_items && element . visibility != Visibility :: Public { return false ; } if let Some (min_complexity) = self . config . min_complexity_for_inclusion { if element . complexity . unwrap_or (0) < min_complexity { return false ; } } if ! self . config . include_test_code { if element . name . contains (\"test\") || element . attributes . iter () . any (| attr | attr . contains (\"test\")) { return false ; } } true } # [doc = \" Build content string for an element.\"] fn build_element_content (& self , element : & CodeElement) -> String { let mut content = String :: new () ; if ! element . doc_comments . is_empty () { content . push_str (& element . doc_comments . join (\"\\n\")) ; content . push_str (\"\\n\\n\") ; } if let Some (signature) = & element . signature { content . push_str (signature) ; } else { content . push_str (& element . name) ; } content } # [doc = \" Build content with additional context.\"] fn build_element_content_with_context (& self , element : & CodeElement , file : & FileAst) -> String { let mut content = String :: new () ; content . push_str (& format ! (\"// File: {}\\n\" , file . relative_path . display ())) ; content . push_str (& format ! (\"// Module: {}\\n\\n\" , element . hierarchy . module_path)) ; content . push_str (& self . build_element_content (element)) ; if element . complexity . is_some () { content . push_str (& format ! (\"\\n// Complexity: {}\" , element . complexity . unwrap ())) ; } content } # [doc = \" Build metadata for a chunk.\"] fn build_chunk_metadata (& self , element : & CodeElement , file : & FileAst , content : & str) -> Result < ChunkMetadata > { let documentation_quality = self . assess_documentation_quality (element) ; let semantic_category = self . categorize_element (element) ; let domain_tags = self . extract_domain_tags (element) ; let intent_tags = self . extract_intent_tags (element) ; let embedding_strategy = self . determine_embedding_strategy (element) ; let retrieval_keywords = self . extract_retrieval_keywords (element) ; Ok (ChunkMetadata { file_path : file . relative_path . to_string_lossy () . to_string () , start_line : element . location . line_start as u32 , end_line : element . location . line_end as u32 , element_type : format ! (\"{:?}\" , element . element_type) , element_name : element . name . clone () , qualified_name : element . hierarchy . qualified_name . clone () , visibility : format ! (\"{:?}\" , element . visibility) , token_count : self . estimate_token_count (content) , complexity : element . complexity , has_documentation : ! element . doc_comments . is_empty () , documentation_quality , semantic_category , domain_tags , intent_tags , references : Vec :: new () , referenced_by : Vec :: new () , parent_elements : vec ! [element . hierarchy . parent_id . clone () . unwrap_or_default ()] , child_elements : element . hierarchy . children_ids . clone () , embedding_strategy , retrieval_keywords , }) } # [doc = \" Estimate token count for text (rough approximation).\"] fn estimate_token_count (& self , text : & str) -> usize { (text . len () as f64 / 4.0) . ceil () as usize } # [doc = \" Generate semantic hash for deduplication.\"] fn generate_semantic_hash (& self , content : & str) -> String { use std :: collections :: hash_map :: DefaultHasher ; use std :: hash :: { Hash , Hasher } ; let mut hasher = DefaultHasher :: new () ; content . hash (& mut hasher) ; format ! (\"{:x}\" , hasher . finish ()) } # [doc = \" Assess documentation quality.\"] fn assess_documentation_quality (& self , element : & CodeElement) -> DocumentationQuality { if element . doc_comments . is_empty () { return DocumentationQuality :: Missing ; } let doc_text = element . doc_comments . join (\" \") ; let has_examples = doc_text . contains (\"```\") || doc_text . contains (\"Example\") ; let has_details = doc_text . len () > 100 ; let has_params = doc_text . contains (\"# Arguments\") || doc_text . contains (\"Parameters\") ; match (has_examples , has_details , has_params) { (true , true , true) => DocumentationQuality :: Excellent , (_ , true , true) | (true , true , _) => DocumentationQuality :: Good , (_ , true , _) | (_ , _ , true) => DocumentationQuality :: Basic , _ => DocumentationQuality :: Basic , } } # [doc = \" Categorize element semantically.\"] fn categorize_element (& self , element : & CodeElement) -> String { match element . element_type { ElementType :: Function => \"function_definition\" . to_string () , ElementType :: Struct => \"data_structure\" . to_string () , ElementType :: Enum => \"data_structure\" . to_string () , ElementType :: Trait => \"trait_definition\" . to_string () , ElementType :: Impl => \"implementation\" . to_string () , ElementType :: Module => \"module_organization\" . to_string () , _ => \"other\" . to_string () , } } # [doc = \" Extract domain-specific tags.\"] fn extract_domain_tags (& self , element : & CodeElement) -> Vec < String > { let mut tags = Vec :: new () ; let name_lower = element . name . to_lowercase () ; if name_lower . contains (\"http\") || name_lower . contains (\"web\") { tags . push (\"web\" . to_string ()) ; } if name_lower . contains (\"db\") || name_lower . contains (\"database\") || name_lower . contains (\"sql\") { tags . push (\"database\" . to_string ()) ; } if name_lower . contains (\"async\") || name_lower . contains (\"future\") { tags . push (\"async\" . to_string ()) ; } if name_lower . contains (\"test\") { tags . push (\"testing\" . to_string ()) ; } tags } # [doc = \" Extract intent tags.\"] fn extract_intent_tags (& self , element : & CodeElement) -> Vec < String > { let mut tags = Vec :: new () ; match element . element_type { ElementType :: Function => { if element . name . starts_with (\"new\") { tags . push (\"constructor\" . to_string ()) ; } if element . name . starts_with (\"get\") || element . name . starts_with (\"is\") { tags . push (\"accessor\" . to_string ()) ; } if element . name . starts_with (\"set\") { tags . push (\"mutator\" . to_string ()) ; } } ElementType :: Trait => { tags . push (\"interface\" . to_string ()) ; } ElementType :: Struct | ElementType :: Enum => { tags . push (\"data_type\" . to_string ()) ; } _ => { } } tags } # [doc = \" Determine optimal embedding strategy.\"] fn determine_embedding_strategy (& self , element : & CodeElement) -> EmbeddingStrategy { if element . doc_comments . is_empty () { EmbeddingStrategy :: CodeOnly } else if element . signature . is_none () { EmbeddingStrategy :: DocumentationOnly } else { EmbeddingStrategy :: Combined } } # [doc = \" Extract keywords for retrieval.\"] fn extract_retrieval_keywords (& self , element : & CodeElement) -> Vec < String > { let mut keywords = Vec :: new () ; keywords . push (element . name . clone ()) ; keywords . push (element . hierarchy . qualified_name . clone ()) ; for doc in & element . doc_comments { let words : Vec < String > = doc . split_whitespace () . filter (| w | w . len () > 3 && ! w . starts_with (\"///\")) . map (| w | w . to_lowercase () . trim_matches (| c : char | ! c . is_alphanumeric ()) . to_string ()) . filter (| w | ! w . is_empty ()) . collect () ; keywords . extend (words) ; } keywords . sort () ; keywords . dedup () ; keywords . truncate (20) ; keywords } fn extract_concept_hierarchy (& self , _project_ast : & ProjectAst) -> Result < Vec < ConceptNode > > { Ok (Vec :: new ()) } fn extract_semantic_relationships (& self , _project_ast : & ProjectAst , _chunks : & [RagChunk]) -> Result < Vec < SemanticRelationship > > { Ok (Vec :: new ()) } fn build_vocabulary (& self , _project_ast : & ProjectAst) -> Result < HashMap < String , VocabularyEntry > > { Ok (HashMap :: new ()) } fn identify_code_patterns (& self , _project_ast : & ProjectAst) -> Result < Vec < CodePattern > > { Ok (Vec :: new ()) } fn analyze_api_surface (& self , project_ast : & ProjectAst) -> Result < ApiSurface > { let mut public_functions = Vec :: new () ; let mut public_types = Vec :: new () ; let mut public_traits = Vec :: new () ; let mut modules = Vec :: new () ; for file in & project_ast . files { for element in & file . elements { if element . visibility == Visibility :: Public { let api_element = ApiElement { name : element . name . clone () , qualified_name : element . hierarchy . qualified_name . clone () , element_type : format ! (\"{:?}\" , element . element_type) , signature : element . signature . clone () . unwrap_or_default () , documentation : element . doc_comments . join (\"\\n\") , chunk_id : format ! (\"chunk_{}\" , element . name) , stability : ApiStability :: Stable , usage_examples : Vec :: new () , } ; match element . element_type { ElementType :: Function => public_functions . push (api_element) , ElementType :: Struct | ElementType :: Enum => public_types . push (api_element) , ElementType :: Trait => public_traits . push (api_element) , ElementType :: Module => modules . push (api_element) , ElementType :: Impl => { } , _ => { } , } } } } let complexity_metrics = ApiComplexityMetrics { total_public_items : public_functions . len () + public_types . len () + public_traits . len () , avg_parameter_count : 0.0 , max_parameter_count : 0 , generic_usage_ratio : 0.0 , documentation_coverage : 0.0 , } ; Ok (ApiSurface { public_functions , public_types , public_traits , modules , entry_points : vec ! [\"main\" . to_string ()] , complexity_metrics , }) } fn create_code_explanation_example (& self , _chunk : & RagChunk , example_id : & mut usize) -> Result < Option < TrainingExample > > { * example_id += 1 ; Ok (None) } fn create_code_completion_example (& self , _chunk : & RagChunk , example_id : & mut usize) -> Result < Option < TrainingExample > > { * example_id += 1 ; Ok (None) } fn create_api_usage_example (& self , _chunk : & RagChunk , example_id : & mut usize) -> Result < Option < TrainingExample > > { * example_id += 1 ; Ok (None) } } . self_ty_28::new",
          "element_type": "Function",
          "signature": "# [doc = \" Create a new RAG formatter with the given configuration.\"] pub fn new (config : RagConfig) -> Self { Self { config } } . sig",
          "documentation": " Create a new RAG formatter with the given configuration.",
          "chunk_id": "chunk_new",
          "stability": "Stable",
          "usage_examples": []
        },
        {
          "name": "default",
          "qualified_name": "Impl_impl impl RagFormatter { # [doc = \" Create a new RAG formatter with the given configuration.\"] pub fn new (config : RagConfig) -> Self { Self { config } } # [doc = \" Create a new RAG formatter with default configuration.\"] pub fn default () -> Self { Self { config : RagConfig :: default () , } } # [doc = \" Format a ProjectAst into RAG document format.\"] pub fn format (& self , project_ast : & ProjectAst) -> Result < RagDocument > { let metadata = self . build_metadata (project_ast) ? ; let chunks = self . create_chunks (project_ast) ? ; let semantics = self . analyze_semantics (project_ast , & chunks) ? ; let training_examples = if self . config . generate_training_examples { self . generate_training_examples (project_ast , & chunks) ? } else { Vec :: new () } ; Ok (RagDocument { metadata , chunks , semantics , training_examples , }) } # [doc = \" Build metadata for the RAG document.\"] fn build_metadata (& self , project_ast : & ProjectAst) -> Result < RagMetadata > { let mut element_distribution = HashMap :: new () ; let mut complexity_distribution = HashMap :: new () ; let mut total_tokens = 0 ; let mut token_sizes = Vec :: new () ; for file in & project_ast . files { for element in & file . elements { let element_type = format ! (\"{:?}\" , element . element_type) ; * element_distribution . entry (element_type) . or_insert (0) += 1 ; if let Some (complexity) = element . complexity { let complexity_level = match complexity { 0 ..= 2 => \"Simple\" , 3 ..= 5 => \"Moderate\" , 6 ..= 10 => \"Complex\" , _ => \"Very Complex\" , } ; * complexity_distribution . entry (complexity_level . to_string ()) . or_insert (0) += 1 ; } let content = self . build_element_content (element) ; let tokens = self . estimate_token_count (& content) ; total_tokens += tokens ; token_sizes . push (tokens) ; } } token_sizes . sort_unstable () ; let chunk_size_stats = ChunkSizeStats { min_tokens : token_sizes . first () . copied () . unwrap_or (0) , max_tokens : token_sizes . last () . copied () . unwrap_or (0) , avg_tokens : if ! token_sizes . is_empty () { token_sizes . iter () . sum :: < usize > () as f64 / token_sizes . len () as f64 } else { 0.0 } , median_tokens : if ! token_sizes . is_empty () { token_sizes [token_sizes . len () / 2] } else { 0 } , p95_tokens : if ! token_sizes . is_empty () { let p95_index = (token_sizes . len () as f64 * 0.95) as usize ; token_sizes [p95_index . min (token_sizes . len () - 1)] } else { 0 } , } ; Ok (RagMetadata { project_name : project_ast . project . name . clone () , project_version : project_ast . project . version . clone () , rust_edition : project_ast . project . rust_edition . clone () , total_chunks : token_sizes . len () , total_tokens , chunk_size_stats , element_distribution , complexity_distribution , semantic_categories : vec ! [\"function_definition\" . to_string () , \"data_structure\" . to_string () , \"trait_definition\" . to_string () , \"implementation\" . to_string () , \"module_organization\" . to_string () ,] , generated_at : chrono :: Utc :: now () . to_rfc3339 () , rustex_version : env ! (\"CARGO_PKG_VERSION\") . to_string () , chunk_strategy : \"semantic_boundaries\" . to_string () , }) } # [doc = \" Create optimized chunks from the project AST.\"] fn create_chunks (& self , project_ast : & ProjectAst) -> Result < Vec < RagChunk > > { let mut chunks = Vec :: new () ; let mut chunk_id = 0 ; for file in & project_ast . files { for element in & file . elements { if ! self . should_include_element (element) { continue ; } let content = self . build_element_content (element) ; let content_with_context = self . build_element_content_with_context (element , file) ; let metadata = self . build_chunk_metadata (element , file , & content) ? ; let semantic_hash = self . generate_semantic_hash (& content) ; chunk_id += 1 ; chunks . push (RagChunk { id : format ! (\"chunk_{}\" , chunk_id) , content , content_with_context , metadata , embedding : None , semantic_hash , }) ; } } Ok (chunks) } # [doc = \" Analyze semantic relationships and concepts.\"] fn analyze_semantics (& self , project_ast : & ProjectAst , chunks : & [RagChunk]) -> Result < RagSemantics > { let concept_hierarchy = self . extract_concept_hierarchy (project_ast) ? ; let relationships = self . extract_semantic_relationships (project_ast , chunks) ? ; let vocabulary = self . build_vocabulary (project_ast) ? ; let patterns = self . identify_code_patterns (project_ast) ? ; let api_surface = self . analyze_api_surface (project_ast) ? ; Ok (RagSemantics { concept_hierarchy , relationships , vocabulary , patterns , api_surface , }) } # [doc = \" Generate training examples for LLM fine-tuning.\"] fn generate_training_examples (& self , _project_ast : & ProjectAst , chunks : & [RagChunk]) -> Result < Vec < TrainingExample > > { let mut examples = Vec :: new () ; let mut example_id = 0 ; for chunk in chunks { let mut chunk_examples = 0 ; if chunk_examples < self . config . max_training_examples_per_chunk { if let Some (example) = self . create_code_explanation_example (chunk , & mut example_id) ? { examples . push (example) ; chunk_examples += 1 ; } } if chunk_examples < self . config . max_training_examples_per_chunk { if let Some (example) = self . create_code_completion_example (chunk , & mut example_id) ? { examples . push (example) ; chunk_examples += 1 ; } } if chunk_examples < self . config . max_training_examples_per_chunk { if let Some (example) = self . create_api_usage_example (chunk , & mut example_id) ? { examples . push (example) ; let _ = chunk_examples + 1 ; } } } Ok (examples) } # [doc = \" Check if an element should be included based on configuration.\"] fn should_include_element (& self , element : & CodeElement) -> bool { if ! self . config . include_private_items && element . visibility != Visibility :: Public { return false ; } if let Some (min_complexity) = self . config . min_complexity_for_inclusion { if element . complexity . unwrap_or (0) < min_complexity { return false ; } } if ! self . config . include_test_code { if element . name . contains (\"test\") || element . attributes . iter () . any (| attr | attr . contains (\"test\")) { return false ; } } true } # [doc = \" Build content string for an element.\"] fn build_element_content (& self , element : & CodeElement) -> String { let mut content = String :: new () ; if ! element . doc_comments . is_empty () { content . push_str (& element . doc_comments . join (\"\\n\")) ; content . push_str (\"\\n\\n\") ; } if let Some (signature) = & element . signature { content . push_str (signature) ; } else { content . push_str (& element . name) ; } content } # [doc = \" Build content with additional context.\"] fn build_element_content_with_context (& self , element : & CodeElement , file : & FileAst) -> String { let mut content = String :: new () ; content . push_str (& format ! (\"// File: {}\\n\" , file . relative_path . display ())) ; content . push_str (& format ! (\"// Module: {}\\n\\n\" , element . hierarchy . module_path)) ; content . push_str (& self . build_element_content (element)) ; if element . complexity . is_some () { content . push_str (& format ! (\"\\n// Complexity: {}\" , element . complexity . unwrap ())) ; } content } # [doc = \" Build metadata for a chunk.\"] fn build_chunk_metadata (& self , element : & CodeElement , file : & FileAst , content : & str) -> Result < ChunkMetadata > { let documentation_quality = self . assess_documentation_quality (element) ; let semantic_category = self . categorize_element (element) ; let domain_tags = self . extract_domain_tags (element) ; let intent_tags = self . extract_intent_tags (element) ; let embedding_strategy = self . determine_embedding_strategy (element) ; let retrieval_keywords = self . extract_retrieval_keywords (element) ; Ok (ChunkMetadata { file_path : file . relative_path . to_string_lossy () . to_string () , start_line : element . location . line_start as u32 , end_line : element . location . line_end as u32 , element_type : format ! (\"{:?}\" , element . element_type) , element_name : element . name . clone () , qualified_name : element . hierarchy . qualified_name . clone () , visibility : format ! (\"{:?}\" , element . visibility) , token_count : self . estimate_token_count (content) , complexity : element . complexity , has_documentation : ! element . doc_comments . is_empty () , documentation_quality , semantic_category , domain_tags , intent_tags , references : Vec :: new () , referenced_by : Vec :: new () , parent_elements : vec ! [element . hierarchy . parent_id . clone () . unwrap_or_default ()] , child_elements : element . hierarchy . children_ids . clone () , embedding_strategy , retrieval_keywords , }) } # [doc = \" Estimate token count for text (rough approximation).\"] fn estimate_token_count (& self , text : & str) -> usize { (text . len () as f64 / 4.0) . ceil () as usize } # [doc = \" Generate semantic hash for deduplication.\"] fn generate_semantic_hash (& self , content : & str) -> String { use std :: collections :: hash_map :: DefaultHasher ; use std :: hash :: { Hash , Hasher } ; let mut hasher = DefaultHasher :: new () ; content . hash (& mut hasher) ; format ! (\"{:x}\" , hasher . finish ()) } # [doc = \" Assess documentation quality.\"] fn assess_documentation_quality (& self , element : & CodeElement) -> DocumentationQuality { if element . doc_comments . is_empty () { return DocumentationQuality :: Missing ; } let doc_text = element . doc_comments . join (\" \") ; let has_examples = doc_text . contains (\"```\") || doc_text . contains (\"Example\") ; let has_details = doc_text . len () > 100 ; let has_params = doc_text . contains (\"# Arguments\") || doc_text . contains (\"Parameters\") ; match (has_examples , has_details , has_params) { (true , true , true) => DocumentationQuality :: Excellent , (_ , true , true) | (true , true , _) => DocumentationQuality :: Good , (_ , true , _) | (_ , _ , true) => DocumentationQuality :: Basic , _ => DocumentationQuality :: Basic , } } # [doc = \" Categorize element semantically.\"] fn categorize_element (& self , element : & CodeElement) -> String { match element . element_type { ElementType :: Function => \"function_definition\" . to_string () , ElementType :: Struct => \"data_structure\" . to_string () , ElementType :: Enum => \"data_structure\" . to_string () , ElementType :: Trait => \"trait_definition\" . to_string () , ElementType :: Impl => \"implementation\" . to_string () , ElementType :: Module => \"module_organization\" . to_string () , _ => \"other\" . to_string () , } } # [doc = \" Extract domain-specific tags.\"] fn extract_domain_tags (& self , element : & CodeElement) -> Vec < String > { let mut tags = Vec :: new () ; let name_lower = element . name . to_lowercase () ; if name_lower . contains (\"http\") || name_lower . contains (\"web\") { tags . push (\"web\" . to_string ()) ; } if name_lower . contains (\"db\") || name_lower . contains (\"database\") || name_lower . contains (\"sql\") { tags . push (\"database\" . to_string ()) ; } if name_lower . contains (\"async\") || name_lower . contains (\"future\") { tags . push (\"async\" . to_string ()) ; } if name_lower . contains (\"test\") { tags . push (\"testing\" . to_string ()) ; } tags } # [doc = \" Extract intent tags.\"] fn extract_intent_tags (& self , element : & CodeElement) -> Vec < String > { let mut tags = Vec :: new () ; match element . element_type { ElementType :: Function => { if element . name . starts_with (\"new\") { tags . push (\"constructor\" . to_string ()) ; } if element . name . starts_with (\"get\") || element . name . starts_with (\"is\") { tags . push (\"accessor\" . to_string ()) ; } if element . name . starts_with (\"set\") { tags . push (\"mutator\" . to_string ()) ; } } ElementType :: Trait => { tags . push (\"interface\" . to_string ()) ; } ElementType :: Struct | ElementType :: Enum => { tags . push (\"data_type\" . to_string ()) ; } _ => { } } tags } # [doc = \" Determine optimal embedding strategy.\"] fn determine_embedding_strategy (& self , element : & CodeElement) -> EmbeddingStrategy { if element . doc_comments . is_empty () { EmbeddingStrategy :: CodeOnly } else if element . signature . is_none () { EmbeddingStrategy :: DocumentationOnly } else { EmbeddingStrategy :: Combined } } # [doc = \" Extract keywords for retrieval.\"] fn extract_retrieval_keywords (& self , element : & CodeElement) -> Vec < String > { let mut keywords = Vec :: new () ; keywords . push (element . name . clone ()) ; keywords . push (element . hierarchy . qualified_name . clone ()) ; for doc in & element . doc_comments { let words : Vec < String > = doc . split_whitespace () . filter (| w | w . len () > 3 && ! w . starts_with (\"///\")) . map (| w | w . to_lowercase () . trim_matches (| c : char | ! c . is_alphanumeric ()) . to_string ()) . filter (| w | ! w . is_empty ()) . collect () ; keywords . extend (words) ; } keywords . sort () ; keywords . dedup () ; keywords . truncate (20) ; keywords } fn extract_concept_hierarchy (& self , _project_ast : & ProjectAst) -> Result < Vec < ConceptNode > > { Ok (Vec :: new ()) } fn extract_semantic_relationships (& self , _project_ast : & ProjectAst , _chunks : & [RagChunk]) -> Result < Vec < SemanticRelationship > > { Ok (Vec :: new ()) } fn build_vocabulary (& self , _project_ast : & ProjectAst) -> Result < HashMap < String , VocabularyEntry > > { Ok (HashMap :: new ()) } fn identify_code_patterns (& self , _project_ast : & ProjectAst) -> Result < Vec < CodePattern > > { Ok (Vec :: new ()) } fn analyze_api_surface (& self , project_ast : & ProjectAst) -> Result < ApiSurface > { let mut public_functions = Vec :: new () ; let mut public_types = Vec :: new () ; let mut public_traits = Vec :: new () ; let mut modules = Vec :: new () ; for file in & project_ast . files { for element in & file . elements { if element . visibility == Visibility :: Public { let api_element = ApiElement { name : element . name . clone () , qualified_name : element . hierarchy . qualified_name . clone () , element_type : format ! (\"{:?}\" , element . element_type) , signature : element . signature . clone () . unwrap_or_default () , documentation : element . doc_comments . join (\"\\n\") , chunk_id : format ! (\"chunk_{}\" , element . name) , stability : ApiStability :: Stable , usage_examples : Vec :: new () , } ; match element . element_type { ElementType :: Function => public_functions . push (api_element) , ElementType :: Struct | ElementType :: Enum => public_types . push (api_element) , ElementType :: Trait => public_traits . push (api_element) , ElementType :: Module => modules . push (api_element) , ElementType :: Impl => { } , _ => { } , } } } } let complexity_metrics = ApiComplexityMetrics { total_public_items : public_functions . len () + public_types . len () + public_traits . len () , avg_parameter_count : 0.0 , max_parameter_count : 0 , generic_usage_ratio : 0.0 , documentation_coverage : 0.0 , } ; Ok (ApiSurface { public_functions , public_types , public_traits , modules , entry_points : vec ! [\"main\" . to_string ()] , complexity_metrics , }) } fn create_code_explanation_example (& self , _chunk : & RagChunk , example_id : & mut usize) -> Result < Option < TrainingExample > > { * example_id += 1 ; Ok (None) } fn create_code_completion_example (& self , _chunk : & RagChunk , example_id : & mut usize) -> Result < Option < TrainingExample > > { * example_id += 1 ; Ok (None) } fn create_api_usage_example (& self , _chunk : & RagChunk , example_id : & mut usize) -> Result < Option < TrainingExample > > { * example_id += 1 ; Ok (None) } } . self_ty_28::default",
          "element_type": "Function",
          "signature": "# [doc = \" Create a new RAG formatter with default configuration.\"] pub fn default () -> Self { Self { config : RagConfig :: default () , } } . sig",
          "documentation": " Create a new RAG formatter with default configuration.",
          "chunk_id": "chunk_default",
          "stability": "Stable",
          "usage_examples": []
        },
        {
          "name": "format",
          "qualified_name": "Impl_impl impl RagFormatter { # [doc = \" Create a new RAG formatter with the given configuration.\"] pub fn new (config : RagConfig) -> Self { Self { config } } # [doc = \" Create a new RAG formatter with default configuration.\"] pub fn default () -> Self { Self { config : RagConfig :: default () , } } # [doc = \" Format a ProjectAst into RAG document format.\"] pub fn format (& self , project_ast : & ProjectAst) -> Result < RagDocument > { let metadata = self . build_metadata (project_ast) ? ; let chunks = self . create_chunks (project_ast) ? ; let semantics = self . analyze_semantics (project_ast , & chunks) ? ; let training_examples = if self . config . generate_training_examples { self . generate_training_examples (project_ast , & chunks) ? } else { Vec :: new () } ; Ok (RagDocument { metadata , chunks , semantics , training_examples , }) } # [doc = \" Build metadata for the RAG document.\"] fn build_metadata (& self , project_ast : & ProjectAst) -> Result < RagMetadata > { let mut element_distribution = HashMap :: new () ; let mut complexity_distribution = HashMap :: new () ; let mut total_tokens = 0 ; let mut token_sizes = Vec :: new () ; for file in & project_ast . files { for element in & file . elements { let element_type = format ! (\"{:?}\" , element . element_type) ; * element_distribution . entry (element_type) . or_insert (0) += 1 ; if let Some (complexity) = element . complexity { let complexity_level = match complexity { 0 ..= 2 => \"Simple\" , 3 ..= 5 => \"Moderate\" , 6 ..= 10 => \"Complex\" , _ => \"Very Complex\" , } ; * complexity_distribution . entry (complexity_level . to_string ()) . or_insert (0) += 1 ; } let content = self . build_element_content (element) ; let tokens = self . estimate_token_count (& content) ; total_tokens += tokens ; token_sizes . push (tokens) ; } } token_sizes . sort_unstable () ; let chunk_size_stats = ChunkSizeStats { min_tokens : token_sizes . first () . copied () . unwrap_or (0) , max_tokens : token_sizes . last () . copied () . unwrap_or (0) , avg_tokens : if ! token_sizes . is_empty () { token_sizes . iter () . sum :: < usize > () as f64 / token_sizes . len () as f64 } else { 0.0 } , median_tokens : if ! token_sizes . is_empty () { token_sizes [token_sizes . len () / 2] } else { 0 } , p95_tokens : if ! token_sizes . is_empty () { let p95_index = (token_sizes . len () as f64 * 0.95) as usize ; token_sizes [p95_index . min (token_sizes . len () - 1)] } else { 0 } , } ; Ok (RagMetadata { project_name : project_ast . project . name . clone () , project_version : project_ast . project . version . clone () , rust_edition : project_ast . project . rust_edition . clone () , total_chunks : token_sizes . len () , total_tokens , chunk_size_stats , element_distribution , complexity_distribution , semantic_categories : vec ! [\"function_definition\" . to_string () , \"data_structure\" . to_string () , \"trait_definition\" . to_string () , \"implementation\" . to_string () , \"module_organization\" . to_string () ,] , generated_at : chrono :: Utc :: now () . to_rfc3339 () , rustex_version : env ! (\"CARGO_PKG_VERSION\") . to_string () , chunk_strategy : \"semantic_boundaries\" . to_string () , }) } # [doc = \" Create optimized chunks from the project AST.\"] fn create_chunks (& self , project_ast : & ProjectAst) -> Result < Vec < RagChunk > > { let mut chunks = Vec :: new () ; let mut chunk_id = 0 ; for file in & project_ast . files { for element in & file . elements { if ! self . should_include_element (element) { continue ; } let content = self . build_element_content (element) ; let content_with_context = self . build_element_content_with_context (element , file) ; let metadata = self . build_chunk_metadata (element , file , & content) ? ; let semantic_hash = self . generate_semantic_hash (& content) ; chunk_id += 1 ; chunks . push (RagChunk { id : format ! (\"chunk_{}\" , chunk_id) , content , content_with_context , metadata , embedding : None , semantic_hash , }) ; } } Ok (chunks) } # [doc = \" Analyze semantic relationships and concepts.\"] fn analyze_semantics (& self , project_ast : & ProjectAst , chunks : & [RagChunk]) -> Result < RagSemantics > { let concept_hierarchy = self . extract_concept_hierarchy (project_ast) ? ; let relationships = self . extract_semantic_relationships (project_ast , chunks) ? ; let vocabulary = self . build_vocabulary (project_ast) ? ; let patterns = self . identify_code_patterns (project_ast) ? ; let api_surface = self . analyze_api_surface (project_ast) ? ; Ok (RagSemantics { concept_hierarchy , relationships , vocabulary , patterns , api_surface , }) } # [doc = \" Generate training examples for LLM fine-tuning.\"] fn generate_training_examples (& self , _project_ast : & ProjectAst , chunks : & [RagChunk]) -> Result < Vec < TrainingExample > > { let mut examples = Vec :: new () ; let mut example_id = 0 ; for chunk in chunks { let mut chunk_examples = 0 ; if chunk_examples < self . config . max_training_examples_per_chunk { if let Some (example) = self . create_code_explanation_example (chunk , & mut example_id) ? { examples . push (example) ; chunk_examples += 1 ; } } if chunk_examples < self . config . max_training_examples_per_chunk { if let Some (example) = self . create_code_completion_example (chunk , & mut example_id) ? { examples . push (example) ; chunk_examples += 1 ; } } if chunk_examples < self . config . max_training_examples_per_chunk { if let Some (example) = self . create_api_usage_example (chunk , & mut example_id) ? { examples . push (example) ; let _ = chunk_examples + 1 ; } } } Ok (examples) } # [doc = \" Check if an element should be included based on configuration.\"] fn should_include_element (& self , element : & CodeElement) -> bool { if ! self . config . include_private_items && element . visibility != Visibility :: Public { return false ; } if let Some (min_complexity) = self . config . min_complexity_for_inclusion { if element . complexity . unwrap_or (0) < min_complexity { return false ; } } if ! self . config . include_test_code { if element . name . contains (\"test\") || element . attributes . iter () . any (| attr | attr . contains (\"test\")) { return false ; } } true } # [doc = \" Build content string for an element.\"] fn build_element_content (& self , element : & CodeElement) -> String { let mut content = String :: new () ; if ! element . doc_comments . is_empty () { content . push_str (& element . doc_comments . join (\"\\n\")) ; content . push_str (\"\\n\\n\") ; } if let Some (signature) = & element . signature { content . push_str (signature) ; } else { content . push_str (& element . name) ; } content } # [doc = \" Build content with additional context.\"] fn build_element_content_with_context (& self , element : & CodeElement , file : & FileAst) -> String { let mut content = String :: new () ; content . push_str (& format ! (\"// File: {}\\n\" , file . relative_path . display ())) ; content . push_str (& format ! (\"// Module: {}\\n\\n\" , element . hierarchy . module_path)) ; content . push_str (& self . build_element_content (element)) ; if element . complexity . is_some () { content . push_str (& format ! (\"\\n// Complexity: {}\" , element . complexity . unwrap ())) ; } content } # [doc = \" Build metadata for a chunk.\"] fn build_chunk_metadata (& self , element : & CodeElement , file : & FileAst , content : & str) -> Result < ChunkMetadata > { let documentation_quality = self . assess_documentation_quality (element) ; let semantic_category = self . categorize_element (element) ; let domain_tags = self . extract_domain_tags (element) ; let intent_tags = self . extract_intent_tags (element) ; let embedding_strategy = self . determine_embedding_strategy (element) ; let retrieval_keywords = self . extract_retrieval_keywords (element) ; Ok (ChunkMetadata { file_path : file . relative_path . to_string_lossy () . to_string () , start_line : element . location . line_start as u32 , end_line : element . location . line_end as u32 , element_type : format ! (\"{:?}\" , element . element_type) , element_name : element . name . clone () , qualified_name : element . hierarchy . qualified_name . clone () , visibility : format ! (\"{:?}\" , element . visibility) , token_count : self . estimate_token_count (content) , complexity : element . complexity , has_documentation : ! element . doc_comments . is_empty () , documentation_quality , semantic_category , domain_tags , intent_tags , references : Vec :: new () , referenced_by : Vec :: new () , parent_elements : vec ! [element . hierarchy . parent_id . clone () . unwrap_or_default ()] , child_elements : element . hierarchy . children_ids . clone () , embedding_strategy , retrieval_keywords , }) } # [doc = \" Estimate token count for text (rough approximation).\"] fn estimate_token_count (& self , text : & str) -> usize { (text . len () as f64 / 4.0) . ceil () as usize } # [doc = \" Generate semantic hash for deduplication.\"] fn generate_semantic_hash (& self , content : & str) -> String { use std :: collections :: hash_map :: DefaultHasher ; use std :: hash :: { Hash , Hasher } ; let mut hasher = DefaultHasher :: new () ; content . hash (& mut hasher) ; format ! (\"{:x}\" , hasher . finish ()) } # [doc = \" Assess documentation quality.\"] fn assess_documentation_quality (& self , element : & CodeElement) -> DocumentationQuality { if element . doc_comments . is_empty () { return DocumentationQuality :: Missing ; } let doc_text = element . doc_comments . join (\" \") ; let has_examples = doc_text . contains (\"```\") || doc_text . contains (\"Example\") ; let has_details = doc_text . len () > 100 ; let has_params = doc_text . contains (\"# Arguments\") || doc_text . contains (\"Parameters\") ; match (has_examples , has_details , has_params) { (true , true , true) => DocumentationQuality :: Excellent , (_ , true , true) | (true , true , _) => DocumentationQuality :: Good , (_ , true , _) | (_ , _ , true) => DocumentationQuality :: Basic , _ => DocumentationQuality :: Basic , } } # [doc = \" Categorize element semantically.\"] fn categorize_element (& self , element : & CodeElement) -> String { match element . element_type { ElementType :: Function => \"function_definition\" . to_string () , ElementType :: Struct => \"data_structure\" . to_string () , ElementType :: Enum => \"data_structure\" . to_string () , ElementType :: Trait => \"trait_definition\" . to_string () , ElementType :: Impl => \"implementation\" . to_string () , ElementType :: Module => \"module_organization\" . to_string () , _ => \"other\" . to_string () , } } # [doc = \" Extract domain-specific tags.\"] fn extract_domain_tags (& self , element : & CodeElement) -> Vec < String > { let mut tags = Vec :: new () ; let name_lower = element . name . to_lowercase () ; if name_lower . contains (\"http\") || name_lower . contains (\"web\") { tags . push (\"web\" . to_string ()) ; } if name_lower . contains (\"db\") || name_lower . contains (\"database\") || name_lower . contains (\"sql\") { tags . push (\"database\" . to_string ()) ; } if name_lower . contains (\"async\") || name_lower . contains (\"future\") { tags . push (\"async\" . to_string ()) ; } if name_lower . contains (\"test\") { tags . push (\"testing\" . to_string ()) ; } tags } # [doc = \" Extract intent tags.\"] fn extract_intent_tags (& self , element : & CodeElement) -> Vec < String > { let mut tags = Vec :: new () ; match element . element_type { ElementType :: Function => { if element . name . starts_with (\"new\") { tags . push (\"constructor\" . to_string ()) ; } if element . name . starts_with (\"get\") || element . name . starts_with (\"is\") { tags . push (\"accessor\" . to_string ()) ; } if element . name . starts_with (\"set\") { tags . push (\"mutator\" . to_string ()) ; } } ElementType :: Trait => { tags . push (\"interface\" . to_string ()) ; } ElementType :: Struct | ElementType :: Enum => { tags . push (\"data_type\" . to_string ()) ; } _ => { } } tags } # [doc = \" Determine optimal embedding strategy.\"] fn determine_embedding_strategy (& self , element : & CodeElement) -> EmbeddingStrategy { if element . doc_comments . is_empty () { EmbeddingStrategy :: CodeOnly } else if element . signature . is_none () { EmbeddingStrategy :: DocumentationOnly } else { EmbeddingStrategy :: Combined } } # [doc = \" Extract keywords for retrieval.\"] fn extract_retrieval_keywords (& self , element : & CodeElement) -> Vec < String > { let mut keywords = Vec :: new () ; keywords . push (element . name . clone ()) ; keywords . push (element . hierarchy . qualified_name . clone ()) ; for doc in & element . doc_comments { let words : Vec < String > = doc . split_whitespace () . filter (| w | w . len () > 3 && ! w . starts_with (\"///\")) . map (| w | w . to_lowercase () . trim_matches (| c : char | ! c . is_alphanumeric ()) . to_string ()) . filter (| w | ! w . is_empty ()) . collect () ; keywords . extend (words) ; } keywords . sort () ; keywords . dedup () ; keywords . truncate (20) ; keywords } fn extract_concept_hierarchy (& self , _project_ast : & ProjectAst) -> Result < Vec < ConceptNode > > { Ok (Vec :: new ()) } fn extract_semantic_relationships (& self , _project_ast : & ProjectAst , _chunks : & [RagChunk]) -> Result < Vec < SemanticRelationship > > { Ok (Vec :: new ()) } fn build_vocabulary (& self , _project_ast : & ProjectAst) -> Result < HashMap < String , VocabularyEntry > > { Ok (HashMap :: new ()) } fn identify_code_patterns (& self , _project_ast : & ProjectAst) -> Result < Vec < CodePattern > > { Ok (Vec :: new ()) } fn analyze_api_surface (& self , project_ast : & ProjectAst) -> Result < ApiSurface > { let mut public_functions = Vec :: new () ; let mut public_types = Vec :: new () ; let mut public_traits = Vec :: new () ; let mut modules = Vec :: new () ; for file in & project_ast . files { for element in & file . elements { if element . visibility == Visibility :: Public { let api_element = ApiElement { name : element . name . clone () , qualified_name : element . hierarchy . qualified_name . clone () , element_type : format ! (\"{:?}\" , element . element_type) , signature : element . signature . clone () . unwrap_or_default () , documentation : element . doc_comments . join (\"\\n\") , chunk_id : format ! (\"chunk_{}\" , element . name) , stability : ApiStability :: Stable , usage_examples : Vec :: new () , } ; match element . element_type { ElementType :: Function => public_functions . push (api_element) , ElementType :: Struct | ElementType :: Enum => public_types . push (api_element) , ElementType :: Trait => public_traits . push (api_element) , ElementType :: Module => modules . push (api_element) , ElementType :: Impl => { } , _ => { } , } } } } let complexity_metrics = ApiComplexityMetrics { total_public_items : public_functions . len () + public_types . len () + public_traits . len () , avg_parameter_count : 0.0 , max_parameter_count : 0 , generic_usage_ratio : 0.0 , documentation_coverage : 0.0 , } ; Ok (ApiSurface { public_functions , public_types , public_traits , modules , entry_points : vec ! [\"main\" . to_string ()] , complexity_metrics , }) } fn create_code_explanation_example (& self , _chunk : & RagChunk , example_id : & mut usize) -> Result < Option < TrainingExample > > { * example_id += 1 ; Ok (None) } fn create_code_completion_example (& self , _chunk : & RagChunk , example_id : & mut usize) -> Result < Option < TrainingExample > > { * example_id += 1 ; Ok (None) } fn create_api_usage_example (& self , _chunk : & RagChunk , example_id : & mut usize) -> Result < Option < TrainingExample > > { * example_id += 1 ; Ok (None) } } . self_ty_28::format",
          "element_type": "Function",
          "signature": "# [doc = \" Format a ProjectAst into RAG document format.\"] pub fn format (& self , project_ast : & ProjectAst) -> Result < RagDocument > { let metadata = self . build_metadata (project_ast) ? ; let chunks = self . create_chunks (project_ast) ? ; let semantics = self . analyze_semantics (project_ast , & chunks) ? ; let training_examples = if self . config . generate_training_examples { self . generate_training_examples (project_ast , & chunks) ? } else { Vec :: new () } ; Ok (RagDocument { metadata , chunks , semantics , training_examples , }) } . sig",
          "documentation": " Format a ProjectAst into RAG document format.",
          "chunk_id": "chunk_format",
          "stability": "Stable",
          "usage_examples": []
        },
        {
          "name": "format_as_json",
          "qualified_name": "crate::rag::format_as_json",
          "element_type": "Function",
          "signature": "# [doc = \" Convert RAG document to JSON format.\"] pub fn format_as_json (document : & RagDocument , pretty : bool) -> Result < String > { if pretty { Ok (serde_json :: to_string_pretty (document) ?) } else { Ok (serde_json :: to_string (document) ?) } } . sig",
          "documentation": " Convert RAG document to JSON format.",
          "chunk_id": "chunk_format_as_json",
          "stability": "Stable",
          "usage_examples": []
        },
        {
          "name": "format_as_jsonl",
          "qualified_name": "crate::rag::format_as_jsonl",
          "element_type": "Function",
          "signature": "# [doc = \" Convert RAG document to JSONL format (one chunk per line).\"] pub fn format_as_jsonl (document : & RagDocument) -> Result < String > { let mut output = String :: new () ; output . push_str (& serde_json :: to_string (& document . metadata) ?) ; output . push ('\\n') ; for chunk in & document . chunks { output . push_str (& serde_json :: to_string (chunk) ?) ; output . push ('\\n') ; } Ok (output) } . sig",
          "documentation": " Convert RAG document to JSONL format (one chunk per line).",
          "chunk_id": "chunk_format_as_jsonl",
          "stability": "Stable",
          "usage_examples": []
        },
        {
          "name": "format_for_embeddings",
          "qualified_name": "crate::rag::format_for_embeddings",
          "element_type": "Function",
          "signature": "# [doc = \" Convert RAG document to embedding-optimized format.\"] pub fn format_for_embeddings (document : & RagDocument) -> Result < Vec < EmbeddingInput > > { let mut inputs = Vec :: new () ; for chunk in & document . chunks { let text = match chunk . metadata . embedding_strategy { EmbeddingStrategy :: Combined => chunk . content_with_context . clone () , EmbeddingStrategy :: CodeOnly => { chunk . content . clone () } EmbeddingStrategy :: DocumentationOnly => { chunk . content . lines () . filter (| line | line . starts_with (\"///\") || line . starts_with (\"//!\")) . map (| line | line . trim_start_matches (\"///\") . trim_start_matches (\"//!\") . trim ()) . collect :: < Vec < _ > > () . join (\" \") } EmbeddingStrategy :: Specialized (_) => chunk . content_with_context . clone () , } ; inputs . push (EmbeddingInput { id : chunk . id . clone () , text , metadata : chunk . metadata . clone () , }) ; } Ok (inputs) } . sig",
          "documentation": " Convert RAG document to embedding-optimized format.",
          "chunk_id": "chunk_format_for_embeddings",
          "stability": "Stable",
          "usage_examples": []
        }
      ],
      "public_types": [
        {
          "name": "RagDocument",
          "qualified_name": "crate::rag::RagDocument",
          "element_type": "Struct",
          "signature": "",
          "documentation": " RAG-optimized AST representation designed for embedding and retrieval.",
          "chunk_id": "chunk_RagDocument",
          "stability": "Stable",
          "usage_examples": []
        },
        {
          "name": "RagMetadata",
          "qualified_name": "crate::rag::RagMetadata",
          "element_type": "Struct",
          "signature": "",
          "documentation": " Metadata for RAG document indexing and filtering.",
          "chunk_id": "chunk_RagMetadata",
          "stability": "Stable",
          "usage_examples": []
        },
        {
          "name": "ChunkSizeStats",
          "qualified_name": "crate::rag::ChunkSizeStats",
          "element_type": "Struct",
          "signature": "",
          "documentation": " Statistics about chunk sizes for embedding optimization.",
          "chunk_id": "chunk_ChunkSizeStats",
          "stability": "Stable",
          "usage_examples": []
        },
        {
          "name": "RagChunk",
          "qualified_name": "crate::rag::RagChunk",
          "element_type": "Struct",
          "signature": "",
          "documentation": " A single text chunk optimized for embedding and retrieval.",
          "chunk_id": "chunk_RagChunk",
          "stability": "Stable",
          "usage_examples": []
        },
        {
          "name": "ChunkMetadata",
          "qualified_name": "crate::rag::ChunkMetadata",
          "element_type": "Struct",
          "signature": "",
          "documentation": " Metadata for individual chunks.",
          "chunk_id": "chunk_ChunkMetadata",
          "stability": "Stable",
          "usage_examples": []
        },
        {
          "name": "DocumentationQuality",
          "qualified_name": "crate::rag::DocumentationQuality",
          "element_type": "Enum",
          "signature": "",
          "documentation": " Documentation quality assessment for ranking.",
          "chunk_id": "chunk_DocumentationQuality",
          "stability": "Stable",
          "usage_examples": []
        },
        {
          "name": "EmbeddingStrategy",
          "qualified_name": "crate::rag::EmbeddingStrategy",
          "element_type": "Enum",
          "signature": "",
          "documentation": " Strategy for embedding this chunk.",
          "chunk_id": "chunk_EmbeddingStrategy",
          "stability": "Stable",
          "usage_examples": []
        },
        {
          "name": "RagSemantics",
          "qualified_name": "crate::rag::RagSemantics",
          "element_type": "Struct",
          "signature": "",
          "documentation": " Semantic information for enhanced retrieval.",
          "chunk_id": "chunk_RagSemantics",
          "stability": "Stable",
          "usage_examples": []
        },
        {
          "name": "ConceptNode",
          "qualified_name": "crate::rag::ConceptNode",
          "element_type": "Struct",
          "signature": "",
          "documentation": " A concept in the semantic hierarchy.",
          "chunk_id": "chunk_ConceptNode",
          "stability": "Stable",
          "usage_examples": []
        },
        {
          "name": "ConceptType",
          "qualified_name": "crate::rag::ConceptType",
          "element_type": "Enum",
          "signature": "",
          "documentation": " Types of semantic concepts.",
          "chunk_id": "chunk_ConceptType",
          "stability": "Stable",
          "usage_examples": []
        },
        {
          "name": "SemanticRelationship",
          "qualified_name": "crate::rag::SemanticRelationship",
          "element_type": "Struct",
          "signature": "",
          "documentation": " Semantic relationship between code elements.",
          "chunk_id": "chunk_SemanticRelationship",
          "stability": "Stable",
          "usage_examples": []
        },
        {
          "name": "RelationshipType",
          "qualified_name": "crate::rag::RelationshipType",
          "element_type": "Enum",
          "signature": "",
          "documentation": " Types of semantic relationships.",
          "chunk_id": "chunk_RelationshipType",
          "stability": "Stable",
          "usage_examples": []
        },
        {
          "name": "VocabularyEntry",
          "qualified_name": "crate::rag::VocabularyEntry",
          "element_type": "Struct",
          "signature": "",
          "documentation": " Entry in the domain vocabulary.",
          "chunk_id": "chunk_VocabularyEntry",
          "stability": "Stable",
          "usage_examples": []
        },
        {
          "name": "CodePattern",
          "qualified_name": "crate::rag::CodePattern",
          "element_type": "Struct",
          "signature": "",
          "documentation": " Identified code pattern or idiom.",
          "chunk_id": "chunk_CodePattern",
          "stability": "Stable",
          "usage_examples": []
        },
        {
          "name": "PatternType",
          "qualified_name": "crate::rag::PatternType",
          "element_type": "Enum",
          "signature": "",
          "documentation": " Types of code patterns.",
          "chunk_id": "chunk_PatternType",
          "stability": "Stable",
          "usage_examples": []
        },
        {
          "name": "ApiSurface",
          "qualified_name": "crate::rag::ApiSurface",
          "element_type": "Struct",
          "signature": "",
          "documentation": " Analysis of the public API surface.",
          "chunk_id": "chunk_ApiSurface",
          "stability": "Stable",
          "usage_examples": []
        },
        {
          "name": "ApiElement",
          "qualified_name": "crate::rag::ApiElement",
          "element_type": "Struct",
          "signature": "",
          "documentation": " A public API element.",
          "chunk_id": "chunk_ApiElement",
          "stability": "Stable",
          "usage_examples": []
        },
        {
          "name": "ApiStability",
          "qualified_name": "crate::rag::ApiStability",
          "element_type": "Enum",
          "signature": "",
          "documentation": " API stability assessment.",
          "chunk_id": "chunk_ApiStability",
          "stability": "Stable",
          "usage_examples": []
        },
        {
          "name": "ApiComplexityMetrics",
          "qualified_name": "crate::rag::ApiComplexityMetrics",
          "element_type": "Struct",
          "signature": "",
          "documentation": " Metrics about API complexity.",
          "chunk_id": "chunk_ApiComplexityMetrics",
          "stability": "Stable",
          "usage_examples": []
        },
        {
          "name": "TrainingExample",
          "qualified_name": "crate::rag::TrainingExample",
          "element_type": "Struct",
          "signature": "",
          "documentation": " Training example for LLM fine-tuning.",
          "chunk_id": "chunk_TrainingExample",
          "stability": "Stable",
          "usage_examples": []
        },
        {
          "name": "TaskType",
          "qualified_name": "crate::rag::TaskType",
          "element_type": "Enum",
          "signature": "",
          "documentation": " Types of training tasks.",
          "chunk_id": "chunk_TaskType",
          "stability": "Stable",
          "usage_examples": []
        },
        {
          "name": "DifficultyLevel",
          "qualified_name": "crate::rag::DifficultyLevel",
          "element_type": "Enum",
          "signature": "",
          "documentation": " Difficulty levels for training examples.",
          "chunk_id": "chunk_DifficultyLevel",
          "stability": "Stable",
          "usage_examples": []
        },
        {
          "name": "TrainingMetadata",
          "qualified_name": "crate::rag::TrainingMetadata",
          "element_type": "Struct",
          "signature": "",
          "documentation": " Metadata for training examples.",
          "chunk_id": "chunk_TrainingMetadata",
          "stability": "Stable",
          "usage_examples": []
        },
        {
          "name": "RagConfig",
          "qualified_name": "crate::rag::RagConfig",
          "element_type": "Struct",
          "signature": "",
          "documentation": " Configuration for RAG document generation.",
          "chunk_id": "chunk_RagConfig",
          "stability": "Stable",
          "usage_examples": []
        },
        {
          "name": "SemanticDepth",
          "qualified_name": "crate::rag::SemanticDepth",
          "element_type": "Enum",
          "signature": "",
          "documentation": " Depth of semantic analysis to perform.",
          "chunk_id": "chunk_SemanticDepth",
          "stability": "Stable",
          "usage_examples": []
        },
        {
          "name": "RagFormatter",
          "qualified_name": "crate::rag::RagFormatter",
          "element_type": "Struct",
          "signature": "",
          "documentation": " Main RAG formatter that converts ProjectAst to RAG format.",
          "chunk_id": "chunk_RagFormatter",
          "stability": "Stable",
          "usage_examples": []
        },
        {
          "name": "EmbeddingInput",
          "qualified_name": "crate::rag::EmbeddingInput",
          "element_type": "Struct",
          "signature": "",
          "documentation": " Input format for embedding models.",
          "chunk_id": "chunk_EmbeddingInput",
          "stability": "Stable",
          "usage_examples": []
        }
      ],
      "public_traits": [],
      "modules": [
        {
          "name": "formatters",
          "qualified_name": "crate::formatters",
          "element_type": "Module",
          "signature": "",
          "documentation": "",
          "chunk_id": "chunk_formatters",
          "stability": "Stable",
          "usage_examples": []
        },
        {
          "name": "rag",
          "qualified_name": "crate::rag",
          "element_type": "Module",
          "signature": "",
          "documentation": "",
          "chunk_id": "chunk_rag",
          "stability": "Stable",
          "usage_examples": []
        }
      ],
      "entry_points": [
        "main"
      ],
      "complexity_metrics": {
        "total_public_items": 40,
        "avg_parameter_count": 0.0,
        "max_parameter_count": 0,
        "generic_usage_ratio": 0.0,
        "documentation_coverage": 0.0
      }
    }
  },
  "training_examples": []
}